{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "01b2ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # QA-supervised GNN (clean version)\n",
    "# - No \"question\" nodes inside the graph\n",
    "# - Train the GNN on your code KG\n",
    "# - Supervise using external QA embeddings: pull each question toward its mapped cluster\n",
    "\n",
    "# %%\n",
    "import os, ast, json, math, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Iterable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyG\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HGTConv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Clean printing\n",
    "pd.set_option('display.max_colwidth', 160)\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6fe362e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def parse_vec_cell(x, fallback_dim: int = 384) -> np.ndarray:\n",
    "    \"\"\"Robustly parse an embedding stored as list/np/str (even with '...').\"\"\"\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.astype(np.float32)\n",
    "    if isinstance(x, list):\n",
    "        return np.array(x, dtype=np.float32)\n",
    "    if isinstance(x, (tuple,)):\n",
    "        return np.array(list(x), dtype=np.float32)\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if \"...\" in s:\n",
    "            s = s.replace(\"...\", \"\")\n",
    "        # Try JSON first\n",
    "        try:\n",
    "            return np.array(json.loads(s), dtype=np.float32)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Try ast\n",
    "        try:\n",
    "            return np.array(ast.literal_eval(s), dtype=np.float32)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Fallback: comma-split floats\n",
    "        try:\n",
    "            s = s.strip(\"[]\")\n",
    "            vals = [float(t) for t in s.split(\",\") if t.strip()]\n",
    "            return np.array(vals, dtype=np.float32)\n",
    "        except Exception:\n",
    "            return np.zeros((fallback_dim,), dtype=np.float32)\n",
    "    # unknown -> zeros\n",
    "    return np.zeros((fallback_dim,), dtype=np.float32)\n",
    "\n",
    "\n",
    "def stack_series_to_tensor(series: pd.Series, fallback_dim: int = 384) -> torch.Tensor:\n",
    "    \"\"\"Vectorizes a DF/Series column with arbitrary embedding representations into a 2D torch tensor.\"\"\"\n",
    "    vecs = [parse_vec_cell(v, fallback_dim=fallback_dim) for v in series.tolist()]\n",
    "    dim = max((len(v) for v in vecs), default=fallback_dim) or fallback_dim\n",
    "    arr = np.zeros((len(vecs), dim), dtype=np.float32)\n",
    "    for i, v in enumerate(vecs):\n",
    "        if v.size:\n",
    "            d = min(dim, v.size)\n",
    "            arr[i, :d] = v[:d]\n",
    "    return torch.tensor(arr, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Optional text encoder for cluster summaries, if you want semantic text features.\n",
    "# Falls back to TF-IDF if transformers aren't available.\n",
    "def build_text_encoder():\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        def encode(texts: Iterable[str]) -> np.ndarray:\n",
    "            return model.encode(list(texts), convert_to_numpy=True, show_progress_bar=False).astype(np.float32)\n",
    "        print(\"Text encoder: sentence-transformers (all-MiniLM-L6-v2)\")\n",
    "        return encode\n",
    "    except Exception:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        vec = TfidfVectorizer(max_features=512)\n",
    "        print(\"Text encoder: TF-IDF fallback (512 dims)\")\n",
    "        def encode(texts: Iterable[str]) -> np.ndarray:\n",
    "            return vec.fit_transform(list(texts)).toarray().astype(np.float32)\n",
    "        return encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e2ab37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"graph_v3.pkl\", \"rb\") as f:\n",
    "    repograph = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "44f25106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 11128 valid embedding of 11128 total\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def safe_parse_embedding(x):\n",
    "    \"\"\"Biztons√°gosan konvert√°lja az embedding stringet list√°v√°.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        val = ast.literal_eval(x)\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    # ha valami hiba van, adunk egy nullvektort ugyanakkora dimenzi√≥val, mint az els≈ë helyes elem\n",
    "    return None\n",
    "\n",
    "# pr√≥b√°ljuk meg kinyerni a j√≥ sorokat\n",
    "parsed = func_nodes[\"docstring_embedding\"].apply(safe_parse_embedding)\n",
    "\n",
    "# eldobunk minden hib√°s sort\n",
    "valid = parsed.dropna()\n",
    "print(f\"‚úÖ {len(valid)} valid embedding of {len(parsed)} total\")\n",
    "\n",
    "# stack only valid embeddings\n",
    "X = np.stack(valid.values)\n",
    "x = torch.tensor(X, dtype=torch.float)\n",
    "\n",
    "# ha kell, a df-et is sz≈±k√≠tsd ehhez:\n",
    "func_nodes = func_nodes.loc[valid.index].reset_index(drop=True)\n",
    "\n",
    "# Felt√©telezz√ºk, hogy ez m√°r megvan:\n",
    "func_edges = repograph[\"function_edges\"]\n",
    "\n",
    "# A PyG √°ltal elv√°rt form√°tum: 2 x num_edges tensor\n",
    "edge_index = torch.tensor(\n",
    "    func_edges[[\"source\", \"target\"]].T.values,  # Transpose ‚Üí [2, num_edges]\n",
    "    dtype=torch.long\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f414739",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_id = min(func_edges[\"source\"].min(), func_edges[\"target\"].min())\n",
    "func_edges[\"source\"] -= min_id\n",
    "func_edges[\"target\"] -= min_id\n",
    "\n",
    "edge_index = torch.tensor(\n",
    "    func_edges[[\"source\", \"target\"]].T.values,\n",
    "    dtype=torch.long\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cbf9ccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[11128, 384], edge_index=[2, 19239])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "73b7878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_ids</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer_ids</th>\n",
       "      <th>answers</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79779783</td>\n",
       "      <td>&lt;p&gt;I have recently noticed that when I change the order of the observations in a sparse array, &lt;code&gt;scikit-learn&lt;/code&gt; PCA with &lt;code&gt;svd_solver=&amp;quot;arp...</td>\n",
       "      <td>79779909</td>\n",
       "      <td>&lt;p&gt;In short - yes, this is to be expected, however the differences should be small as they are caused by precision limits of the floating point arithmetic.&lt;...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79748223</td>\n",
       "      <td>&lt;p&gt;I would like to perform a regression analysis and test different transformations of the input variables for the same model. To accomplish this, I created...</td>\n",
       "      <td>79751118</td>\n",
       "      <td>&lt;p&gt;I actually found a solution similar to Ben Reiniger, but using GridSearchCV. The transformation of the target variable was not smooth at first, but Ben's...</td>\n",
       "      <td>['GridSearchCV._run_search']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79748461</td>\n",
       "      <td>&lt;p&gt;I want to undersample 3 cross-validation folds from a dataset, using say, RandomUnderSampler from imblearn, and then, optimize the hyperparameters of var...</td>\n",
       "      <td>79751379</td>\n",
       "      <td>&lt;p&gt;You can do this:&lt;/p&gt;\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;Get initial folds using &lt;code&gt;.split()&lt;/code&gt; method of your sklearn CV object. It returns indices for train and test ...</td>\n",
       "      <td>['HalvingRandomSearchCV._generate_candidate_params']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79749078</td>\n",
       "      <td>&lt;p&gt;I‚Äôm trying to evaluate classification models on a highly imbalanced fraud dataset using the Brier Skill Score (BSS) as the evaluation metric.&lt;/p&gt;\\n&lt;br&gt;\\n...</td>\n",
       "      <td>79749170</td>\n",
       "      <td>&lt;p&gt;I was getting &lt;code&gt;NaN&lt;/code&gt; values when using &lt;strong&gt;Brier Skill Score&lt;/strong&gt; with cross-validation.&lt;br /&gt;\\nThe issue was in how I defined the scor...</td>\n",
       "      <td>['DummyClassifier.predict_proba', '_ConstantPredictor.predict_proba', 'OneVsRestClassifier.predict_proba', 'MultiOutputClassifier.predict_proba', 'Pipeline....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79730533</td>\n",
       "      <td>&lt;p&gt;I am trying to install &lt;code&gt;scikit-learn&lt;/code&gt; and &lt;code&gt;imbalanced-learn&lt;/code&gt; for ML project using &lt;code&gt;poetry&lt;/code&gt;.&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;# File pypro...</td>\n",
       "      <td>79730580</td>\n",
       "      <td>&lt;p&gt;It seems &lt;code&gt;imbalanced-learn&lt;/code&gt; uses &lt;code&gt;sklearn-compat&lt;/code&gt; which needs &lt;code&gt;scikit-learn &amp;lt; 1.7&lt;/code&gt;&lt;/p&gt;\\n&lt;p&gt;So if you can work with ol...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>59881343</td>\n",
       "      <td>&lt;p&gt;As part of pursuing a course, I was trying to implement L1 logistic regression using scikit-learn in Python. Unfortunately for the code&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code...</td>\n",
       "      <td>59881394</td>\n",
       "      <td>&lt;p&gt;You can do it like you are doing in the first code snippet, but you have to define another solver. Use either ‚Äòliblinear‚Äô or ‚Äòsaga‚Äô, &lt;a href=\"https://sci...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>59864306</td>\n",
       "      <td>&lt;p&gt;i'm building a neural network using &lt;code&gt;sklearn.neural_network.MLPClassifier&lt;/code&gt; :&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;   clf =  sklearn.neural_network.MLPClassifier(...</td>\n",
       "      <td>59865247</td>\n",
       "      <td>&lt;p&gt;–£our method may give different scaling factors. It is for single scaling jobs, but not for the ones requiring consistent transformation.&lt;/p&gt;\\n\\n&lt;p&gt;I sugg...</td>\n",
       "      <td>['RBFSampler.transform', 'AdditiveChi2Sampler.transform', 'Nystroem.transform', 'Pipeline.fit_transform', 'Pipeline.transform', 'FeatureUnion.fit_transform'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>59812995</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;from sklearn.feature_extraction.text import CountVectorizer\\nvectorizer = CountVectorizer()\\nvector = vectorizer.fit_transform(X_train).toarray()...</td>\n",
       "      <td>59813181</td>\n",
       "      <td>&lt;p&gt;You should call &lt;code&gt;.toarray()&lt;/code&gt; as you have done for train data:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;test_vectors = vectorizer.transform(X_test).toarray()&lt;/code&gt;&lt;/p&gt;\\n</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>59839096</td>\n",
       "      <td>&lt;p&gt;Whenever I make a confusion matrix, I see the cells are not separated by a boundary line. I want to put a black line bordering between all cells. Can thi...</td>\n",
       "      <td>59860688</td>\n",
       "      <td>&lt;p&gt;use linewidths&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;sns.heatmap(confusion_mat_df, annot=True,linewidths=2,cmap=\"Blues\")\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;see &lt;a href=\"https://seaborn.py...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>59809219</td>\n",
       "      <td>&lt;p&gt;I am trying to use an sci-kit learn optimizer but I am having some issues that I can't resolve.I'm trying to use Bayesian optimization to tune my hyperpa...</td>\n",
       "      <td>59809455</td>\n",
       "      <td>&lt;p&gt;A minimal reproducible example would be nice. But i assume that the problem is, that the function that must be minimized is a method. Therefore func insi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4798 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_ids  \\\n",
       "0         79779783   \n",
       "1         79748223   \n",
       "2         79748461   \n",
       "3         79749078   \n",
       "4         79730533   \n",
       "...            ...   \n",
       "4793      59881343   \n",
       "4794      59864306   \n",
       "4795      59812995   \n",
       "4796      59839096   \n",
       "4797      59809219   \n",
       "\n",
       "                                                                                                                                                            questions  \\\n",
       "0     <p>I have recently noticed that when I change the order of the observations in a sparse array, <code>scikit-learn</code> PCA with <code>svd_solver=&quot;arp...   \n",
       "1     <p>I would like to perform a regression analysis and test different transformations of the input variables for the same model. To accomplish this, I created...   \n",
       "2     <p>I want to undersample 3 cross-validation folds from a dataset, using say, RandomUnderSampler from imblearn, and then, optimize the hyperparameters of var...   \n",
       "3     <p>I‚Äôm trying to evaluate classification models on a highly imbalanced fraud dataset using the Brier Skill Score (BSS) as the evaluation metric.</p>\\n<br>\\n...   \n",
       "4     <p>I am trying to install <code>scikit-learn</code> and <code>imbalanced-learn</code> for ML project using <code>poetry</code>.</p>\\n<pre><code># File pypro...   \n",
       "...                                                                                                                                                               ...   \n",
       "4793  <p>As part of pursuing a course, I was trying to implement L1 logistic regression using scikit-learn in Python. Unfortunately for the code</p>\\n\\n<pre><code...   \n",
       "4794  <p>i'm building a neural network using <code>sklearn.neural_network.MLPClassifier</code> :</p>\\n\\n<pre><code>   clf =  sklearn.neural_network.MLPClassifier(...   \n",
       "4795  <pre><code>from sklearn.feature_extraction.text import CountVectorizer\\nvectorizer = CountVectorizer()\\nvector = vectorizer.fit_transform(X_train).toarray()...   \n",
       "4796  <p>Whenever I make a confusion matrix, I see the cells are not separated by a boundary line. I want to put a black line bordering between all cells. Can thi...   \n",
       "4797  <p>I am trying to use an sci-kit learn optimizer but I am having some issues that I can't resolve.I'm trying to use Bayesian optimization to tune my hyperpa...   \n",
       "\n",
       "      answer_ids  \\\n",
       "0       79779909   \n",
       "1       79751118   \n",
       "2       79751379   \n",
       "3       79749170   \n",
       "4       79730580   \n",
       "...          ...   \n",
       "4793    59881394   \n",
       "4794    59865247   \n",
       "4795    59813181   \n",
       "4796    59860688   \n",
       "4797    59809455   \n",
       "\n",
       "                                                                                                                                                              answers  \\\n",
       "0     <p>In short - yes, this is to be expected, however the differences should be small as they are caused by precision limits of the floating point arithmetic.<...   \n",
       "1     <p>I actually found a solution similar to Ben Reiniger, but using GridSearchCV. The transformation of the target variable was not smooth at first, but Ben's...   \n",
       "2     <p>You can do this:</p>\\n<ol>\\n<li><p>Get initial folds using <code>.split()</code> method of your sklearn CV object. It returns indices for train and test ...   \n",
       "3     <p>I was getting <code>NaN</code> values when using <strong>Brier Skill Score</strong> with cross-validation.<br />\\nThe issue was in how I defined the scor...   \n",
       "4     <p>It seems <code>imbalanced-learn</code> uses <code>sklearn-compat</code> which needs <code>scikit-learn &lt; 1.7</code></p>\\n<p>So if you can work with ol...   \n",
       "...                                                                                                                                                               ...   \n",
       "4793  <p>You can do it like you are doing in the first code snippet, but you have to define another solver. Use either ‚Äòliblinear‚Äô or ‚Äòsaga‚Äô, <a href=\"https://sci...   \n",
       "4794  <p>–£our method may give different scaling factors. It is for single scaling jobs, but not for the ones requiring consistent transformation.</p>\\n\\n<p>I sugg...   \n",
       "4795   <p>You should call <code>.toarray()</code> as you have done for train data:</p>\\n\\n<p><code>test_vectors = vectorizer.transform(X_test).toarray()</code></p>\\n   \n",
       "4796  <p>use linewidths</p>\\n\\n<pre><code>sns.heatmap(confusion_mat_df, annot=True,linewidths=2,cmap=\"Blues\")\\n</code></pre>\\n\\n<p>see <a href=\"https://seaborn.py...   \n",
       "4797  <p>A minimal reproducible example would be nice. But i assume that the problem is, that the function that must be minimized is a method. Therefore func insi...   \n",
       "\n",
       "                                                                                                                                                             contexts  \n",
       "0                                                                                                                                                                  []  \n",
       "1                                                                                                                                        ['GridSearchCV._run_search']  \n",
       "2                                                                                                                ['HalvingRandomSearchCV._generate_candidate_params']  \n",
       "3     ['DummyClassifier.predict_proba', '_ConstantPredictor.predict_proba', 'OneVsRestClassifier.predict_proba', 'MultiOutputClassifier.predict_proba', 'Pipeline....  \n",
       "4                                                                                                                                                                  []  \n",
       "...                                                                                                                                                               ...  \n",
       "4793                                                                                                                                                               []  \n",
       "4794  ['RBFSampler.transform', 'AdditiveChi2Sampler.transform', 'Nystroem.transform', 'Pipeline.fit_transform', 'Pipeline.transform', 'FeatureUnion.fit_transform'...  \n",
       "4795                                                                                                                                                               []  \n",
       "4796                                                                                                                                                               []  \n",
       "4797                                                                                                                                                               []  \n",
       "\n",
       "[4798 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pd.read_csv(\"stackowerQnA_context.csv\", sep=\",\", on_bad_lines='warn', engine='python')\n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae6a2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ context column ready: I have recently noticed that when I change the order of the observations in a sparse array, scikit-learn PCA with svd_solver=\"arpack\" returns different floating point numbers. Is this an expected beha\n",
      "üìä Golden context coverage: 0.23280533555648186 have function names\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "qa_stack = qa.copy()\n",
    "\n",
    "# --- 1Ô∏è‚É£ HTML sz√∂vegek megtiszt√≠t√°sa ---\n",
    "def clean_html(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text(\" \", strip=True)\n",
    "\n",
    "qa_stack[\"q_clean\"] = qa_stack[\"questions\"].apply(clean_html)\n",
    "qa_stack[\"a_clean\"] = qa_stack[\"answers\"].apply(clean_html)\n",
    "\n",
    "# --- 2Ô∏è‚É£ Kontextusos k√©rd√©s-sz√∂veg l√©trehoz√°sa ---\n",
    "qa_stack[\"context\"] = (\n",
    "    qa_stack[\"q_clean\"].fillna('') + \" \" + qa_stack[\"a_clean\"].fillna('')\n",
    ").str.strip()\n",
    "\n",
    "print(\"‚úÖ context column ready:\", qa_stack[\"context\"].iloc[0][:200])\n",
    "\n",
    "# --- 3Ô∏è‚É£ A 'contexts' oszlop feldolgoz√°sa ---\n",
    "# pl. \"['GridSearchCV._run_search']\" ‚Üí ['GridSearchCV._run_search']\n",
    "qa_stack[\"contexts\"] = qa_stack[\"contexts\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else []\n",
    ")\n",
    "\n",
    "print(\"üìä Golden context coverage:\", (qa_stack[\"contexts\"].str.len() > 0).mean(), \"have function names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "641bb8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created pos_function_idx tensor: torch.Size([4798])\n",
      "‚ö†Ô∏è 0 questions had no matching function in the graph.\n",
      "üìà Match rate: 100.00%\n",
      "‚úÖ Filtered valid QA pairs: 1117 remaining.\n",
      "üíæ Saved pos_function_idx_stack.pt and qa_stack_valid.csv\n",
      "üíæ Saved pos_function_idx_stack.pt and qa_stack_valid.csv\n"
     ]
    }
   ],
   "source": [
    "# %% -------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Map golden context function names ‚Üí node indices in graph\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "\n",
    "# Create lookup dictionary for function names ‚Üí node indices\n",
    "fn_name_to_idx = {\n",
    "    name: i for i, name in enumerate(repograph[\"function_nodes\"][\"combinedName\"].fillna(\"\").tolist())\n",
    "}\n",
    "\n",
    "pos_function_idx = []\n",
    "unmatched = 0\n",
    "\n",
    "for contexts in qa_stack[\"contexts\"]:\n",
    "    if not contexts:  # √ºres lista\n",
    "        pos_function_idx.append(-1)\n",
    "        continue\n",
    "\n",
    "    # Use the first known function name that exists in the graph\n",
    "    found_idx = None\n",
    "    for c in contexts:\n",
    "        if c in fn_name_to_idx:\n",
    "            found_idx = fn_name_to_idx[c]\n",
    "            break\n",
    "\n",
    "    if found_idx is not None:\n",
    "        pos_function_idx.append(found_idx)\n",
    "    else:\n",
    "        pos_function_idx.append(-1)\n",
    "        unmatched += 1\n",
    "\n",
    "pos_function_idx = torch.tensor(pos_function_idx, dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"‚úÖ Created pos_function_idx tensor: {pos_function_idx.shape}\")\n",
    "print(f\"‚ö†Ô∏è {unmatched} questions had no matching function in the graph.\")\n",
    "print(f\"üìà Match rate: {(1 - unmatched/len(pos_function_idx)) * 100:.2f}%\")\n",
    "\n",
    "# Optional: filter QA pairs that have valid matches only\n",
    "mask_valid = pos_function_idx >= 0\n",
    "qa_stack_valid = qa_stack[mask_valid.cpu().numpy()].reset_index(drop=True)\n",
    "pos_function_idx = pos_function_idx[mask_valid]\n",
    "print(f\"‚úÖ Filtered valid QA pairs: {len(qa_stack_valid)} remaining.\")\n",
    "\n",
    "# Save for reuse\n",
    "torch.save(pos_function_idx, \"pos_function_idx_stack.pt\")\n",
    "qa_stack_valid.to_csv(\"qa_stack_valid.csv\", index=False)\n",
    "print(\"üíæ Saved pos_function_idx_stack.pt and qa_stack_valid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea553e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Encoded 1117 QA pairs ‚Üí shape: torch.Size([1117, 384])\n",
      "üìò Using 1117 golden QA pairs for training\n",
      "Epoch 01 | loss = 3.8803\n",
      "Epoch 01 | loss = 3.8803\n",
      "Epoch 02 | loss = 3.8498\n",
      "Epoch 02 | loss = 3.8498\n",
      "Epoch 03 | loss = 3.8668\n",
      "Epoch 03 | loss = 3.8668\n",
      "Epoch 04 | loss = 3.8324\n",
      "Epoch 04 | loss = 3.8324\n",
      "Epoch 05 | loss = 3.7753\n",
      "Epoch 05 | loss = 3.7753\n",
      "Epoch 06 | loss = 3.8437\n",
      "Epoch 06 | loss = 3.8437\n",
      "Epoch 07 | loss = 3.8066\n",
      "Epoch 07 | loss = 3.8066\n",
      "Epoch 08 | loss = 3.7691\n",
      "Epoch 08 | loss = 3.7691\n",
      "Epoch 09 | loss = 3.8327\n",
      "Epoch 09 | loss = 3.8327\n",
      "Epoch 10 | loss = 3.8012\n",
      "Epoch 10 | loss = 3.8012\n",
      "Epoch 11 | loss = 3.8083\n",
      "Epoch 11 | loss = 3.8083\n",
      "Epoch 12 | loss = 3.7970\n",
      "Epoch 12 | loss = 3.7970\n",
      "Epoch 13 | loss = 3.8131\n",
      "Epoch 13 | loss = 3.8131\n",
      "Epoch 14 | loss = 3.7930\n",
      "Epoch 14 | loss = 3.7930\n",
      "Epoch 15 | loss = 3.8307\n",
      "Epoch 15 | loss = 3.8307\n",
      "Epoch 16 | loss = 3.7856\n",
      "Epoch 16 | loss = 3.7856\n",
      "Epoch 17 | loss = 3.7512\n",
      "Epoch 17 | loss = 3.7512\n",
      "Epoch 18 | loss = 3.7401\n",
      "Epoch 18 | loss = 3.7401\n",
      "Epoch 19 | loss = 3.7767\n",
      "Epoch 19 | loss = 3.7767\n",
      "Epoch 20 | loss = 3.7611\n",
      "Epoch 20 | loss = 3.7611\n",
      "Epoch 21 | loss = 3.7812\n",
      "Epoch 21 | loss = 3.7812\n",
      "Epoch 22 | loss = 3.7269\n",
      "Epoch 22 | loss = 3.7269\n",
      "Epoch 23 | loss = 3.7389\n",
      "Epoch 23 | loss = 3.7389\n",
      "Epoch 24 | loss = 3.7264\n",
      "Epoch 24 | loss = 3.7264\n",
      "Epoch 25 | loss = 3.7132\n",
      "Epoch 25 | loss = 3.7132\n",
      "Epoch 26 | loss = 3.7551\n",
      "Epoch 26 | loss = 3.7551\n",
      "Epoch 27 | loss = 3.7433\n",
      "Epoch 27 | loss = 3.7433\n",
      "Epoch 28 | loss = 3.7167\n",
      "Epoch 28 | loss = 3.7167\n",
      "Epoch 29 | loss = 3.6989\n",
      "Epoch 29 | loss = 3.6989\n",
      "Epoch 30 | loss = 3.7167\n",
      "Epoch 30 | loss = 3.7167\n",
      "Epoch 31 | loss = 3.7443\n",
      "Epoch 31 | loss = 3.7443\n",
      "Epoch 32 | loss = 3.7012\n",
      "Epoch 32 | loss = 3.7012\n",
      "Epoch 33 | loss = 3.7144\n",
      "Epoch 33 | loss = 3.7144\n",
      "Epoch 34 | loss = 3.7138\n",
      "Epoch 34 | loss = 3.7138\n",
      "Epoch 35 | loss = 3.6631\n",
      "Epoch 35 | loss = 3.6631\n",
      "Epoch 36 | loss = 3.7316\n",
      "Epoch 36 | loss = 3.7316\n",
      "Epoch 37 | loss = 3.6936\n",
      "Epoch 37 | loss = 3.6936\n",
      "Epoch 38 | loss = 3.6825\n",
      "Epoch 38 | loss = 3.6825\n",
      "Epoch 39 | loss = 3.6799\n",
      "Epoch 39 | loss = 3.6799\n",
      "Epoch 40 | loss = 3.7288\n",
      "Epoch 40 | loss = 3.7288\n",
      "Epoch 41 | loss = 3.7356\n",
      "Epoch 41 | loss = 3.7356\n",
      "Epoch 42 | loss = 3.6502\n",
      "Epoch 42 | loss = 3.6502\n",
      "Epoch 43 | loss = 3.6827\n",
      "Epoch 43 | loss = 3.6827\n",
      "Epoch 44 | loss = 3.6882\n",
      "Epoch 44 | loss = 3.6882\n",
      "Epoch 45 | loss = 3.7229\n",
      "Epoch 45 | loss = 3.7229\n",
      "Epoch 46 | loss = 3.6659\n",
      "Epoch 46 | loss = 3.6659\n",
      "Epoch 47 | loss = 3.6851\n",
      "Epoch 47 | loss = 3.6851\n",
      "Epoch 48 | loss = 3.6560\n",
      "Epoch 48 | loss = 3.6560\n",
      "Epoch 49 | loss = 3.6779\n",
      "Epoch 49 | loss = 3.6779\n",
      "Epoch 50 | loss = 3.7235\n",
      "Epoch 50 | loss = 3.7235\n",
      "Epoch 51 | loss = 3.6458\n",
      "Epoch 51 | loss = 3.6458\n",
      "Epoch 52 | loss = 3.6253\n",
      "Epoch 52 | loss = 3.6253\n",
      "Epoch 53 | loss = 3.6161\n",
      "Epoch 53 | loss = 3.6161\n",
      "Epoch 54 | loss = 3.6076\n",
      "Epoch 54 | loss = 3.6076\n",
      "Epoch 55 | loss = 3.6165\n",
      "Epoch 55 | loss = 3.6165\n",
      "Epoch 56 | loss = 3.6282\n",
      "Epoch 56 | loss = 3.6282\n",
      "Epoch 57 | loss = 3.6317\n",
      "Epoch 57 | loss = 3.6317\n",
      "Epoch 58 | loss = 3.6508\n",
      "Epoch 58 | loss = 3.6508\n",
      "Epoch 59 | loss = 3.6375\n",
      "Epoch 59 | loss = 3.6375\n",
      "Epoch 60 | loss = 3.6346\n",
      "Epoch 60 | loss = 3.6346\n",
      "Epoch 61 | loss = 3.6371\n",
      "Epoch 61 | loss = 3.6371\n",
      "Epoch 62 | loss = 3.6131\n",
      "Epoch 62 | loss = 3.6131\n",
      "Epoch 63 | loss = 3.6409\n",
      "Epoch 63 | loss = 3.6409\n",
      "Epoch 64 | loss = 3.6241\n",
      "Epoch 64 | loss = 3.6241\n",
      "Epoch 65 | loss = 3.5971\n",
      "Epoch 65 | loss = 3.5971\n",
      "Epoch 66 | loss = 3.6285\n",
      "Epoch 66 | loss = 3.6285\n",
      "Epoch 67 | loss = 3.6089\n",
      "Epoch 67 | loss = 3.6089\n",
      "Epoch 68 | loss = 3.6065\n",
      "Epoch 68 | loss = 3.6065\n",
      "Epoch 69 | loss = 3.6024\n",
      "Epoch 69 | loss = 3.6024\n",
      "Epoch 70 | loss = 3.6371\n",
      "Epoch 70 | loss = 3.6371\n",
      "Epoch 71 | loss = 3.6058\n",
      "Epoch 71 | loss = 3.6058\n",
      "Epoch 72 | loss = 3.6036\n",
      "Epoch 72 | loss = 3.6036\n",
      "Epoch 73 | loss = 3.6022\n",
      "Epoch 73 | loss = 3.6022\n",
      "Epoch 74 | loss = 3.5991\n",
      "Epoch 74 | loss = 3.5991\n",
      "Epoch 75 | loss = 3.6209\n",
      "Epoch 75 | loss = 3.6209\n",
      "Epoch 76 | loss = 3.6159\n",
      "Epoch 76 | loss = 3.6159\n",
      "Epoch 77 | loss = 3.5989\n",
      "Epoch 77 | loss = 3.5989\n",
      "Epoch 78 | loss = 3.5857\n",
      "Epoch 78 | loss = 3.5857\n",
      "Epoch 79 | loss = 3.5801\n",
      "Epoch 79 | loss = 3.5801\n",
      "Epoch 80 | loss = 3.5509\n",
      "Epoch 80 | loss = 3.5509\n",
      "Epoch 81 | loss = 3.6518\n",
      "Epoch 81 | loss = 3.6518\n",
      "Epoch 82 | loss = 3.6076\n",
      "Epoch 82 | loss = 3.6076\n",
      "Epoch 83 | loss = 3.6184\n",
      "Epoch 83 | loss = 3.6184\n",
      "Epoch 84 | loss = 3.5589\n",
      "Epoch 84 | loss = 3.5589\n",
      "Epoch 85 | loss = 3.5713\n",
      "Epoch 85 | loss = 3.5713\n",
      "Epoch 86 | loss = 3.5558\n",
      "Epoch 86 | loss = 3.5558\n",
      "Epoch 87 | loss = 3.6245\n",
      "Epoch 87 | loss = 3.6245\n",
      "Epoch 88 | loss = 3.5453\n",
      "Epoch 88 | loss = 3.5453\n",
      "Epoch 89 | loss = 3.5814\n",
      "Epoch 89 | loss = 3.5814\n",
      "Epoch 90 | loss = 3.5667\n",
      "Epoch 90 | loss = 3.5667\n",
      "Epoch 91 | loss = 3.5932\n",
      "Epoch 91 | loss = 3.5932\n",
      "Epoch 92 | loss = 3.5754\n",
      "Epoch 92 | loss = 3.5754\n",
      "Epoch 93 | loss = 3.5373\n",
      "Epoch 93 | loss = 3.5373\n",
      "Epoch 94 | loss = 3.5571\n",
      "Epoch 94 | loss = 3.5571\n",
      "Epoch 95 | loss = 3.5264\n",
      "Epoch 95 | loss = 3.5264\n",
      "Epoch 96 | loss = 3.5472\n",
      "Epoch 96 | loss = 3.5472\n",
      "Epoch 97 | loss = 3.5239\n",
      "Epoch 97 | loss = 3.5239\n",
      "Epoch 98 | loss = 3.5437\n",
      "Epoch 98 | loss = 3.5437\n",
      "Epoch 99 | loss = 3.5501\n",
      "Epoch 99 | loss = 3.5501\n",
      "Epoch 100 | loss = 3.5371\n",
      "Epoch 100 | loss = 3.5371\n",
      "Epoch 101 | loss = 3.5431\n",
      "Epoch 101 | loss = 3.5431\n",
      "Epoch 102 | loss = 3.5361\n",
      "Epoch 102 | loss = 3.5361\n",
      "Epoch 103 | loss = 3.5371\n",
      "Epoch 103 | loss = 3.5371\n",
      "Epoch 104 | loss = 3.5428\n",
      "Epoch 104 | loss = 3.5428\n",
      "Epoch 105 | loss = 3.5057\n",
      "Epoch 105 | loss = 3.5057\n",
      "Epoch 106 | loss = 3.5467\n",
      "Epoch 106 | loss = 3.5467\n",
      "Epoch 107 | loss = 3.5814\n",
      "Epoch 107 | loss = 3.5814\n",
      "Epoch 108 | loss = 3.5120\n",
      "Epoch 108 | loss = 3.5120\n",
      "Epoch 109 | loss = 3.5316\n",
      "Epoch 109 | loss = 3.5316\n",
      "Epoch 110 | loss = 3.5355\n",
      "Epoch 110 | loss = 3.5355\n",
      "Epoch 111 | loss = 3.5112\n",
      "Epoch 111 | loss = 3.5112\n",
      "Epoch 112 | loss = 3.4797\n",
      "Epoch 112 | loss = 3.4797\n",
      "Epoch 113 | loss = 3.4778\n",
      "Epoch 113 | loss = 3.4778\n",
      "Epoch 114 | loss = 3.5155\n",
      "Epoch 114 | loss = 3.5155\n",
      "Epoch 115 | loss = 3.5267\n",
      "Epoch 115 | loss = 3.5267\n",
      "Epoch 116 | loss = 3.5262\n",
      "Epoch 116 | loss = 3.5262\n",
      "Epoch 117 | loss = 3.5153\n",
      "Epoch 117 | loss = 3.5153\n",
      "Epoch 118 | loss = 3.5000\n",
      "Epoch 118 | loss = 3.5000\n",
      "Epoch 119 | loss = 3.4907\n",
      "Epoch 119 | loss = 3.4907\n",
      "Epoch 120 | loss = 3.5061\n",
      "Epoch 120 | loss = 3.5061\n",
      "Epoch 121 | loss = 3.5160\n",
      "Epoch 121 | loss = 3.5160\n",
      "Epoch 122 | loss = 3.5189\n",
      "Epoch 122 | loss = 3.5189\n",
      "Epoch 123 | loss = 3.5438\n",
      "Epoch 123 | loss = 3.5438\n",
      "Epoch 124 | loss = 3.5243\n",
      "Epoch 124 | loss = 3.5243\n",
      "Epoch 125 | loss = 3.5169\n",
      "Epoch 125 | loss = 3.5169\n",
      "Epoch 126 | loss = 3.5013\n",
      "Epoch 126 | loss = 3.5013\n",
      "Epoch 127 | loss = 3.5400\n",
      "Epoch 127 | loss = 3.5400\n",
      "Epoch 128 | loss = 3.5072\n",
      "Epoch 128 | loss = 3.5072\n",
      "Epoch 129 | loss = 3.4607\n",
      "Epoch 129 | loss = 3.4607\n",
      "Epoch 130 | loss = 3.4584\n",
      "Epoch 130 | loss = 3.4584\n",
      "Epoch 131 | loss = 3.5094\n",
      "Epoch 131 | loss = 3.5094\n",
      "Epoch 132 | loss = 3.5143\n",
      "Epoch 132 | loss = 3.5143\n",
      "Epoch 133 | loss = 3.5036\n",
      "Epoch 133 | loss = 3.5036\n",
      "Epoch 134 | loss = 3.5188\n",
      "Epoch 134 | loss = 3.5188\n",
      "Epoch 135 | loss = 3.5585\n",
      "Epoch 135 | loss = 3.5585\n",
      "Epoch 136 | loss = 3.4997\n",
      "Epoch 136 | loss = 3.4997\n",
      "Epoch 137 | loss = 3.4704\n",
      "Epoch 137 | loss = 3.4704\n",
      "Epoch 138 | loss = 3.5118\n",
      "Epoch 138 | loss = 3.5118\n",
      "Epoch 139 | loss = 3.4815\n",
      "Epoch 139 | loss = 3.4815\n",
      "Epoch 140 | loss = 3.4406\n",
      "Epoch 140 | loss = 3.4406\n",
      "Epoch 141 | loss = 3.5314\n",
      "Epoch 141 | loss = 3.5314\n",
      "Epoch 142 | loss = 3.4687\n",
      "Epoch 142 | loss = 3.4687\n",
      "Epoch 143 | loss = 3.4590\n",
      "Epoch 143 | loss = 3.4590\n",
      "Epoch 144 | loss = 3.4646\n",
      "Epoch 144 | loss = 3.4646\n",
      "Epoch 145 | loss = 3.5151\n",
      "Epoch 145 | loss = 3.5151\n",
      "Epoch 146 | loss = 3.4675\n",
      "Epoch 146 | loss = 3.4675\n",
      "Epoch 147 | loss = 3.4542\n",
      "Epoch 147 | loss = 3.4542\n",
      "Epoch 148 | loss = 3.5119\n",
      "Epoch 148 | loss = 3.5119\n",
      "Epoch 149 | loss = 3.4796\n",
      "Epoch 149 | loss = 3.4796\n",
      "Epoch 150 | loss = 3.4703\n",
      "Epoch 150 | loss = 3.4703\n",
      "Epoch 151 | loss = 3.4619\n",
      "Epoch 151 | loss = 3.4619\n",
      "Epoch 152 | loss = 3.4386\n",
      "Epoch 152 | loss = 3.4386\n",
      "Epoch 153 | loss = 3.4874\n",
      "Epoch 153 | loss = 3.4874\n",
      "Epoch 154 | loss = 3.4774\n",
      "Epoch 154 | loss = 3.4774\n",
      "Epoch 155 | loss = 3.4496\n",
      "Epoch 155 | loss = 3.4496\n",
      "Epoch 156 | loss = 3.4661\n",
      "Epoch 156 | loss = 3.4661\n",
      "Epoch 157 | loss = 3.4724\n",
      "Epoch 157 | loss = 3.4724\n",
      "Epoch 158 | loss = 3.4636\n",
      "Epoch 158 | loss = 3.4636\n",
      "Epoch 159 | loss = 3.4769\n",
      "Epoch 159 | loss = 3.4769\n",
      "Epoch 160 | loss = 3.4873\n",
      "Epoch 160 | loss = 3.4873\n",
      "Epoch 161 | loss = 3.4477\n",
      "Epoch 161 | loss = 3.4477\n",
      "Epoch 162 | loss = 3.4539\n",
      "Epoch 162 | loss = 3.4539\n",
      "Epoch 163 | loss = 3.4178\n",
      "Epoch 163 | loss = 3.4178\n",
      "Epoch 164 | loss = 3.4561\n",
      "Epoch 164 | loss = 3.4561\n",
      "Epoch 165 | loss = 3.4372\n",
      "Epoch 165 | loss = 3.4372\n",
      "Epoch 166 | loss = 3.4598\n",
      "Epoch 166 | loss = 3.4598\n",
      "Epoch 167 | loss = 3.4314\n",
      "Epoch 167 | loss = 3.4314\n",
      "Epoch 168 | loss = 3.4566\n",
      "Epoch 168 | loss = 3.4566\n",
      "Epoch 169 | loss = 3.4512\n",
      "Epoch 169 | loss = 3.4512\n",
      "Epoch 170 | loss = 3.4406\n",
      "Epoch 170 | loss = 3.4406\n",
      "Epoch 171 | loss = 3.4401\n",
      "Epoch 171 | loss = 3.4401\n",
      "Epoch 172 | loss = 3.4138\n",
      "Epoch 172 | loss = 3.4138\n",
      "Epoch 173 | loss = 3.4774\n",
      "Epoch 173 | loss = 3.4774\n",
      "Epoch 174 | loss = 3.4045\n",
      "Epoch 174 | loss = 3.4045\n",
      "Epoch 175 | loss = 3.4094\n",
      "Epoch 175 | loss = 3.4094\n",
      "Epoch 176 | loss = 3.4643\n",
      "Epoch 176 | loss = 3.4643\n",
      "Epoch 177 | loss = 3.4191\n",
      "Epoch 177 | loss = 3.4191\n",
      "Epoch 178 | loss = 3.4986\n",
      "Epoch 178 | loss = 3.4986\n",
      "Epoch 179 | loss = 3.4227\n",
      "Epoch 179 | loss = 3.4227\n",
      "Epoch 180 | loss = 3.4222\n",
      "Epoch 180 | loss = 3.4222\n",
      "Epoch 181 | loss = 3.4470\n",
      "Epoch 181 | loss = 3.4470\n",
      "Epoch 182 | loss = 3.4467\n",
      "Epoch 182 | loss = 3.4467\n",
      "Epoch 183 | loss = 3.4336\n",
      "Epoch 183 | loss = 3.4336\n",
      "Epoch 184 | loss = 3.4399\n",
      "Epoch 184 | loss = 3.4399\n",
      "Epoch 185 | loss = 3.4107\n",
      "Epoch 185 | loss = 3.4107\n",
      "Epoch 186 | loss = 3.4185\n",
      "Epoch 186 | loss = 3.4185\n",
      "Epoch 187 | loss = 3.4477\n",
      "Epoch 187 | loss = 3.4477\n",
      "Epoch 188 | loss = 3.4381\n",
      "Epoch 188 | loss = 3.4381\n",
      "Epoch 189 | loss = 3.4197\n",
      "Epoch 189 | loss = 3.4197\n",
      "Epoch 190 | loss = 3.3851\n",
      "Epoch 190 | loss = 3.3851\n",
      "Epoch 191 | loss = 3.4304\n",
      "Epoch 191 | loss = 3.4304\n",
      "Epoch 192 | loss = 3.4183\n",
      "Epoch 192 | loss = 3.4183\n",
      "Epoch 193 | loss = 3.4258\n",
      "Epoch 193 | loss = 3.4258\n",
      "Epoch 194 | loss = 3.3970\n",
      "Epoch 194 | loss = 3.3970\n",
      "Epoch 195 | loss = 3.4118\n",
      "Epoch 195 | loss = 3.4118\n",
      "Epoch 196 | loss = 3.4046\n",
      "Epoch 196 | loss = 3.4046\n",
      "Epoch 197 | loss = 3.4522\n",
      "Epoch 197 | loss = 3.4522\n",
      "Epoch 198 | loss = 3.4158\n",
      "Epoch 198 | loss = 3.4158\n",
      "Epoch 199 | loss = 3.4220\n",
      "Epoch 199 | loss = 3.4220\n",
      "Epoch 200 | loss = 3.4448\n",
      "Epoch 200 | loss = 3.4448\n"
     ]
    }
   ],
   "source": [
    "# %% ------------------------------------------------------------\n",
    "# Train GNN using golden StackOverflow QA supervision\n",
    "# ---------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Load valid QA pairs\n",
    "qa_stack_valid = pd.read_csv(\"qa_stack_valid.csv\")\n",
    "pos_function_idx = torch.load(\"pos_function_idx_stack.pt\").to(device)\n",
    "\n",
    "# SentenceTransformer model (same as before)\n",
    "qa_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# Context = k√©rd√©s + v√°lasz\n",
    "qa_texts = (qa_stack_valid[\"questions\"].fillna(\"\") + \" \" +\n",
    "             qa_stack_valid[\"answers\"].fillna(\"\")).str.strip()\n",
    "\n",
    "# Encode embeddings\n",
    "q_emb = qa_encoder.encode(qa_texts.tolist(), convert_to_tensor=True, device=device)\n",
    "print(f\"‚úÖ Encoded {len(q_emb)} QA pairs ‚Üí shape: {q_emb.shape}\")\n",
    "\n",
    "# Align lengths\n",
    "n_q = min(len(q_emb), len(pos_function_idx))\n",
    "q_emb = q_emb[:n_q]\n",
    "pos_function_idx = pos_function_idx[:n_q]\n",
    "\n",
    "indices = torch.arange(n_q, device=device)\n",
    "print(f\"üìò Using {n_q} golden QA pairs for training\")\n",
    "\n",
    "# --- InfoNCE loss ---\n",
    "def info_nce(q, items, pos_index, temperature=0.07):\n",
    "    q = F.normalize(q, dim=-1)\n",
    "    items = F.normalize(items, dim=-1)\n",
    "    logits = q @ items.T / temperature\n",
    "    return F.cross_entropy(logits, pos_index.to(q.device)), logits\n",
    "\n",
    "# --- Training loop ---\n",
    "EPOCHS = 200\n",
    "BATCH = 64\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    perm = indices[torch.randperm(len(indices))]\n",
    "    num_batches = math.ceil(len(perm) / BATCH)\n",
    "\n",
    "    for start in range(0, len(perm), BATCH):\n",
    "        idx = perm[start:start+BATCH]\n",
    "        q_batch = q_emb[idx]\n",
    "        pos_batch = pos_function_idx[idx]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        func_emb = F.normalize(model(data.x.to(device), data.edge_index.to(device)), dim=-1)\n",
    "\n",
    "        loss, _ = info_nce(q_batch, func_emb, pos_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch:02d} | loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "127afa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Function embeddings shape: torch.Size([11128, 384])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ugyanaz az encoder, amit a tan√≠t√°sn√°l is haszn√°ltunk\n",
    "qa_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_function_embeddings():\n",
    "    \"\"\"Lek√©rdezi √©s normaliz√°lja a GNN √°ltal tanult function node embeddingeket.\"\"\"\n",
    "    func_emb = model(data.x.to(device), data.edge_index.to(device))\n",
    "    func_emb = F.normalize(func_emb, dim=-1)\n",
    "    print(f\"‚úÖ Function embeddings shape: {func_emb.shape}\")\n",
    "    return func_emb\n",
    "\n",
    "function_emb = get_function_embeddings()\n",
    "\n",
    "def ask(question: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    K√©rd√©s megv√°laszol√°sa a GNN + text encoder alapj√°n.\n",
    "    Kisz√°molja a hasonl√≥s√°got a k√©rd√©s embeddingje √©s a function node embeddingek k√∂z√∂tt.\n",
    "    \"\"\"\n",
    "    # K√©rd√©s embeddingje\n",
    "    q_vec = qa_encoder.encode([question], convert_to_tensor=True).to(device)\n",
    "    q_vec = F.normalize(q_vec, dim=-1)\n",
    "\n",
    "    # Cosine-similarit√°s\n",
    "    sim = q_vec @ function_emb.T\n",
    "    top_vals, top_idx = torch.topk(sim, k)\n",
    "\n",
    "    print(f\"\\n‚ùì Question: {question}\\n\")\n",
    "    print(\"Top-k related functions:\\n\")\n",
    "    for rank, (fid, score) in enumerate(zip(top_idx[0].tolist(), top_vals[0].tolist()), start=1):\n",
    "        name = repograph[\"function_nodes\"][\"combinedName\"].iloc[fid]\n",
    "        doc = repograph[\"function_nodes\"][\"docstring\"].iloc[fid]\n",
    "        print(f\"{rank:>2}. {name} (score={score:.4f})\")\n",
    "        print(f\"   {doc[:200]}{'...' if len(doc)>200 else ''}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1fa7c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ----------------------- RAG over GNN functions -----------------------\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- El≈ëfelt√©telek (ezeknek m√°r l√©tezni√ºk kell a notebookodban) ---\n",
    "# - model: a betan√≠tott FunctionGNN (forward(x, edge_index) -> [N, D])\n",
    "# - data: PyG Data(x=[N,384], edge_index=[2,E])\n",
    "# - repograph[\"function_nodes\"]: DataFrame (combinedName, docstring, ...)\n",
    "# - qa_stack_valid: DataFrame a StackOverflow QA-kkal (questions, answers, contexts)\n",
    "# - device: \"cuda\" vagy \"cpu\"\n",
    "# - qa_encoder: SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "def _ensure_func_emb_cache():\n",
    "    \"\"\"Sz√°molja √©s cache-eli a normaliz√°lt function embeddingeket (GNN output).\"\"\"\n",
    "    global _FUNC_EMB_CACHE\n",
    "    if \"_FUNC_EMB_CACHE\" not in globals() or _FUNC_EMB_CACHE is None:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            emb = model(data.x.to(device), data.edge_index.to(device))      # [N, D]\n",
    "            emb = F.normalize(emb, dim=-1)\n",
    "        _FUNC_EMB_CACHE = emb\n",
    "    return _FUNC_EMB_CACHE\n",
    "\n",
    "def _sent_tokenize(text: str, max_sent=6):\n",
    "    \"\"\"Nagyon egyszer≈± mondat-szeletel≈ë, fallback arra, ha nincs nltk.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    # darabol√°s pont/k√©rd≈ëjel/felki√°lt√≥jel ment√©n\n",
    "    parts = re.split(r'(?<=[\\.\\?\\!])\\s+', text.strip())\n",
    "    return [s.strip() for s in parts if s.strip()][:max_sent]\n",
    "\n",
    "def _gather_function_contexts(func_name: str, top_rows=6):\n",
    "    \"\"\"\n",
    "    Kikeresi a qa_stack_valid sorait, ahol a contexts oszlop tartalmazza a func_name-t.\n",
    "    Visszaad (row_idx, question_text, answer_text) tripl√°kat.\n",
    "    \"\"\"\n",
    "    if \"contexts\" not in qa_stack_valid.columns:\n",
    "        return []\n",
    "    hits = []\n",
    "    # contexts oszlop list√°kat tartalmaz (pl. ['GridSearchCV._run_search', ...])\n",
    "    for i, ctx_list in enumerate(qa_stack_valid[\"contexts\"]):\n",
    "        try:\n",
    "            if isinstance(ctx_list, str):\n",
    "                # ha valami√©rt stringk√©nt maradt, pr√≥b√°ljuk list√°v√°\n",
    "                ctx_list = eval(ctx_list)  # a datasetet m√°r megtiszt√≠tottad kor√°bban\n",
    "        except Exception:\n",
    "            ctx_list = []\n",
    "        if isinstance(ctx_list, (list, tuple)) and func_name in ctx_list:\n",
    "            q = qa_stack_valid.loc[i, \"questions\"]\n",
    "            a = qa_stack_valid.loc[i, \"answers\"]\n",
    "            hits.append((i, q, a))\n",
    "            if len(hits) >= top_rows:\n",
    "                break\n",
    "    return hits\n",
    "\n",
    "@torch.no_grad()\n",
    "def ask_rag(question: str, k_funcs: int = 10, k_ctx: int = 5, max_snips_per_source: int = 2):\n",
    "    \"\"\"\n",
    "    RAG pipeline:\n",
    "      1) top-k function jel√∂lt a GNN embeddingekkel,\n",
    "      2) ezekhez docstring + StackOverflow context gy≈±jt√©se,\n",
    "      3) √∫jrarangsorol√°s a k√©rd√©shez k√©pest (MiniLM),\n",
    "      4) r√∂vid v√°lasz + forr√°sok.\n",
    "    \"\"\"\n",
    "    # 1) K√©rd√©s embedding\n",
    "    q_vec = qa_encoder.encode([question], convert_to_tensor=True).to(device)\n",
    "    q_vec = F.normalize(q_vec, dim=-1)  # [1, 384]\n",
    "\n",
    "    # 2) top-k function jel√∂ltek a GNN-b≈ël\n",
    "    func_emb = _ensure_func_emb_cache()               # [N, D]\n",
    "    sim = (q_vec @ func_emb.T).squeeze(0)            # [N]\n",
    "    vals, idxs = torch.topk(sim, k=min(k_funcs, func_emb.size(0)))\n",
    "    idxs = idxs.tolist()\n",
    "    vals = vals.tolist()\n",
    "\n",
    "    # 3) Kontextek √∂sszegy≈±jt√©se (docstring + SO QA)\n",
    "    fn_df = repograph[\"function_nodes\"]\n",
    "    cand_contexts = []\n",
    "    for rank, (fid, score) in enumerate(zip(idxs, vals), start=1):\n",
    "        row = fn_df.iloc[fid]\n",
    "        fname = row.get(\"combinedName\", f\"Function_{fid}\")\n",
    "        doc = row.get(\"docstring\", \"\") or \"\"\n",
    "        # docstringb≈ël mondatok\n",
    "        doc_sents = _sent_tokenize(doc, max_sent=6)\n",
    "\n",
    "        # SO kontextusok (k√©rd√©s+v√°lasz), ahol ez a function szerepel a contexts-ben\n",
    "        so_hits = _gather_function_contexts(fname, top_rows=k_ctx)\n",
    "\n",
    "        # minden forr√°st k√ºl√∂n elemk√©nt t√°rolunk (sz√∂veg + meta)\n",
    "        if doc_sents:\n",
    "            cand_contexts.append({\n",
    "                \"type\": \"docstring\",\n",
    "                \"function_id\": fid,\n",
    "                \"function_name\": fname,\n",
    "                \"text\": \" \".join(doc_sents),\n",
    "                \"source\": f\"docstring:{fname}\"\n",
    "            })\n",
    "        for (row_id, q_html, a_html) in so_hits:\n",
    "            # nagyon alap HTML ‚Üí plain text (ha nem tiszt√≠tottad kor√°bban)\n",
    "            q_plain = re.sub(\"<[^>]+>\", \" \", q_html or \"\")\n",
    "            a_plain = re.sub(\"<[^>]+>\", \" \", a_html or \"\")\n",
    "            joined = (q_plain + \" \" + a_plain).strip()\n",
    "            if joined:\n",
    "                # v√°gjunk ki mondatokat, hogy t√∂m√∂rebb legyen\n",
    "                snips = _sent_tokenize(joined, max_sent=6)\n",
    "                if snips:\n",
    "                    cand_contexts.append({\n",
    "                        \"type\": \"stack_overflow\",\n",
    "                        \"function_id\": fid,\n",
    "                        \"function_name\": fname,\n",
    "                        \"text\": \" \".join(snips[:max_snips_per_source]),\n",
    "                        \"source\": f\"SO row {row_id} (contexts contains {fname})\"\n",
    "                    })\n",
    "\n",
    "    if not cand_contexts:\n",
    "        print(\"‚ö†Ô∏è Nem tal√°ltam felhaszn√°lhat√≥ kontextust. Visszaadom a top-k function-√∂ket debugra.\")\n",
    "        return {\n",
    "            \"answer\": \"\",\n",
    "            \"functions\": [(fn_df.iloc[fid].get(\"combinedName\", f\"Function_{fid}\"), score) for fid, score in zip(idxs, vals)],\n",
    "            \"sources\": []\n",
    "        }\n",
    "\n",
    "    # 4) √öjrarangsorol√°s a k√©rd√©shez k√©pest (MiniLM)\n",
    "    ctx_texts = [c[\"text\"] for c in cand_contexts]\n",
    "    ctx_emb = qa_encoder.encode(ctx_texts, convert_to_tensor=True, device=device)\n",
    "    ctx_emb = F.normalize(ctx_emb, dim=-1)\n",
    "    rel = (q_vec @ ctx_emb.T).squeeze(0)  # [M]\n",
    "    top_rel_vals, top_rel_idx = torch.topk(rel, k=min(8, rel.size(0)))  # 8 kontextust visz√ºnk tov√°bb\n",
    "    top_rel_idx = top_rel_idx.tolist()\n",
    "    top_rel_vals = top_rel_vals.tolist()\n",
    "\n",
    "    top_contexts = [cand_contexts[i] for i in top_rel_idx]\n",
    "\n",
    "    # 5) Egyszer≈± v√°lasz-√∂ssze√°ll√≠t√°s: top kontextusok els≈ë 2-3 mondat√°b√≥l\n",
    "    # (ha szeretn√©d, itt haszn√°lhatsz LLM-et is a gener√°l√°shoz)\n",
    "    answer_snips = []\n",
    "    for c in top_contexts[:4]:\n",
    "        sents = _sent_tokenize(c[\"text\"], max_sent=3)\n",
    "        answer_snips.extend(sents)\n",
    "    # dedup + r√∂vid√≠t√©s\n",
    "    seen = set()\n",
    "    final_lines = []\n",
    "    for s in answer_snips:\n",
    "        t = s.strip()\n",
    "        if t and t not in seen:\n",
    "            seen.add(t)\n",
    "            final_lines.append(t)\n",
    "        if len(final_lines) >= 6:  # maximum 6 r√∂vid sor\n",
    "            break\n",
    "\n",
    "    answer = \" \".join(final_lines) if final_lines else \"(Nem tal√°ltam el√©g relev√°ns, r√∂vid kontextust.)\"\n",
    "\n",
    "    # 6) Forr√°sok list√°z√°sa\n",
    "    source_list = []\n",
    "    for c, score in zip(top_contexts, top_rel_vals):\n",
    "        source_list.append({\n",
    "            \"function\": c[\"function_name\"],\n",
    "            \"type\": c[\"type\"],\n",
    "            \"score\": float(score),\n",
    "            \"source\": c[\"source\"]\n",
    "        })\n",
    "\n",
    "    # 7) Debug: top-k function jel√∂ltek\n",
    "    top_functions = []\n",
    "    for fid, s in zip(idxs, vals):\n",
    "        nm = fn_df.iloc[fid].get(\"combinedName\", f\"Function_{fid}\")\n",
    "        top_functions.append((nm, float(s)))\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"functions\": top_functions,\n",
    "        \"sources\": source_list\n",
    "    }\n",
    "\n",
    "\n",
    "def print_rag_answer(question):\n",
    "    res = ask_rag(question, k_funcs=15, k_ctx=6)\n",
    "    \"\"\"Seg√©df√ºggv√©ny a RAG v√°lasz ki√≠r√°s√°hoz.\"\"\"\n",
    "    print(\"\\nüü© Answer:\\n\", res[\"answer\"])\n",
    "    print(\"\\nüîé Top function candidates:\")\n",
    "    for name, sc in res[\"functions\"][:8]:\n",
    "        print(f\" - {name:60s}  (sim={sc:.4f})\")\n",
    "\n",
    "    print(\"\\nüìö Sources (reranked):\")\n",
    "    for s in res[\"sources\"][:8]:\n",
    "        print(f\" - [{s['type']}] {s['function']}  | sim={s['score']:.4f}  | {s['source']}\")\n",
    "# ---------------- Example usage ----------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e97cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü© Answer:\n",
      " Generate cross-validated estimates for each input data point. The data is split according to the cv parameter. Each sample belongs\n",
      "to exactly one test set, and its prediction is computed with an\n",
      "estimator fitted on the corresponding training set. I am training a model to solve binary classification problem usign scikitlearn, and i wish to perform cross validation with 5 folds. As metrics, i would like to get both the average accuracy and a confusion matrix over the 5 folds. This is my minimal reproducible example: \n",
      "  import numpy as np\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.model_selection import cross_validate\n",
      "\n",
      "x = np.array([\n",
      "   [1, 2],\n",
      "   [3, 4],\n",
      "   [5, 6],\n",
      "   [6, 7]\n",
      "])  \n",
      "y = [1, 0, 0, 1]\n",
      "\n",
      "model = GaussianNB()\n",
      "scores = cross_validate(model, x, y, cv=2, scoring=(&quot;accuracy&quot;))\n",
      "\n",
      "model.predict([8,9])\n",
      "  \n",
      " What I intended to do is instantiating a  Gaussian Naive Bayes Classifier  and use  sklearn.model_selection.cross_validate  for cross validate my model (I am using  cross_validate  instead of  cross_val_score  since in my real project I need precision, recall and f1 as well).\n",
      "\n",
      "üîé Top function candidates:\n",
      " - cross_val_score                                               (sim=0.5046)\n",
      " - cross_validate                                                (sim=0.4627)\n",
      " - GridSearchCV._run_search                                      (sim=0.3711)\n",
      " - learning_curve                                                (sim=0.3275)\n",
      " - RFE.fit                                                       (sim=0.3103)\n",
      " - RFECV.fit                                                     (sim=0.3042)\n",
      " - cross_val_predict                                             (sim=0.2873)\n",
      " - OneVsRestClassifier.fit                                       (sim=0.2872)\n",
      "\n",
      "üìö Sources (reranked):\n",
      " - [docstring] cross_val_predict  | sim=0.6149  | docstring:cross_val_predict\n",
      " - [stack_overflow] _RidgeGCV._score  | sim=0.5330  | SO row 370 (contexts contains _RidgeGCV._score)\n",
      " - [stack_overflow] cross_validate  | sim=0.5309  | SO row 106 (contexts contains cross_validate)\n",
      " - [stack_overflow] cross_val_score  | sim=0.5126  | SO row 80 (contexts contains cross_val_score)\n",
      " - [docstring] cross_validate  | sim=0.5020  | docstring:cross_validate\n",
      " - [stack_overflow] cross_val_score  | sim=0.4884  | SO row 172 (contexts contains cross_val_score)\n",
      " - [stack_overflow] cross_val_predict  | sim=0.4884  | SO row 172 (contexts contains cross_val_predict)\n",
      " - [docstring] cross_val_score  | sim=0.4852  | docstring:cross_val_score\n"
     ]
    }
   ],
   "source": [
    "print_rag_answer(\"How can I evaluate classifier performance with cross-validation?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4785d695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü© Answer:\n",
      " I've built a model using  LogisticRegression()  and after a grid search the data suggests for my inverse of regularization strength,  C = .0000001  is the &quot;best&quot; value to make my predictions. This parameter works fine for  LogisticRegression() , but seeing as I want to cross-validate I decide to use  LogisticRegressionCV()  the equivalent  c  parameter here is denoted as  Cs , yet when I try to pass the same variable  Cs = .0000001 , I get an error: \n",
      "      797     warm_start_sag = {&quot;coef&quot;: np.expand_dims(w0, axis=1)}\n",
      "    799 coefs = list()\n",
      "--&gt; 800 n_iter = np.zeros(len(Cs), dtype=np.int32)\n",
      "    801 for i, C in enumerate(Cs):\n",
      "    802     if solver == &quot;lbfgs&quot;:\n",
      "\n",
      "TypeError: object of type 'float' has no len()\n",
      "  \n",
      " When referring to the  documents  it seems that for  LogisticRegressionCV() : \n",
      " \n",
      " If Cs is as an int, then a grid of Cs values are chosen in a\n",
      "logarithmic scale between 1e-4 and 1e4. I tried to find the best combination of hyperparameters for  LogisticRegression  in  sklearn . Below is the example of my code: \n",
      "  pipeline = Pipeline([(&quot;scaler&quot;, StandardScaler()),\n",
      "                     (&quot;smt&quot;,    SMOTE(random_state=42)),\n",
      "                     (&quot;logreg&quot;, LogisticRegression())])\n",
      "\n",
      "\n",
      "parameters = [{'logreg__solver': ['saga']},\n",
      "              {'logreg__penalty':['l1', 'l2']},\n",
      "              {'logreg__C':[1e-3, 0.1, 1, 10, 100]}]\n",
      "\n",
      "grid_pipeline = GridSearchCV(pipeline,\n",
      "                             parameters, \n",
      "                             scoring= 'f1', \n",
      "                             n_jobs=5, verbose=5,\n",
      "                             return_train_score=True, \n",
      "                             cv=5) \n",
      "\n",
      "grid_result = grid_pipeline.fit(X_train,y_train)\n",
      "  \n",
      " During fitting I get the following error: \n",
      "  ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty. I'm running a  GridSearchCV  optimization into a parallelized function. The pseudocode looks like this \n",
      "  from tqdm.contrib.concurrent import process_map\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "def main():\n",
      "    results = process_map(func, it, max_workers=5)\n",
      "    # We never reach here with n_jobs &gt; 1 in GridSearch\n",
      "\n",
      "def func(it):\n",
      "    ...\n",
      "\n",
      "üîé Top function candidates:\n",
      " - LogisticRegression.fit                                        (sim=0.4765)\n",
      " - test_dispatch_config_parallel                                 (sim=0.4751)\n",
      " - OneVsRestClassifier.partial_fit                               (sim=0.3442)\n",
      " - LogisticRegressionCV.fit                                      (sim=0.3272)\n",
      " - StandardScaler.fit                                            (sim=0.2638)\n",
      " - QuadraticDiscriminantAnalysis.fit                             (sim=0.2429)\n",
      " - LogisticRegressionCV.score                                    (sim=0.2394)\n",
      " - DummyClassifier.score                                         (sim=0.2308)\n",
      "\n",
      "üìö Sources (reranked):\n",
      " - [stack_overflow] LogisticRegressionCV.score  | sim=0.4629  | SO row 210 (contexts contains LogisticRegressionCV.score)\n",
      " - [stack_overflow] GridSearchCV._run_search  | sim=0.4257  | SO row 70 (contexts contains GridSearchCV._run_search)\n",
      " - [stack_overflow] GridSearchCV._run_search  | sim=0.3233  | SO row 5 (contexts contains GridSearchCV._run_search)\n",
      " - [stack_overflow] OneVsRestClassifier.partial_fit  | sim=0.2947  | SO row 121 (contexts contains OneVsRestClassifier.partial_fit)\n",
      " - [stack_overflow] LogisticRegressionCV.score  | sim=0.2867  | SO row 245 (contexts contains LogisticRegressionCV.score)\n",
      " - [stack_overflow] DummyClassifier.score  | sim=0.2867  | SO row 245 (contexts contains DummyClassifier.score)\n",
      " - [docstring] make_scorer  | sim=0.2693  | docstring:make_scorer\n",
      " - [stack_overflow] LinearModelLoss.loss  | sim=0.2630  | SO row 458 (contexts contains LinearModelLoss.loss)\n"
     ]
    }
   ],
   "source": [
    "print_rag_answer(\"How does LogisticRegression perform optimization?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "551ccd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü© Answer:\n",
      " Partially fit underlying estimators. Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iterations. for example we have: \n",
      "  from sklearn.decomposition import PCA\n",
      "import numpy as np \n",
      "\n",
      "xx = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      "pca = PCA()\n",
      "pca.fit_transform(xx)\n",
      "  \n",
      " otput: \n",
      "  array([[ 1.38340578,  0.2935787 ],\n",
      "   [ 2.22189802, -0.25133484],\n",
      "   [ 3.6053038 ,  0.04224385],\n",
      "   [-1.38340578, -0.2935787 ],\n",
      "   [-2.22189802,  0.25133484],\n",
      "   [-3.6053038 , -0.04224385]])\n",
      "  \n",
      " In this case i am not reducing the size however the array is changed... why? Background:  \n",
      "I'm doing research using EigenFaces with Python.\n",
      "\n",
      "üîé Top function candidates:\n",
      " - PCA.fit                                                       (sim=0.3625)\n",
      " - _infer_dimension                                              (sim=0.3510)\n",
      " - PCA.fit_transform                                             (sim=0.2964)\n",
      " - RBFSampler.transform                                          (sim=0.2220)\n",
      " - CountVectorizer._sort_features                                (sim=0.2121)\n",
      " - KernelPCA.fit                                                 (sim=0.1988)\n",
      " - TimeSeriesSplit.split                                         (sim=0.1871)\n",
      " - func                                                          (sim=0.1815)\n",
      "\n",
      "üìö Sources (reranked):\n",
      " - [docstring] OneVsRestClassifier.partial_fit  | sim=0.4143  | docstring:OneVsRestClassifier.partial_fit\n",
      " - [stack_overflow] Kernel.theta  | sim=0.4102  | SO row 719 (contexts contains Kernel.theta)\n",
      " - [stack_overflow] PCA.fit_transform  | sim=0.3723  | SO row 66 (contexts contains PCA.fit_transform)\n",
      " - [stack_overflow] PCA.fit  | sim=0.3723  | SO row 66 (contexts contains PCA.fit)\n",
      " - [docstring] RBFSampler.transform  | sim=0.3592  | docstring:RBFSampler.transform\n",
      " - [stack_overflow] CountVectorizer._sort_features  | sim=0.3306  | SO row 94 (contexts contains CountVectorizer._sort_features)\n",
      " - [docstring] PCA.fit  | sim=0.3175  | docstring:PCA.fit\n",
      " - [stack_overflow] func  | sim=0.3133  | SO row 446 (contexts contains func)\n"
     ]
    }
   ],
   "source": [
    "print_rag_answer(\"How does PCA handle sparse data?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ed439",
   "metadata": {},
   "source": [
    "# No need to run the cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd4e1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_csv(\"generated_qna_large_gpt.csv\", sep=\"\\t\")\n",
    "qa_df = qa.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "530e29e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Total QA examples: 433\n",
      "‚úÖ Encoded QA questions + summaries ‚Üí torch.Size([433, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/348 [00:22<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Encoded function names ‚Üí torch.Size([11128, 384])\n",
      "‚úÖ Mapped 433 questions ‚Üí function nodes.\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------------------------------------------------\n",
    "# 1Ô∏è‚É£ - Compute embeddings for QA questions and summaries\n",
    "# ------------------------------------------------------------\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Use the same model as for the function_nodes\n",
    "qa_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "# Take the relevant text fields\n",
    "qa_texts = (\n",
    "    qa_df[\"questions\"].fillna(\"\") + \" \" + qa_df[\"summaries\"].fillna(\"\") + \" \" + qa_df[\"statements\"].fillna(\"\")\n",
    ").str.strip()\n",
    "\n",
    "print(f\"üìò Total QA examples: {len(qa_texts)}\")\n",
    "\n",
    "# Encode all questions (batch mode)\n",
    "qa_df[\"context\"] = (\n",
    "    qa_df[\"questions\"].fillna('') + \" \" +\n",
    "    qa_df[\"summaries\"].fillna('') + \" \" +\n",
    "    qa_df[\"comments\"].fillna('') + \" \" +\n",
    "    qa_df[\"statements\"].fillna('')\n",
    ").str.strip()\n",
    "\n",
    "# Encode context-rich text instead of plain questions\n",
    "q_emb = qa_encoder.encode(qa_df[\"context\"].tolist(), convert_to_tensor=True, device=device)\n",
    "print(\"‚úÖ Encoded QA questions + summaries ‚Üí\", q_emb.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ - Compute similarity with function node docstrings\n",
    "# ------------------------------------------------------------\n",
    "func_texts = repograph[\"function_nodes\"][\"combinedName\"].fillna(\"\").tolist()\n",
    "func_embs = qa_encoder.encode(func_texts, convert_to_tensor=True, device=device, show_progress_bar=True)\n",
    "print(\"‚úÖ Encoded function names ‚Üí\", func_embs.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ - Find the most similar function for each question\n",
    "# ------------------------------------------------------------\n",
    "pos_function_idx = []\n",
    "for q in q_emb:\n",
    "    sim = util.cos_sim(q.unsqueeze(0), func_embs)[0]\n",
    "    best_func = torch.argmax(sim).item()\n",
    "    pos_function_idx.append(best_func)\n",
    "\n",
    "pos_function_idx = torch.tensor(pos_function_idx, dtype=torch.long, device=device)\n",
    "print(f\"‚úÖ Mapped {len(pos_function_idx)} questions ‚Üí function nodes.\")\n",
    "\n",
    "# Optional: save for reuse\n",
    "torch.save(pos_function_idx, \"pos_function_idx.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d379e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç 10 random QA ‚Üí function mapping p√©lda:\n",
      "\n",
      "üß© [Q245] What change is being applied in the referenced PR to address platform‚Äëdependency issues with NumPy's...\n",
      "‚û°Ô∏è Function: test_yeojohnson_for_different_scipy_version\n",
      "üìò Docstring: Check that the results are consistent across different SciPy versions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q224] In which pull request was the issue about the MNT Fix issue template link to a blank issue reported?\n",
      "‚û°Ô∏è Function: test_knn_imputer_drops_all_nan_features\n",
      "üìò Docstring: \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q283] Why did the Binder build for the scikit‚Äëlearn repository fail after the mybinder.org deploy update (...\n",
      "‚û°Ô∏è Function: ContainerAdapterProtocol.is_supported_container\n",
      "üìò Docstring: Return True if X is a supported container.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "Xs: container\n",
      "    Containers to be checked.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "is_supported_container : bool\n",
      "    True if X is a supported container.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q366] What change does the pull request propose for the feature selection logic?\n",
      "‚û°Ô∏è Function: test_rfe_n_features_to_select_warning\n",
      "üìò Docstring: Check if the correct warning is raised when trying to initialize a RFE\n",
      "object with a n_features_to_select attribute larger than the number of\n",
      "features present in the X variable that is passed to the f...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q200] What specific change does the pull request implement to unify the spelling of the contributor‚Äôs name...\n",
      "‚û°Ô∏è Function: _get_git_revision\n",
      "üìò Docstring: \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q20] What exception does StratifiedGroupKFold.split() raise when the 'groups' argument is omitted?\n",
      "‚û°Ô∏è Function: test_no_group_splitters_warns_with_groups\n",
      "üìò Docstring: \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q420] What change was made to GridSearchCV to ensure appropriate evaluation during cross-validation?\n",
      "‚û°Ô∏è Function: test_gridsearchcv_cross_val_predict_with_method\n",
      "üìò Docstring: \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q414] What was the ccache hit rate observed in the CI build after updates, and how many minutes of build t...\n",
      "‚û°Ô∏è Function: _MultimetricScorer._use_cache\n",
      "üìò Docstring: Return True if using a cache is beneficial, thus when a response method will\n",
      "be called several time.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q50] What change does the pull request make to the `make_scorer` function regarding the `pos_label` param...\n",
      "‚û°Ô∏è Function: test_precision_recall_f1_score_binary_averaged\n",
      "üìò Docstring: \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üß© [Q105] Which temporary variables were explicitly deleted in the updated `DBSCAN.fit` implementation to redu...\n",
      "‚û°Ô∏è Function: test_dbscan_sparse\n",
      "üìò Docstring: \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------------------------------------\n",
    "# N√©zz√ºk meg, mely function node-okat rendelt a model a k√©rd√©sekhez\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Convert tensors back to CPU for readability\n",
    "pos_idx_cpu = pos_function_idx.cpu().numpy()\n",
    "\n",
    "print(\"üîç 10 random QA ‚Üí function mapping p√©lda:\\n\")\n",
    "\n",
    "sample_ids = torch.randperm(len(qa_df))[:10].tolist()\n",
    "\n",
    "for i in sample_ids:\n",
    "    q_text = qa_df.loc[i, \"questions\"]\n",
    "    f_id = pos_idx_cpu[i]\n",
    "\n",
    "    f_name = repograph[\"function_nodes\"].iloc[f_id][\"combinedName\"]\n",
    "    f_doc = repograph[\"function_nodes\"].iloc[f_id][\"docstring\"]\n",
    "\n",
    "    print(f\"üß© [Q{i}] {q_text.strip()[:100]}{'...' if len(q_text)>100 else ''}\")\n",
    "    print(f\"‚û°Ô∏è Function: {f_name}\")\n",
    "    print(f\"üìò Docstring: {f_doc.strip()[:200]}{'...' if len(f_doc)>200 else ''}\\n\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "354c1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss = 9.3351 | temp = 0.0679\n",
      "Epoch 02 | loss = 9.2665 | temp = 0.0659\n",
      "Epoch 03 | loss = 9.1974 | temp = 0.0639\n",
      "Epoch 04 | loss = 9.1304 | temp = 0.0620\n",
      "Epoch 05 | loss = 9.0681 | temp = 0.0601\n",
      "Epoch 06 | loss = 9.0163 | temp = 0.0583\n",
      "Epoch 07 | loss = 8.9336 | temp = 0.0566\n",
      "Epoch 08 | loss = 8.8473 | temp = 0.0549\n",
      "Epoch 09 | loss = 8.7614 | temp = 0.0532\n",
      "Epoch 10 | loss = 8.7037 | temp = 0.0516\n",
      "Epoch 11 | loss = 8.5612 | temp = 0.0501\n",
      "Epoch 12 | loss = 8.4967 | temp = 0.0486\n",
      "Epoch 13 | loss = 8.4051 | temp = 0.0471\n",
      "Epoch 14 | loss = 8.3323 | temp = 0.0457\n",
      "Epoch 15 | loss = 8.2388 | temp = 0.0443\n",
      "Epoch 16 | loss = 8.1590 | temp = 0.0430\n",
      "Epoch 17 | loss = 8.0642 | temp = 0.0417\n",
      "Epoch 18 | loss = 7.9674 | temp = 0.0405\n",
      "Epoch 19 | loss = 7.8651 | temp = 0.0392\n",
      "Epoch 20 | loss = 7.6986 | temp = 0.0381\n",
      "Epoch 21 | loss = 7.6825 | temp = 0.0369\n",
      "Epoch 22 | loss = 7.4833 | temp = 0.0358\n",
      "Epoch 23 | loss = 7.4217 | temp = 0.0347\n",
      "Epoch 24 | loss = 7.3028 | temp = 0.0337\n",
      "Epoch 25 | loss = 7.1953 | temp = 0.0327\n",
      "Epoch 26 | loss = 7.0646 | temp = 0.0317\n",
      "Epoch 27 | loss = 6.9795 | temp = 0.0308\n",
      "Epoch 28 | loss = 6.9369 | temp = 0.0300\n",
      "Epoch 29 | loss = 6.8172 | temp = 0.0300\n",
      "Epoch 30 | loss = 6.7684 | temp = 0.0300\n",
      "Epoch 31 | loss = 6.6937 | temp = 0.0300\n",
      "Epoch 32 | loss = 6.6439 | temp = 0.0300\n",
      "Epoch 33 | loss = 6.5679 | temp = 0.0300\n",
      "Epoch 34 | loss = 6.4813 | temp = 0.0300\n",
      "Epoch 35 | loss = 6.5305 | temp = 0.0300\n",
      "Epoch 36 | loss = 6.3993 | temp = 0.0300\n",
      "Epoch 37 | loss = 6.3390 | temp = 0.0300\n",
      "Epoch 38 | loss = 6.2888 | temp = 0.0300\n",
      "Epoch 39 | loss = 6.3349 | temp = 0.0300\n",
      "Epoch 40 | loss = 6.2295 | temp = 0.0300\n",
      "Epoch 41 | loss = 6.2193 | temp = 0.0300\n",
      "Epoch 42 | loss = 6.2272 | temp = 0.0300\n",
      "Epoch 43 | loss = 6.1225 | temp = 0.0300\n",
      "Epoch 44 | loss = 6.1115 | temp = 0.0300\n",
      "Epoch 45 | loss = 6.1127 | temp = 0.0300\n",
      "Epoch 46 | loss = 6.0398 | temp = 0.0300\n",
      "Epoch 47 | loss = 6.0153 | temp = 0.0300\n",
      "Epoch 48 | loss = 6.0616 | temp = 0.0300\n",
      "Epoch 49 | loss = 5.9790 | temp = 0.0300\n",
      "Epoch 50 | loss = 5.9248 | temp = 0.0300\n",
      "Epoch 51 | loss = 6.0005 | temp = 0.0300\n",
      "Epoch 52 | loss = 5.9321 | temp = 0.0300\n",
      "Epoch 53 | loss = 5.8771 | temp = 0.0300\n",
      "Epoch 54 | loss = 5.9129 | temp = 0.0300\n",
      "Epoch 55 | loss = 5.9036 | temp = 0.0300\n",
      "Epoch 56 | loss = 5.8534 | temp = 0.0300\n",
      "Epoch 57 | loss = 5.8541 | temp = 0.0300\n",
      "Epoch 58 | loss = 5.8562 | temp = 0.0300\n",
      "Epoch 59 | loss = 5.7915 | temp = 0.0300\n",
      "Epoch 60 | loss = 5.8011 | temp = 0.0300\n",
      "Epoch 61 | loss = 5.7879 | temp = 0.0300\n",
      "Epoch 62 | loss = 5.7664 | temp = 0.0300\n",
      "Epoch 63 | loss = 5.7997 | temp = 0.0300\n",
      "Epoch 64 | loss = 5.7232 | temp = 0.0300\n",
      "Epoch 65 | loss = 5.7156 | temp = 0.0300\n",
      "Epoch 66 | loss = 5.7210 | temp = 0.0300\n",
      "Epoch 67 | loss = 5.7011 | temp = 0.0300\n",
      "Epoch 68 | loss = 5.7165 | temp = 0.0300\n",
      "Epoch 69 | loss = 5.6443 | temp = 0.0300\n",
      "Epoch 70 | loss = 5.6799 | temp = 0.0300\n",
      "Epoch 71 | loss = 5.7089 | temp = 0.0300\n",
      "Epoch 72 | loss = 5.6557 | temp = 0.0300\n",
      "Epoch 73 | loss = 5.6811 | temp = 0.0300\n",
      "Epoch 74 | loss = 5.6379 | temp = 0.0300\n",
      "Epoch 75 | loss = 5.6059 | temp = 0.0300\n",
      "Epoch 76 | loss = 5.6284 | temp = 0.0300\n",
      "Epoch 77 | loss = 5.5989 | temp = 0.0300\n",
      "Epoch 78 | loss = 5.5728 | temp = 0.0300\n",
      "Epoch 79 | loss = 5.5929 | temp = 0.0300\n",
      "Epoch 80 | loss = 5.5807 | temp = 0.0300\n",
      "Epoch 81 | loss = 5.5647 | temp = 0.0300\n",
      "Epoch 82 | loss = 5.5792 | temp = 0.0300\n",
      "Epoch 83 | loss = 5.6021 | temp = 0.0300\n",
      "Epoch 84 | loss = 5.5387 | temp = 0.0300\n",
      "Epoch 85 | loss = 5.5155 | temp = 0.0300\n",
      "Epoch 86 | loss = 5.5444 | temp = 0.0300\n",
      "Epoch 87 | loss = 5.5339 | temp = 0.0300\n",
      "Epoch 88 | loss = 5.5361 | temp = 0.0300\n",
      "Epoch 89 | loss = 5.5442 | temp = 0.0300\n",
      "Epoch 90 | loss = 5.5017 | temp = 0.0300\n",
      "Epoch 91 | loss = 5.4468 | temp = 0.0300\n",
      "Epoch 92 | loss = 5.4600 | temp = 0.0300\n",
      "Epoch 93 | loss = 5.4907 | temp = 0.0300\n",
      "Epoch 94 | loss = 5.5026 | temp = 0.0300\n",
      "Epoch 95 | loss = 5.4802 | temp = 0.0300\n",
      "Epoch 96 | loss = 5.4391 | temp = 0.0300\n",
      "Epoch 97 | loss = 5.4644 | temp = 0.0300\n",
      "Epoch 98 | loss = 5.5097 | temp = 0.0300\n",
      "Epoch 99 | loss = 5.4297 | temp = 0.0300\n",
      "Epoch 100 | loss = 5.4855 | temp = 0.0300\n",
      "Epoch 101 | loss = 5.4168 | temp = 0.0300\n",
      "Epoch 102 | loss = 5.4636 | temp = 0.0300\n",
      "Epoch 103 | loss = 5.4783 | temp = 0.0300\n",
      "Epoch 104 | loss = 5.4687 | temp = 0.0300\n",
      "Epoch 105 | loss = 5.4239 | temp = 0.0300\n",
      "Epoch 106 | loss = 5.4785 | temp = 0.0300\n",
      "Epoch 107 | loss = 5.4330 | temp = 0.0300\n",
      "Epoch 108 | loss = 5.4049 | temp = 0.0300\n",
      "Epoch 109 | loss = 5.4571 | temp = 0.0300\n",
      "Epoch 110 | loss = 5.4204 | temp = 0.0300\n",
      "Epoch 111 | loss = 5.3904 | temp = 0.0300\n",
      "Epoch 112 | loss = 5.3904 | temp = 0.0300\n",
      "Epoch 113 | loss = 5.4080 | temp = 0.0300\n",
      "Epoch 114 | loss = 5.3690 | temp = 0.0300\n",
      "Epoch 115 | loss = 5.4202 | temp = 0.0300\n",
      "Epoch 116 | loss = 5.3408 | temp = 0.0300\n",
      "Epoch 117 | loss = 5.4036 | temp = 0.0300\n",
      "Epoch 118 | loss = 5.4110 | temp = 0.0300\n",
      "Epoch 119 | loss = 5.3960 | temp = 0.0300\n",
      "Epoch 120 | loss = 5.3397 | temp = 0.0300\n",
      "Epoch 121 | loss = 5.3462 | temp = 0.0300\n",
      "Epoch 122 | loss = 5.3530 | temp = 0.0300\n",
      "Epoch 123 | loss = 5.3740 | temp = 0.0300\n",
      "Epoch 124 | loss = 5.3512 | temp = 0.0300\n",
      "Epoch 125 | loss = 5.3406 | temp = 0.0300\n",
      "Epoch 126 | loss = 5.3450 | temp = 0.0300\n",
      "Epoch 127 | loss = 5.3094 | temp = 0.0300\n",
      "Epoch 128 | loss = 5.3231 | temp = 0.0300\n",
      "Epoch 129 | loss = 5.3461 | temp = 0.0300\n",
      "Epoch 130 | loss = 5.3369 | temp = 0.0300\n",
      "Epoch 131 | loss = 5.3312 | temp = 0.0300\n",
      "Epoch 132 | loss = 5.3194 | temp = 0.0300\n",
      "Epoch 133 | loss = 5.3095 | temp = 0.0300\n",
      "Epoch 134 | loss = 5.3686 | temp = 0.0300\n",
      "Epoch 135 | loss = 5.3345 | temp = 0.0300\n",
      "Epoch 136 | loss = 5.2692 | temp = 0.0300\n",
      "Epoch 137 | loss = 5.3206 | temp = 0.0300\n",
      "Epoch 138 | loss = 5.3366 | temp = 0.0300\n",
      "Epoch 139 | loss = 5.3056 | temp = 0.0300\n",
      "Epoch 140 | loss = 5.2908 | temp = 0.0300\n",
      "Epoch 141 | loss = 5.3040 | temp = 0.0300\n",
      "Epoch 142 | loss = 5.3186 | temp = 0.0300\n",
      "Epoch 143 | loss = 5.3054 | temp = 0.0300\n",
      "Epoch 144 | loss = 5.3181 | temp = 0.0300\n",
      "Epoch 145 | loss = 5.3071 | temp = 0.0300\n",
      "Epoch 146 | loss = 5.2837 | temp = 0.0300\n",
      "Epoch 147 | loss = 5.3052 | temp = 0.0300\n",
      "Epoch 148 | loss = 5.3537 | temp = 0.0300\n",
      "Epoch 149 | loss = 5.3289 | temp = 0.0300\n",
      "Epoch 150 | loss = 5.2890 | temp = 0.0300\n",
      "Epoch 151 | loss = 5.2613 | temp = 0.0300\n",
      "Epoch 152 | loss = 5.2724 | temp = 0.0300\n",
      "Epoch 153 | loss = 5.3092 | temp = 0.0300\n",
      "Epoch 154 | loss = 5.3390 | temp = 0.0300\n",
      "Epoch 155 | loss = 5.2799 | temp = 0.0300\n",
      "Epoch 156 | loss = 5.2868 | temp = 0.0300\n",
      "Epoch 157 | loss = 5.2762 | temp = 0.0300\n",
      "Epoch 158 | loss = 5.2908 | temp = 0.0300\n",
      "Epoch 159 | loss = 5.3137 | temp = 0.0300\n",
      "Epoch 160 | loss = 5.3099 | temp = 0.0300\n",
      "Epoch 161 | loss = 5.2759 | temp = 0.0300\n",
      "Epoch 162 | loss = 5.2559 | temp = 0.0300\n",
      "Epoch 163 | loss = 5.2928 | temp = 0.0300\n",
      "Epoch 164 | loss = 5.2670 | temp = 0.0300\n",
      "Epoch 165 | loss = 5.2523 | temp = 0.0300\n",
      "Epoch 166 | loss = 5.2929 | temp = 0.0300\n",
      "Epoch 167 | loss = 5.2710 | temp = 0.0300\n",
      "Epoch 168 | loss = 5.2479 | temp = 0.0300\n",
      "Epoch 169 | loss = 5.2859 | temp = 0.0300\n",
      "Epoch 170 | loss = 5.2196 | temp = 0.0300\n",
      "Epoch 171 | loss = 5.2781 | temp = 0.0300\n",
      "Epoch 172 | loss = 5.2196 | temp = 0.0300\n",
      "Epoch 173 | loss = 5.2642 | temp = 0.0300\n",
      "Epoch 174 | loss = 5.2212 | temp = 0.0300\n",
      "Epoch 175 | loss = 5.2344 | temp = 0.0300\n",
      "Epoch 176 | loss = 5.2174 | temp = 0.0300\n",
      "Epoch 177 | loss = 5.2519 | temp = 0.0300\n",
      "Epoch 178 | loss = 5.2614 | temp = 0.0300\n",
      "Epoch 179 | loss = 5.2499 | temp = 0.0300\n",
      "Epoch 180 | loss = 5.2441 | temp = 0.0300\n",
      "Epoch 181 | loss = 5.2637 | temp = 0.0300\n",
      "Epoch 182 | loss = 5.2120 | temp = 0.0300\n",
      "Epoch 183 | loss = 5.2132 | temp = 0.0300\n",
      "Epoch 184 | loss = 5.2350 | temp = 0.0300\n",
      "Epoch 185 | loss = 5.2580 | temp = 0.0300\n",
      "Epoch 186 | loss = 5.2311 | temp = 0.0300\n",
      "Epoch 187 | loss = 5.2736 | temp = 0.0300\n",
      "Epoch 188 | loss = 5.2291 | temp = 0.0300\n",
      "Epoch 189 | loss = 5.2315 | temp = 0.0300\n",
      "Epoch 190 | loss = 5.2173 | temp = 0.0300\n",
      "Epoch 191 | loss = 5.2157 | temp = 0.0300\n",
      "Epoch 192 | loss = 5.2236 | temp = 0.0300\n",
      "Epoch 193 | loss = 5.2250 | temp = 0.0300\n",
      "Epoch 194 | loss = 5.2068 | temp = 0.0300\n",
      "Epoch 195 | loss = 5.2046 | temp = 0.0300\n",
      "Epoch 196 | loss = 5.2576 | temp = 0.0300\n",
      "Epoch 197 | loss = 5.2194 | temp = 0.0300\n",
      "Epoch 198 | loss = 5.2136 | temp = 0.0300\n",
      "Epoch 199 | loss = 5.2339 | temp = 0.0300\n",
      "Epoch 200 | loss = 5.2047 | temp = 0.0300\n",
      "Epoch 201 | loss = 5.2314 | temp = 0.0300\n",
      "Epoch 202 | loss = 5.1968 | temp = 0.0300\n",
      "Epoch 203 | loss = 5.2175 | temp = 0.0300\n",
      "Epoch 204 | loss = 5.2179 | temp = 0.0300\n",
      "Epoch 205 | loss = 5.2037 | temp = 0.0300\n",
      "Epoch 206 | loss = 5.2415 | temp = 0.0300\n",
      "Epoch 207 | loss = 5.2260 | temp = 0.0300\n",
      "Epoch 208 | loss = 5.2110 | temp = 0.0300\n",
      "Epoch 209 | loss = 5.2288 | temp = 0.0300\n",
      "Epoch 210 | loss = 5.1832 | temp = 0.0300\n",
      "Epoch 211 | loss = 5.1662 | temp = 0.0300\n",
      "Epoch 212 | loss = 5.2079 | temp = 0.0300\n",
      "Epoch 213 | loss = 5.1979 | temp = 0.0300\n",
      "Epoch 214 | loss = 5.1723 | temp = 0.0300\n",
      "Epoch 215 | loss = 5.1841 | temp = 0.0300\n",
      "Epoch 216 | loss = 5.1909 | temp = 0.0300\n",
      "Epoch 217 | loss = 5.1884 | temp = 0.0300\n",
      "Epoch 218 | loss = 5.1939 | temp = 0.0300\n",
      "Epoch 219 | loss = 5.2176 | temp = 0.0300\n",
      "Epoch 220 | loss = 5.1842 | temp = 0.0300\n",
      "Epoch 221 | loss = 5.1969 | temp = 0.0300\n",
      "Epoch 222 | loss = 5.1871 | temp = 0.0300\n",
      "Epoch 223 | loss = 5.1456 | temp = 0.0300\n",
      "Epoch 224 | loss = 5.1971 | temp = 0.0300\n",
      "Epoch 225 | loss = 5.1683 | temp = 0.0300\n",
      "Epoch 226 | loss = 5.1934 | temp = 0.0300\n",
      "Epoch 227 | loss = 5.1644 | temp = 0.0300\n",
      "Epoch 228 | loss = 5.1864 | temp = 0.0300\n",
      "Epoch 229 | loss = 5.1725 | temp = 0.0300\n",
      "Epoch 230 | loss = 5.1969 | temp = 0.0300\n",
      "Epoch 231 | loss = 5.1967 | temp = 0.0300\n",
      "Epoch 232 | loss = 5.1399 | temp = 0.0300\n",
      "Epoch 233 | loss = 5.1570 | temp = 0.0300\n",
      "Epoch 234 | loss = 5.2058 | temp = 0.0300\n",
      "Epoch 235 | loss = 5.1799 | temp = 0.0300\n",
      "Epoch 236 | loss = 5.1683 | temp = 0.0300\n",
      "Epoch 237 | loss = 5.1817 | temp = 0.0300\n",
      "Epoch 238 | loss = 5.1615 | temp = 0.0300\n",
      "Epoch 239 | loss = 5.1923 | temp = 0.0300\n",
      "Epoch 240 | loss = 5.1793 | temp = 0.0300\n",
      "Epoch 241 | loss = 5.1544 | temp = 0.0300\n",
      "Epoch 242 | loss = 5.1893 | temp = 0.0300\n",
      "Epoch 243 | loss = 5.2049 | temp = 0.0300\n",
      "Epoch 244 | loss = 5.1322 | temp = 0.0300\n",
      "Epoch 245 | loss = 5.1741 | temp = 0.0300\n",
      "Epoch 246 | loss = 5.1167 | temp = 0.0300\n",
      "Epoch 247 | loss = 5.1460 | temp = 0.0300\n",
      "Epoch 248 | loss = 5.1629 | temp = 0.0300\n",
      "Epoch 249 | loss = 5.1095 | temp = 0.0300\n",
      "Epoch 250 | loss = 5.1619 | temp = 0.0300\n",
      "Epoch 251 | loss = 5.1177 | temp = 0.0300\n",
      "Epoch 252 | loss = 5.1101 | temp = 0.0300\n",
      "Epoch 253 | loss = 5.1534 | temp = 0.0300\n",
      "Epoch 254 | loss = 5.1031 | temp = 0.0300\n",
      "Epoch 255 | loss = 5.1227 | temp = 0.0300\n",
      "Epoch 256 | loss = 5.1497 | temp = 0.0300\n",
      "Epoch 257 | loss = 5.1288 | temp = 0.0300\n",
      "Epoch 258 | loss = 5.1312 | temp = 0.0300\n",
      "Epoch 259 | loss = 5.1669 | temp = 0.0300\n",
      "Epoch 260 | loss = 5.1403 | temp = 0.0300\n",
      "Epoch 261 | loss = 5.1136 | temp = 0.0300\n",
      "Epoch 262 | loss = 5.1719 | temp = 0.0300\n",
      "Epoch 263 | loss = 5.1203 | temp = 0.0300\n",
      "Epoch 264 | loss = 5.1010 | temp = 0.0300\n",
      "Epoch 265 | loss = 5.1557 | temp = 0.0300\n",
      "Epoch 266 | loss = 5.1241 | temp = 0.0300\n",
      "Epoch 267 | loss = 5.1392 | temp = 0.0300\n",
      "Epoch 268 | loss = 5.1015 | temp = 0.0300\n",
      "Epoch 269 | loss = 5.1033 | temp = 0.0300\n",
      "Epoch 270 | loss = 5.1106 | temp = 0.0300\n",
      "Epoch 271 | loss = 5.1102 | temp = 0.0300\n",
      "Epoch 272 | loss = 5.1160 | temp = 0.0300\n",
      "Epoch 273 | loss = 5.1432 | temp = 0.0300\n",
      "Epoch 274 | loss = 5.1671 | temp = 0.0300\n",
      "Epoch 275 | loss = 5.1642 | temp = 0.0300\n",
      "Epoch 276 | loss = 5.1482 | temp = 0.0300\n",
      "Epoch 277 | loss = 5.1317 | temp = 0.0300\n",
      "Epoch 278 | loss = 5.1356 | temp = 0.0300\n",
      "Epoch 279 | loss = 5.1291 | temp = 0.0300\n",
      "Epoch 280 | loss = 5.1265 | temp = 0.0300\n",
      "Epoch 281 | loss = 5.1276 | temp = 0.0300\n",
      "Epoch 282 | loss = 5.0827 | temp = 0.0300\n",
      "Epoch 283 | loss = 5.1344 | temp = 0.0300\n",
      "Epoch 284 | loss = 5.0885 | temp = 0.0300\n",
      "Epoch 285 | loss = 5.1232 | temp = 0.0300\n",
      "Epoch 286 | loss = 5.1241 | temp = 0.0300\n",
      "Epoch 287 | loss = 5.0844 | temp = 0.0300\n",
      "Epoch 288 | loss = 5.1336 | temp = 0.0300\n",
      "Epoch 289 | loss = 5.1070 | temp = 0.0300\n",
      "Epoch 290 | loss = 5.1360 | temp = 0.0300\n",
      "Epoch 291 | loss = 5.1285 | temp = 0.0300\n",
      "Epoch 292 | loss = 5.1182 | temp = 0.0300\n",
      "Epoch 293 | loss = 5.1055 | temp = 0.0300\n",
      "Epoch 294 | loss = 5.1089 | temp = 0.0300\n",
      "Epoch 295 | loss = 5.1407 | temp = 0.0300\n",
      "Epoch 296 | loss = 5.0945 | temp = 0.0300\n",
      "Epoch 297 | loss = 5.1510 | temp = 0.0300\n",
      "Epoch 298 | loss = 5.1315 | temp = 0.0300\n",
      "Epoch 299 | loss = 5.0600 | temp = 0.0300\n",
      "Epoch 300 | loss = 5.0996 | temp = 0.0300\n",
      "Epoch 301 | loss = 5.1427 | temp = 0.0300\n",
      "Epoch 302 | loss = 5.1375 | temp = 0.0300\n",
      "Epoch 303 | loss = 5.1337 | temp = 0.0300\n",
      "Epoch 304 | loss = 5.0804 | temp = 0.0300\n",
      "Epoch 305 | loss = 5.1030 | temp = 0.0300\n",
      "Epoch 306 | loss = 5.1310 | temp = 0.0300\n",
      "Epoch 307 | loss = 5.0797 | temp = 0.0300\n",
      "Epoch 308 | loss = 5.1181 | temp = 0.0300\n",
      "Epoch 309 | loss = 5.0831 | temp = 0.0300\n",
      "Epoch 310 | loss = 5.0929 | temp = 0.0300\n",
      "Epoch 311 | loss = 5.1058 | temp = 0.0300\n",
      "Epoch 312 | loss = 5.0792 | temp = 0.0300\n",
      "Epoch 313 | loss = 5.1223 | temp = 0.0300\n",
      "Epoch 314 | loss = 5.0756 | temp = 0.0300\n",
      "Epoch 315 | loss = 5.1023 | temp = 0.0300\n",
      "Epoch 316 | loss = 5.0942 | temp = 0.0300\n",
      "Epoch 317 | loss = 5.1143 | temp = 0.0300\n",
      "Epoch 318 | loss = 5.1035 | temp = 0.0300\n",
      "Epoch 319 | loss = 5.0904 | temp = 0.0300\n",
      "Epoch 320 | loss = 5.0964 | temp = 0.0300\n",
      "Epoch 321 | loss = 5.0978 | temp = 0.0300\n",
      "Epoch 322 | loss = 5.1330 | temp = 0.0300\n",
      "Epoch 323 | loss = 5.0926 | temp = 0.0300\n",
      "Epoch 324 | loss = 5.1014 | temp = 0.0300\n",
      "Epoch 325 | loss = 5.0848 | temp = 0.0300\n",
      "Epoch 326 | loss = 5.0986 | temp = 0.0300\n",
      "Epoch 327 | loss = 5.0887 | temp = 0.0300\n",
      "Epoch 328 | loss = 5.0989 | temp = 0.0300\n",
      "Epoch 329 | loss = 5.1105 | temp = 0.0300\n",
      "Epoch 330 | loss = 5.0502 | temp = 0.0300\n",
      "Epoch 331 | loss = 5.1262 | temp = 0.0300\n",
      "Epoch 332 | loss = 5.1479 | temp = 0.0300\n",
      "Epoch 333 | loss = 5.1300 | temp = 0.0300\n",
      "Epoch 334 | loss = 5.0864 | temp = 0.0300\n",
      "Epoch 335 | loss = 5.0793 | temp = 0.0300\n",
      "Epoch 336 | loss = 5.1018 | temp = 0.0300\n",
      "Epoch 337 | loss = 5.1026 | temp = 0.0300\n",
      "Epoch 338 | loss = 5.0784 | temp = 0.0300\n",
      "Epoch 339 | loss = 5.1190 | temp = 0.0300\n",
      "Epoch 340 | loss = 5.0817 | temp = 0.0300\n",
      "Epoch 341 | loss = 5.0590 | temp = 0.0300\n",
      "Epoch 342 | loss = 5.0960 | temp = 0.0300\n",
      "Epoch 343 | loss = 5.1128 | temp = 0.0300\n",
      "Epoch 344 | loss = 5.0870 | temp = 0.0300\n",
      "Epoch 345 | loss = 5.0754 | temp = 0.0300\n",
      "Epoch 346 | loss = 5.0782 | temp = 0.0300\n",
      "Epoch 347 | loss = 5.0476 | temp = 0.0300\n",
      "Epoch 348 | loss = 5.0635 | temp = 0.0300\n",
      "Epoch 349 | loss = 5.0603 | temp = 0.0300\n",
      "Epoch 350 | loss = 5.0825 | temp = 0.0300\n",
      "Epoch 351 | loss = 5.1112 | temp = 0.0300\n",
      "Epoch 352 | loss = 5.0895 | temp = 0.0300\n",
      "Epoch 353 | loss = 5.0640 | temp = 0.0300\n",
      "Epoch 354 | loss = 5.0347 | temp = 0.0300\n",
      "Epoch 355 | loss = 5.0550 | temp = 0.0300\n",
      "Epoch 356 | loss = 5.0885 | temp = 0.0300\n",
      "Epoch 357 | loss = 5.0764 | temp = 0.0300\n",
      "Epoch 358 | loss = 5.0910 | temp = 0.0300\n",
      "Epoch 359 | loss = 5.0758 | temp = 0.0300\n",
      "Epoch 360 | loss = 5.0690 | temp = 0.0300\n",
      "Epoch 361 | loss = 5.0833 | temp = 0.0300\n",
      "Epoch 362 | loss = 5.0869 | temp = 0.0300\n",
      "Epoch 363 | loss = 5.0346 | temp = 0.0300\n",
      "Epoch 364 | loss = 5.0616 | temp = 0.0300\n",
      "Epoch 365 | loss = 5.0718 | temp = 0.0300\n",
      "Epoch 366 | loss = 5.0408 | temp = 0.0300\n",
      "Epoch 367 | loss = 5.0397 | temp = 0.0300\n",
      "Epoch 368 | loss = 5.0440 | temp = 0.0300\n",
      "Epoch 369 | loss = 5.0430 | temp = 0.0300\n",
      "Epoch 370 | loss = 5.1082 | temp = 0.0300\n",
      "Epoch 371 | loss = 5.0650 | temp = 0.0300\n",
      "Epoch 372 | loss = 5.0645 | temp = 0.0300\n",
      "Epoch 373 | loss = 5.1121 | temp = 0.0300\n",
      "Epoch 374 | loss = 5.0604 | temp = 0.0300\n",
      "Epoch 375 | loss = 5.0589 | temp = 0.0300\n",
      "Epoch 376 | loss = 5.0742 | temp = 0.0300\n",
      "Epoch 377 | loss = 5.0460 | temp = 0.0300\n",
      "Epoch 378 | loss = 5.0463 | temp = 0.0300\n",
      "Epoch 379 | loss = 5.0748 | temp = 0.0300\n",
      "Epoch 380 | loss = 5.0300 | temp = 0.0300\n",
      "Epoch 381 | loss = 5.0732 | temp = 0.0300\n",
      "Epoch 382 | loss = 5.0142 | temp = 0.0300\n",
      "Epoch 383 | loss = 5.0327 | temp = 0.0300\n",
      "Epoch 384 | loss = 5.0635 | temp = 0.0300\n",
      "Epoch 385 | loss = 5.0461 | temp = 0.0300\n",
      "Epoch 386 | loss = 5.0252 | temp = 0.0300\n",
      "Epoch 387 | loss = 5.0558 | temp = 0.0300\n",
      "Epoch 388 | loss = 5.0621 | temp = 0.0300\n",
      "Epoch 389 | loss = 5.0471 | temp = 0.0300\n",
      "Epoch 390 | loss = 5.0847 | temp = 0.0300\n",
      "Epoch 391 | loss = 5.0382 | temp = 0.0300\n",
      "Epoch 392 | loss = 5.0464 | temp = 0.0300\n",
      "Epoch 393 | loss = 5.0881 | temp = 0.0300\n",
      "Epoch 394 | loss = 5.0817 | temp = 0.0300\n",
      "Epoch 395 | loss = 5.0356 | temp = 0.0300\n",
      "Epoch 396 | loss = 5.0374 | temp = 0.0300\n",
      "Epoch 397 | loss = 5.0789 | temp = 0.0300\n",
      "Epoch 398 | loss = 5.0850 | temp = 0.0300\n",
      "Epoch 399 | loss = 5.0353 | temp = 0.0300\n",
      "Epoch 400 | loss = 5.0627 | temp = 0.0300\n"
     ]
    }
   ],
   "source": [
    "# %% ----------------------------------------------------------\n",
    "# üìò Enhanced Function-GNN with Text Alignment + Annealing\n",
    "# ------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Define model\n",
    "# ------------------------------------------------------------\n",
    "class FunctionGNN(nn.Module):\n",
    "    def __init__(self, in_dim=384, hidden_dim=128, out_dim=384):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.text_align = nn.Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.text_align(x)   # project to text embedding space\n",
    "        return x\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Rebuild / reuse model + optimizer\n",
    "# ------------------------------------------------------------\n",
    "model = FunctionGNN(in_dim=x.size(1)).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ InfoNCE loss with annealing temperature\n",
    "# ------------------------------------------------------------\n",
    "def info_nce(q, items, pos_index, temperature):\n",
    "    q = F.normalize(q, dim=-1)\n",
    "    items = F.normalize(items, dim=-1)\n",
    "    logits = q @ items.T / temperature\n",
    "    pos_index = pos_index.clamp(0, items.size(0) - 1)\n",
    "    loss = F.cross_entropy(logits, pos_index.to(q.device))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Continue training with temperature annealing\n",
    "# ------------------------------------------------------------\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 64\n",
    "indices = torch.arange(len(q_emb), device=device)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    perm = indices[torch.randperm(len(indices))]\n",
    "    num_batches = math.ceil(len(perm) / BATCH_SIZE)\n",
    "\n",
    "    # slowly decrease temperature\n",
    "    temperature = max(0.03, 0.07 * (0.97 ** epoch))\n",
    "\n",
    "    for start in range(0, len(perm), BATCH_SIZE):\n",
    "        idx = perm[start:start + BATCH_SIZE]\n",
    "        q_batch = q_emb[idx]\n",
    "        pos_batch = pos_function_idx[idx]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        func_emb = model(data.x, data.edge_index)\n",
    "        loss = info_nce(q_batch, func_emb, pos_batch, temperature)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch:02d} | loss = {avg_loss:.4f} | temp = {temperature:.4f}\")\n",
    "\n",
    "    # optional checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"function_gnn_aligned_epoch{epoch:02d}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd4be443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% -----------------------------------------------\n",
    "# ‚úÖ Updated ask() function ‚Äì compatible with text_align GNN\n",
    "# ---------------------------------------------------\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ugyanaz a MiniLM encoder, mint a tan√≠t√°skor\n",
    "qa_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_function_embeddings():\n",
    "    \"\"\"Lek√©ri √©s szinkroniz√°lja a GNN function embeddingeket a sz√∂vegt√©rbe.\"\"\"\n",
    "    model.eval()\n",
    "    func_emb = model(data.x.to(device), data.edge_index.to(device))\n",
    "    func_emb = F.normalize(func_emb, dim=-1)  # cosine-simhez normaliz√°l√°s\n",
    "    return func_emb\n",
    "\n",
    "func_emb = get_function_embeddings()\n",
    "\n",
    "def ask(question: str, k: int = 5):\n",
    "    \"\"\"K√©rd√©s ‚Üí top-k legrelev√°nsabb function node.\"\"\"\n",
    "    q_vec = qa_encoder.encode([question], convert_to_tensor=True).to(device)\n",
    "    q_vec = F.normalize(q_vec, dim=-1)\n",
    "\n",
    "    # cosine-similarity a szinkroniz√°lt t√©rben\n",
    "    sim = q_vec @ func_emb.T\n",
    "    top_vals, top_idx = torch.topk(sim, k)\n",
    "\n",
    "    print(f\"\\n‚ùì Question: {question}\\n\")\n",
    "    print(\"Top-k related functions:\\n\")\n",
    "    for rank, (fid, score) in enumerate(zip(top_idx[0].tolist(), top_vals[0].tolist()), start=1):\n",
    "        row = repograph[\"function_nodes\"].iloc[fid]\n",
    "        name = row.get(\"combinedName\", f\"Function_{fid}\")\n",
    "        doc = row.get(\"docstring\", \"\")\n",
    "        print(f\"{rank:>2}. {name} (score={score:.4f})\")\n",
    "        if isinstance(doc, str) and doc.strip():\n",
    "            print(f\"   {doc[:180]}{'...' if len(doc) > 180 else ''}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98037965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: Which test in `sklearn/ensemble/tests/test_bagging.py` was updated to use the `global_random_seed` fixture?\n",
      "\n",
      "Top-k related functions:\n",
      "\n",
      " 1. test_newrand_set_seed (score=0.4108)\n",
      "   Test that `set_seed` produces deterministic results\n",
      "\n",
      " 2. pytest_generate_tests (score=0.2841)\n",
      "   Parametrization of global_random_seed fixture\n",
      "\n",
      "based on the SKLEARN_TESTS_GLOBAL_RANDOM_SEED environment variable.\n",
      "\n",
      "The goal of this fixture is to prevent tests that use it to be s...\n",
      "\n",
      " 3. test_newrand_set_seed_overflow (score=0.2510)\n",
      "   Test that `set_seed_wrap` is defined for unsigned 32bits ints\n",
      "\n",
      " 4. test_affinity_propagation_random_state (score=0.2418)\n",
      "   Check that different random states lead to different initialisations\n",
      "by looking at the center locations after two iterations.\n",
      "\n",
      " 5. BaseSearchCV._run_search (score=0.2135)\n",
      "   Repeatedly calls `evaluate_candidates` to conduct a search.\n",
      "\n",
      "This method, implemented in sub-classes, makes it possible to\n",
      "customize the scheduling of evaluations: GridSearchCV and...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"Which test in `sklearn/ensemble/tests/test_bagging.py` was updated to use the `global_random_seed` fixture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ac42208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: ** Which Naive Bayes estimators in scikit‚Äëlearn are being targeted for array‚ÄëAPI support in the described pull request?\n",
      "\n",
      "Top-k related functions:\n",
      "\n",
      " 1. test_fetch_openml_requires_pandas_error (score=0.1916)\n",
      "   Check that we raise the proper errors when we require pandas.\n",
      "\n",
      " 2. test_config_array_api_dispatch_error_scipy (score=0.1624)\n",
      "   Check error when SciPy is too old\n",
      "\n",
      " 3. bench_scikit_tree_regressor (score=0.1620)\n",
      "   Benchmark with scikit-learn decision tree regressor\n",
      "\n",
      " 4. test_raises_value_error_on_same_number_of_classes_and_samples (score=0.1561)\n",
      "   Tests that if the number of samples equals the number\n",
      "of classes, a ValueError is raised.\n",
      "\n",
      " 5. AdamOptimizer._get_updates (score=0.1560)\n",
      "   Get the values used to update params with given gradients\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "grads : list, length = len(coefs_) + len(intercepts_)\n",
      "    Containing gradients with respect to coef...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"** Which Naive Bayes estimators in scikit‚Äëlearn are being targeted for array‚ÄëAPI support in the described pull request?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38aff434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | loss = 6.8991\n",
      "Epoch 76 | loss = 6.8660\n",
      "Epoch 77 | loss = 6.8823\n",
      "Epoch 78 | loss = 6.8583\n",
      "Epoch 79 | loss = 6.8662\n",
      "Epoch 80 | loss = 6.8413\n",
      "Epoch 81 | loss = 6.8158\n",
      "Epoch 82 | loss = 6.8090\n",
      "Epoch 83 | loss = 6.7740\n",
      "Epoch 84 | loss = 6.7791\n",
      "Epoch 85 | loss = 6.7624\n",
      "Epoch 86 | loss = 6.7714\n",
      "Epoch 87 | loss = 6.7430\n",
      "Epoch 88 | loss = 6.7469\n",
      "Epoch 89 | loss = 6.7392\n",
      "Epoch 90 | loss = 6.7352\n",
      "Epoch 91 | loss = 6.6878\n",
      "Epoch 92 | loss = 6.6808\n",
      "Epoch 93 | loss = 6.6869\n",
      "Epoch 94 | loss = 6.6737\n",
      "Epoch 95 | loss = 6.6768\n",
      "Epoch 96 | loss = 6.6642\n",
      "Epoch 97 | loss = 6.6386\n",
      "Epoch 98 | loss = 6.6098\n",
      "Epoch 99 | loss = 6.6234\n",
      "Epoch 100 | loss = 6.6356\n",
      "Epoch 101 | loss = 6.6045\n",
      "Epoch 102 | loss = 6.5987\n",
      "Epoch 103 | loss = 6.5859\n",
      "Epoch 104 | loss = 6.5764\n",
      "Epoch 105 | loss = 6.5702\n",
      "Epoch 106 | loss = 6.5543\n",
      "Epoch 107 | loss = 6.5470\n",
      "Epoch 108 | loss = 6.5381\n",
      "Epoch 109 | loss = 6.5478\n",
      "Epoch 110 | loss = 6.5346\n",
      "Epoch 111 | loss = 6.5383\n",
      "Epoch 112 | loss = 6.5444\n",
      "Epoch 113 | loss = 6.4825\n",
      "Epoch 114 | loss = 6.5093\n",
      "Epoch 115 | loss = 6.5228\n",
      "Epoch 116 | loss = 6.4703\n",
      "Epoch 117 | loss = 6.4871\n",
      "Epoch 118 | loss = 6.4685\n",
      "Epoch 119 | loss = 6.4656\n",
      "Epoch 120 | loss = 6.4566\n",
      "Epoch 121 | loss = 6.4655\n",
      "Epoch 122 | loss = 6.4432\n",
      "Epoch 123 | loss = 6.4640\n",
      "Epoch 124 | loss = 6.4065\n",
      "Epoch 125 | loss = 6.4359\n",
      "Epoch 126 | loss = 6.4241\n",
      "Epoch 127 | loss = 6.3876\n",
      "Epoch 128 | loss = 6.3702\n",
      "Epoch 129 | loss = 6.3840\n",
      "Epoch 130 | loss = 6.3690\n",
      "Epoch 131 | loss = 6.3761\n",
      "Epoch 132 | loss = 6.3768\n",
      "Epoch 133 | loss = 6.3542\n",
      "Epoch 134 | loss = 6.3831\n",
      "Epoch 135 | loss = 6.3652\n",
      "Epoch 136 | loss = 6.3570\n",
      "Epoch 137 | loss = 6.3441\n",
      "Epoch 138 | loss = 6.3310\n",
      "Epoch 139 | loss = 6.3138\n",
      "Epoch 140 | loss = 6.3350\n",
      "Epoch 141 | loss = 6.3290\n",
      "Epoch 142 | loss = 6.3219\n",
      "Epoch 143 | loss = 6.3080\n",
      "Epoch 144 | loss = 6.2920\n",
      "Epoch 145 | loss = 6.3231\n",
      "Epoch 146 | loss = 6.2972\n",
      "Epoch 147 | loss = 6.3230\n",
      "Epoch 148 | loss = 6.2546\n",
      "Epoch 149 | loss = 6.2751\n",
      "Epoch 150 | loss = 6.2803\n",
      "Epoch 151 | loss = 6.2625\n",
      "Epoch 152 | loss = 6.2377\n",
      "Epoch 153 | loss = 6.2774\n",
      "Epoch 154 | loss = 6.2304\n",
      "Epoch 155 | loss = 6.2346\n",
      "Epoch 156 | loss = 6.2233\n",
      "Epoch 157 | loss = 6.2370\n",
      "Epoch 158 | loss = 6.1911\n",
      "Epoch 159 | loss = 6.1919\n",
      "Epoch 160 | loss = 6.2046\n",
      "Epoch 161 | loss = 6.2240\n",
      "Epoch 162 | loss = 6.1916\n",
      "Epoch 163 | loss = 6.1927\n",
      "Epoch 164 | loss = 6.1815\n",
      "Epoch 165 | loss = 6.2180\n",
      "Epoch 166 | loss = 6.1655\n",
      "Epoch 167 | loss = 6.2040\n",
      "Epoch 168 | loss = 6.1846\n",
      "Epoch 169 | loss = 6.1610\n",
      "Epoch 170 | loss = 6.1638\n",
      "Epoch 171 | loss = 6.1695\n",
      "Epoch 172 | loss = 6.1536\n",
      "Epoch 173 | loss = 6.1536\n",
      "Epoch 174 | loss = 6.1614\n",
      "Epoch 175 | loss = 6.1461\n",
      "Epoch 176 | loss = 6.1351\n",
      "Epoch 177 | loss = 6.1249\n",
      "Epoch 178 | loss = 6.1352\n",
      "Epoch 179 | loss = 6.1595\n",
      "Epoch 180 | loss = 6.1328\n",
      "Epoch 181 | loss = 6.1335\n",
      "Epoch 182 | loss = 6.1390\n",
      "Epoch 183 | loss = 6.1275\n",
      "Epoch 184 | loss = 6.1077\n",
      "Epoch 185 | loss = 6.1025\n",
      "Epoch 186 | loss = 6.1045\n",
      "Epoch 187 | loss = 6.0904\n",
      "Epoch 188 | loss = 6.0972\n",
      "Epoch 189 | loss = 6.0783\n",
      "Epoch 190 | loss = 6.0693\n",
      "Epoch 191 | loss = 6.0798\n",
      "Epoch 192 | loss = 6.0621\n",
      "Epoch 193 | loss = 6.0745\n",
      "Epoch 194 | loss = 6.0665\n",
      "Epoch 195 | loss = 6.0913\n",
      "Epoch 196 | loss = 6.0597\n",
      "Epoch 197 | loss = 6.0578\n",
      "Epoch 198 | loss = 6.0773\n",
      "Epoch 199 | loss = 6.0534\n",
      "Epoch 200 | loss = 6.0726\n",
      "Epoch 201 | loss = 6.0759\n",
      "Epoch 202 | loss = 6.0750\n",
      "Epoch 203 | loss = 6.0557\n",
      "Epoch 204 | loss = 6.0492\n",
      "Epoch 205 | loss = 6.0197\n",
      "Epoch 206 | loss = 6.0652\n",
      "Epoch 207 | loss = 6.0296\n",
      "Epoch 208 | loss = 6.0167\n",
      "Epoch 209 | loss = 6.0512\n",
      "Epoch 210 | loss = 6.0069\n",
      "Epoch 211 | loss = 6.0407\n",
      "Epoch 212 | loss = 6.0110\n",
      "Epoch 213 | loss = 6.0276\n",
      "Epoch 214 | loss = 6.0249\n",
      "Epoch 215 | loss = 5.9942\n",
      "Epoch 216 | loss = 6.0246\n",
      "Epoch 217 | loss = 6.0003\n",
      "Epoch 218 | loss = 5.9695\n",
      "Epoch 219 | loss = 5.9799\n",
      "Epoch 220 | loss = 5.9885\n",
      "Epoch 221 | loss = 6.0183\n",
      "Epoch 222 | loss = 6.0036\n",
      "Epoch 223 | loss = 5.9990\n",
      "Epoch 224 | loss = 5.9776\n",
      "Epoch 225 | loss = 5.9871\n",
      "Epoch 226 | loss = 5.9755\n",
      "Epoch 227 | loss = 5.9729\n",
      "Epoch 228 | loss = 5.9975\n",
      "Epoch 229 | loss = 5.9795\n",
      "Epoch 230 | loss = 5.9556\n",
      "Epoch 231 | loss = 5.9652\n",
      "Epoch 232 | loss = 5.9738\n",
      "Epoch 233 | loss = 5.9593\n",
      "Epoch 234 | loss = 5.9289\n",
      "Epoch 235 | loss = 5.9387\n",
      "Epoch 236 | loss = 5.9700\n",
      "Epoch 237 | loss = 5.9793\n",
      "Epoch 238 | loss = 5.9585\n",
      "Epoch 239 | loss = 5.9417\n",
      "Epoch 240 | loss = 5.9634\n",
      "Epoch 241 | loss = 5.9432\n",
      "Epoch 242 | loss = 5.9334\n",
      "Epoch 243 | loss = 5.9852\n",
      "Epoch 244 | loss = 5.9264\n",
      "Epoch 245 | loss = 5.9439\n",
      "Epoch 246 | loss = 5.9148\n",
      "Epoch 247 | loss = 5.9311\n",
      "Epoch 248 | loss = 5.9271\n",
      "Epoch 249 | loss = 5.9432\n",
      "Epoch 250 | loss = 5.8966\n",
      "Epoch 251 | loss = 5.9019\n",
      "Epoch 252 | loss = 5.9408\n",
      "Epoch 253 | loss = 5.9318\n",
      "Epoch 254 | loss = 5.9439\n",
      "Epoch 255 | loss = 5.9155\n",
      "Epoch 256 | loss = 5.9218\n",
      "Epoch 257 | loss = 5.9070\n",
      "Epoch 258 | loss = 5.8644\n",
      "Epoch 259 | loss = 5.9078\n",
      "Epoch 260 | loss = 5.9122\n",
      "Epoch 261 | loss = 5.9122\n",
      "Epoch 262 | loss = 5.9146\n",
      "Epoch 263 | loss = 5.9065\n",
      "Epoch 264 | loss = 5.8929\n",
      "Epoch 265 | loss = 5.9020\n",
      "Epoch 266 | loss = 5.8592\n",
      "Epoch 267 | loss = 5.8799\n",
      "Epoch 268 | loss = 5.8875\n",
      "Epoch 269 | loss = 5.8888\n",
      "Epoch 270 | loss = 5.9014\n",
      "Epoch 271 | loss = 5.8879\n",
      "Epoch 272 | loss = 5.8936\n",
      "Epoch 273 | loss = 5.8826\n",
      "Epoch 274 | loss = 5.8870\n"
     ]
    }
   ],
   "source": [
    "# Tov√°bbi tan√≠t√°s ‚Äî folytat√°s az el≈ëz≈ë checkpointb√≥l\n",
    "EXTRA_EPOCHS = 200   # pl. m√©g 25 epoch\n",
    "START = 75          # el≈ëz≈ë utols√≥ epoch ut√°n\n",
    "\n",
    "for epoch in range(START, START + EXTRA_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    perm = indices[torch.randperm(len(indices))]\n",
    "    num_batches = math.ceil(len(perm) / BATCH_SIZE)\n",
    "\n",
    "    for start in range(0, len(perm), BATCH_SIZE):\n",
    "        idx = perm[start:start + BATCH_SIZE]\n",
    "        q_batch = q_emb[idx]\n",
    "        pos_batch = pos_function_idx[idx]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        func_emb = model(data.x, data.edge_index)\n",
    "        loss = info_nce(q_batch, func_emb, pos_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch:02d} | loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f74dc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: How is PCA implemented?\n",
      "\n",
      "Top-k related functions:\n",
      "\n",
      " 1. BayesianGaussianMixture._estimate_precisions (score=0.1896)\n",
      "   Estimate the precisions parameters of the precision distribution.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "nk : array-like of shape (n_components,)\n",
      "\n",
      "xk : array-like of shape (n_components, n_feature...\n",
      "\n",
      " 2. Kernel.requires_vector_input (score=0.1804)\n",
      "   Returns whether the kernel is defined on fixed-length feature\n",
      "vectors or generic objects. Defaults to True for backward\n",
      "compatibility.\n",
      "\n",
      " 3. _check_precision_positivity (score=0.1803)\n",
      "   Check a precision vector is positive-definite.\n",
      "\n",
      " 4. BayesianGaussianMixture._check_precision_parameters (score=0.1760)\n",
      "   Check the prior parameters of the precision distribution.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "X : array-like of shape (n_samples, n_features)\n",
      "\n",
      " 5. KNeighborsClassifier.score (score=0.1671)\n",
      "   Return the mean accuracy on the given test data and labels.\n",
      "\n",
      "In multi-label classification, this is the subset accuracy\n",
      "which is a harsh metric since you require for each sample th...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% -----------------------------------------------\n",
    "# Real-time k√©rdez√©s a tan√≠tott function-GNN modellen\n",
    "# -----------------------------------------------\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "qa_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_function_embeddings():\n",
    "    \"\"\"GNN √°ltal tanult function embeddingek (384-D t√©rben).\"\"\"\n",
    "    func_emb = model(data.x.to(device), data.edge_index.to(device))\n",
    "    func_emb = F.normalize(func_emb, dim=-1)\n",
    "    return func_emb\n",
    "\n",
    "func_emb = get_function_embeddings()\n",
    "\n",
    "def ask(question: str, k: int = 5):\n",
    "    \"\"\"Adott k√©rd√©shez legrelev√°nsabb function node-ok lek√©rdez√©se.\"\"\"\n",
    "    q_vec = qa_encoder.encode([question], convert_to_tensor=True).to(device)\n",
    "    q_vec = F.normalize(q_vec, dim=-1)\n",
    "    sim = q_vec @ func_emb.T\n",
    "    top_vals, top_idx = torch.topk(sim, k)\n",
    "\n",
    "    print(f\"\\n‚ùì Question: {question}\\n\")\n",
    "    print(\"Top-k related functions:\\n\")\n",
    "    for rank, (fid, score) in enumerate(zip(top_idx[0].tolist(), top_vals[0].tolist()), start=1):\n",
    "        name = repograph[\"function_nodes\"].iloc[fid][\"combinedName\"]\n",
    "        doc = repograph[\"function_nodes\"].iloc[fid][\"docstring\"]\n",
    "        print(f\"{rank:>2}. {name} (score={score:.4f})\")\n",
    "        if isinstance(doc, str) and doc.strip():\n",
    "            print(f\"   {doc[:180]}{'...' if len(doc) > 180 else ''}\\n\")\n",
    "\n",
    "# P√©lda:\n",
    "ask(\"How is PCA implemented?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a350e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: Which test in `sklearn/ensemble/tests/test_bagging.py` was updated to use the `global_random_seed` fixture?\n",
      "\n",
      "Top-k related functions:\n",
      "\n",
      " 1. test_newrand_set_seed (score=0.4508)\n",
      "   Test that `set_seed` produces deterministic results\n",
      "\n",
      " 2. pytest_generate_tests (score=0.3875)\n",
      "   Parametrization of global_random_seed fixture\n",
      "\n",
      "based on the SKLEARN_TESTS_GLOBAL_RANDOM_SEED environment variable.\n",
      "\n",
      "The goal of this fixture is to prevent tests that use it to be s...\n",
      "\n",
      " 3. test_newrand_set_seed_overflow (score=0.3630)\n",
      "   Test that `set_seed_wrap` is defined for unsigned 32bits ints\n",
      "\n",
      " 4. test_affinity_propagation_random_state (score=0.3146)\n",
      "   Check that different random states lead to different initialisations\n",
      "by looking at the center locations after two iterations.\n",
      "\n",
      " 5. test_kernel_pca_precomputed (score=0.2819)\n",
      "   Test that kPCA works with a precomputed kernel, for all solvers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"Which test in `sklearn/ensemble/tests/test_bagging.py` was updated to use the `global_random_seed` fixture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea535591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoder: sentence-transformers (all-MiniLM-L6-v2)\n",
      "Node types: ['function', 'cluster']\n",
      "Edge types: [('cluster', 'has_function', 'function')]\n",
      "('cluster', 'has_function', 'function'): 11128 edges\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Assumes your KG dict is already in `repograph` (from your notebook).\n",
    "# If not, uncomment and adjust:\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# --- Node features ---\n",
    "# function: use precomputed docstring embeddings (robust parser)\n",
    "if \"function_nodes\" in repograph and \"docstring_embedding\" in repograph[\"function_nodes\"].columns:\n",
    "    fn_x = stack_series_to_tensor(repograph[\"function_nodes\"][\"docstring_embedding\"], fallback_dim=384)\n",
    "else:\n",
    "    # If you had no function embeddings, you could fall back to text encodings here.\n",
    "    raise RuntimeError(\"function_nodes['docstring_embedding'] not found; please ensure it's in the notebook.\")\n",
    "\n",
    "data[\"function\"].x = fn_x\n",
    "data[\"function\"].num_nodes = len(repograph[\"function_nodes\"])\n",
    "\n",
    "# cluster: encode summaries text (or fallback to zeros)\n",
    "if \"cluster_nodes\" in repograph and \"summary\" in repograph[\"cluster_nodes\"].columns:\n",
    "    encode = build_text_encoder()\n",
    "    cl_text = repograph[\"cluster_nodes\"][\"summary\"].fillna(\"\").astype(str).tolist()\n",
    "    cl_x = torch.tensor(encode(cl_text), dtype=torch.float)\n",
    "else:\n",
    "    cl_x = torch.zeros((len(repograph[\"cluster_nodes\"]), 384), dtype=torch.float)\n",
    "\n",
    "data[\"cluster\"].x = cl_x\n",
    "data[\"cluster\"].num_nodes = len(repograph[\"cluster_nodes\"])\n",
    "\n",
    "# --- Edges (keep the core structural edge; add more later if you like) ---\n",
    "assert \"cluster_function_edges\" in repograph, \"Expected 'cluster_function_edges' in repograph.\"\n",
    "cfe = repograph[\"cluster_function_edges\"][[\"source\",\"target\"]].to_numpy(dtype=np.int64).T\n",
    "data[(\"cluster\",\"has_function\",\"function\")].edge_index = torch.tensor(cfe, dtype=torch.long)\n",
    "\n",
    "print(\"Node types:\", data.node_types)\n",
    "print(\"Edge types:\", data.edge_types)\n",
    "for et in data.edge_types:\n",
    "    ei = data[et].edge_index\n",
    "    print(f\"{et}: {ei.size(1)} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c1f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA dataset: (433, 6)\n",
      "Columns: ['statements', 'comments', 'summaries', 'questions', 'answers', 'scores']\n",
      "Text encoder: sentence-transformers (all-MiniLM-L6-v2)\n",
      "Encoding QA questions and contexts...\n",
      "Generated embeddings: q_emb=(433, 384), ctx_emb=(433, 384)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Load QA dataset (text ‚Üí embedding) ---\n",
    "# If not loaded yet:\n",
    "qa_df = pd.read_csv(\"generated_qna_large_gpt.csv\", sep=\"\\t\").fillna(\"\")\n",
    "\n",
    "print(\"QA dataset:\", qa_df.shape)\n",
    "print(\"Columns:\", qa_df.columns.tolist())\n",
    "\n",
    "# Choose which text fields to embed\n",
    "QUESTION_TEXT_COL = \"questions\"\n",
    "CONTEXT_TEXT_COL  = \"summaries\"   # or \"answers\" if you prefer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# --- Text encoder (same as clusters) ---\n",
    "encode = build_text_encoder()\n",
    "\n",
    "# --- Compute embeddings ---\n",
    "print(\"Encoding QA questions and contexts...\")\n",
    "q_emb_np = encode(qa_df[QUESTION_TEXT_COL].astype(str).fillna(\"\").tolist())\n",
    "ctx_emb_np = encode(qa_df[CONTEXT_TEXT_COL].astype(str).fillna(\"\").tolist())\n",
    "\n",
    "# --- Convert to tensors ---\n",
    "q_emb = torch.tensor(q_emb_np, dtype=torch.float).to(device)\n",
    "ctx_emb = torch.tensor(ctx_emb_np, dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Generated embeddings: q_emb={tuple(q_emb.shape)}, ctx_emb={tuple(ctx_emb.shape)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0b4bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster text embeddings: (20, 384)\n",
      "positive cluster ids (sample): [11, 19, 19, 11, 11, 17, 17, 17, 11, 7, 17, 17, 17, 17, 18, 17, 19, 17, 17, 19, 11, 11, 17, 17, 17, 17, 11, 11, 17, 17, 17, 11, 17, 19, 5, 11, 17, 17, 11, 17, 11, 11, 17, 17, 17, 17, 11, 17, 4, 17, 11, 19, 19, 17, 19, 17, 17, 17, 17, 1, 17, 13, 17, 17, 11, 11, 1, 19, 5, 11, 17, 1, 17, 19, 17, 17, 17, 17, 17, 14, 11, 17, 17, 17, 17, 11, 17, 17, 17, 6, 17, 17, 11, 9, 17, 10, 17, 4, 17, 17]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17    219\n",
       "11    112\n",
       "19     29\n",
       "10     14\n",
       "5      13\n",
       "1       8\n",
       "4       8\n",
       "7       6\n",
       "3       5\n",
       "9       5\n",
       "18      4\n",
       "6       3\n",
       "13      2\n",
       "14      2\n",
       "16      2\n",
       "2       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# %%\n",
    "# Build a text embedding for cluster summaries using the SAME encoder as earlier (or parse if you precomputed them).\n",
    "# If you already have 'cluster_summary_emb' cached in your notebook, replace cl_text_emb accordingly.\n",
    "\n",
    "# If we used sentence-transformers above:\n",
    "try:\n",
    "    # Reuse the same encoder function built earlier\n",
    "    cl_text = repograph[\"cluster_nodes\"][\"summary\"].fillna(\"\").astype(str).tolist()\n",
    "    cl_text_emb = torch.tensor(encode(cl_text), dtype=torch.float).to(device)\n",
    "    print(\"Cluster text embeddings:\", tuple(cl_text_emb.shape))\n",
    "except Exception:\n",
    "    # fallback: use data[\"cluster\"].x as is\n",
    "    cl_text_emb = data[\"cluster\"].x.to(device)\n",
    "    print(\"Using cluster node features as text embeddings:\", tuple(cl_text_emb.shape))\n",
    "\n",
    "# Normalize\n",
    "ctx_n = F.normalize(ctx_emb, dim=-1)\n",
    "clt_n = F.normalize(cl_text_emb, dim=-1)\n",
    "\n",
    "# Map each QA row to its nearest cluster ID in text space (teacher)\n",
    "with torch.no_grad():\n",
    "    sim = ctx_n @ clt_n.T            # [num_qa, num_clusters]\n",
    "    pos_cluster_idx = sim.argmax(dim=1)  # [num_qa]\n",
    "pos_cluster_idx = pos_cluster_idx.detach()  # LongTensor\n",
    "print(\"positive cluster ids (sample):\", pos_cluster_idx[:100].tolist())\n",
    "\n",
    "# Show the counts of each cluster assignment\n",
    "pd.Series(pos_cluster_idx.cpu().numpy()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d621ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HGTConv\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class HeteroEncoder(nn.Module):\n",
    "    def __init__(self, data, hidden=256, num_layers=2, heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.metadata = (data.node_types, data.edge_types)\n",
    "        self.ntypes = data.node_types\n",
    "\n",
    "        self.proj = nn.ModuleDict({\n",
    "            n: nn.Linear(data[n].x.size(-1), hidden)\n",
    "            for n in self.ntypes if hasattr(data[n], \"x\") and data[n].x is not None\n",
    "        })\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            HGTConv(\n",
    "                in_channels=hidden,\n",
    "                out_channels=hidden,\n",
    "                metadata=self.metadata,\n",
    "                heads=heads\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.text_align = nn.Linear(hidden, hidden)  # <-- projection head\n",
    "\n",
    "        self.act = nn.GELU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = {n: self.act(self.proj[n](data[n].x)) for n in self.proj.keys()}\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, data.edge_index_dict)\n",
    "            for n in x:\n",
    "                x[n] = self.drop(self.act(x[n]))\n",
    "        # Apply projection to improve text‚Äìgraph alignment\n",
    "        for n in x:\n",
    "            x[n] = F.normalize(self.text_align(x[n]), dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# ‚ö†Ô∏è Add reverse edge\n",
    "rev = data[(\"cluster\", \"has_function\", \"function\")].edge_index.flip(0)\n",
    "data[(\"function\", \"rev_has_function\", \"cluster\")].edge_index = rev\n",
    "\n",
    "# ‚úÖ Reinitialize model + optimizer\n",
    "model = HeteroEncoder(data, hidden=64, num_layers=2, heads=4, dropout=0.05).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f441f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pos_function_idx from QA dataset via semantic similarity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348/348 [00:22<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ pos_function_idx generated for 433 questions.\n",
      "‚úÖ Using 384 aligned QA pairs for training\n",
      "Epoch 01 | loss = 4.2364\n",
      "Epoch 02 | loss = 4.3104\n",
      "Epoch 03 | loss = 4.2208\n",
      "Epoch 04 | loss = 4.3034\n",
      "Epoch 05 | loss = 4.2189\n",
      "Epoch 06 | loss = 4.2377\n",
      "Epoch 07 | loss = 4.0687\n",
      "Epoch 08 | loss = 4.1512\n",
      "Epoch 09 | loss = 4.1198\n",
      "Epoch 10 | loss = 4.1452\n",
      "Epoch 11 | loss = 4.2068\n",
      "Epoch 12 | loss = 4.1260\n",
      "Epoch 13 | loss = 4.2332\n",
      "Epoch 14 | loss = 4.1671\n",
      "Epoch 15 | loss = 4.0344\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import util\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1Ô∏è‚É£ InfoNCE (CLIP-style in-batch variant)\n",
    "# ----------------------------------------------------------\n",
    "def info_nce_inbatch(q, items, temperature=0.02):\n",
    "    \"\"\"\n",
    "    Contrastive InfoNCE with in-batch negatives.\n",
    "    Each query is paired with its corresponding item in the same batch.\n",
    "    \"\"\"\n",
    "    q = F.normalize(q, dim=-1)\n",
    "    items = F.normalize(items, dim=-1)\n",
    "\n",
    "    logits = q @ items.T / temperature          # [B, B]\n",
    "    labels = torch.arange(q.size(0), device=q.device)  # positives are diagonal\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Ensure pos_function_idx exists and data aligned\n",
    "# ----------------------------------------------------------\n",
    "if \"pos_function_idx\" not in locals() or len(pos_function_idx) != len(qa_df):\n",
    "    print(\"Generating pos_function_idx from QA dataset via semantic similarity...\")\n",
    "\n",
    "    func_texts = repograph[\"function_nodes\"][\"combinedName\"].tolist()\n",
    "    func_embs = qa_encoder.encode(\n",
    "        func_texts,\n",
    "        convert_to_tensor=True,\n",
    "        device=device,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    pos_function_idx_list = []\n",
    "    for q in qa_df[\"questions\"]:\n",
    "        q_emb = qa_encoder.encode(q, convert_to_tensor=True, device=device)\n",
    "        cos_sim = util.cos_sim(q_emb, func_embs)[0]\n",
    "        best_func = int(torch.argmax(cos_sim))\n",
    "        pos_function_idx_list.append(best_func)\n",
    "\n",
    "    pos_function_idx = torch.tensor(pos_function_idx_list, dtype=torch.long, device=device)\n",
    "    print(f\"‚úÖ pos_function_idx generated for {len(pos_function_idx)} questions.\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Align all arrays to the same length\n",
    "# ----------------------------------------------------------\n",
    "n_q = min(len(q_emb), len(pos_cluster_idx), len(pos_function_idx))\n",
    "q_emb = q_emb[:n_q]\n",
    "pos_cluster_idx = pos_cluster_idx[:n_q]\n",
    "pos_function_idx = pos_function_idx[:n_q]\n",
    "indices = torch.arange(n_q, device=device)\n",
    "print(f\"‚úÖ Using {n_q} aligned QA pairs for training\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Dual in-batch InfoNCE training loop (cluster + function)\n",
    "# ----------------------------------------------------------\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    perm = indices[torch.randperm(len(indices))]\n",
    "    num_batches = math.ceil(len(perm) / BATCH_SIZE)\n",
    "\n",
    "    for start in range(0, len(perm), BATCH_SIZE):\n",
    "        idx = perm[start:start + BATCH_SIZE]\n",
    "\n",
    "        # slice aligned batches\n",
    "        q_batch = q_emb[idx]\n",
    "        pos_cluster_batch = pos_cluster_idx[idx]\n",
    "        pos_func_batch = pos_function_idx[idx]\n",
    "\n",
    "        # ensure 2D queries\n",
    "        if q_batch.ndim == 1:\n",
    "            q_batch = q_batch.unsqueeze(0)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass through GNN\n",
    "        xdict = model(data)\n",
    "        cl_all = F.normalize(xdict[\"cluster\"], dim=-1)\n",
    "        func_all = F.normalize(xdict[\"function\"], dim=-1)\n",
    "\n",
    "        # gather the positive cluster/function embeddings for this batch\n",
    "        cl_batch = cl_all[pos_cluster_batch]\n",
    "        func_batch = func_all[pos_func_batch]\n",
    "\n",
    "        # compute dual InfoNCE losses\n",
    "        loss_cluster, _ = info_nce_inbatch(q_batch, cl_batch, temperature=0.02)\n",
    "        loss_func, _ = info_nce_inbatch(q_batch, func_batch, temperature=0.02)\n",
    "        loss = 0.5 * loss_cluster + 0.5 * loss_func\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch:02d} | loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bad45d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this small adapter layer once\n",
    "model.text_align = torch.nn.Linear(64, 384).to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_function_embeddings():\n",
    "    xdict = model(data.to(device))\n",
    "    func_emb = F.normalize(model.text_align(xdict[\"function\"]), dim=-1)\n",
    "    return func_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "588f756d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x384 and 64x11128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow is PCA implemented?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arion\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mask\u001b[39m\u001b[34m(question, k)\u001b[39m\n\u001b[32m     28\u001b[39m q_vec = F.normalize(q_vec, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Cosine similarity\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m sim = (\u001b[43mq_vec\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_emb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m).squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     33\u001b[39m top_vals, top_idx = torch.topk(sim, k)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚ùì Question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1x384 and 64x11128)"
     ]
    }
   ],
   "source": [
    "ask(\"How is PCA implemented?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc112017",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (11128x384 and 64x384)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     func_emb = F.normalize(func_emb, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func_emb\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m function_emb = \u001b[43mget_function_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mask\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m, k: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Retrieve top-k most relevant functions for a natural language question.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arion\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mget_function_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Extract normalized function embeddings in text space (384-D).\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m xdict = model(data.to(device))\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m func_emb = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_align\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# project to text space (no-op if already 384)\u001b[39;00m\n\u001b[32m     17\u001b[39m func_emb = F.normalize(func_emb, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func_emb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arion\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arion\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arion\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (11128x384 and 64x384)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "qa_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# üîß Fix: make sure projection matches GNN output\n",
    "if not hasattr(model, \"text_align\"):\n",
    "    model.text_align = torch.nn.Linear(384, 384).to(device)  # in_dim must match your GNN output dim\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_function_embeddings():\n",
    "    \"\"\"Extract normalized function embeddings in text space (384-D).\"\"\"\n",
    "    xdict = model(data.to(device))\n",
    "    func_emb = model.text_align(xdict[\"function\"])   # project to text space (no-op if already 384)\n",
    "    func_emb = F.normalize(func_emb, dim=-1)\n",
    "    return func_emb\n",
    "\n",
    "function_emb = get_function_embeddings()\n",
    "\n",
    "@torch.no_grad()\n",
    "def ask(question: str, k: int = 5):\n",
    "    \"\"\"Retrieve top-k most relevant functions for a natural language question.\"\"\"\n",
    "    q_vec = qa_encoder.encode([question], convert_to_tensor=True, device=device)\n",
    "    q_vec = F.normalize(q_vec, dim=-1)  # 384-D\n",
    "    sim = (q_vec @ function_emb.T).squeeze(0)\n",
    "\n",
    "    top_vals, top_idx = torch.topk(sim, k)\n",
    "    print(f\"\\n‚ùì Question: {question}\\n\")\n",
    "    print(\"Top-k related functions:\\n\")\n",
    "    for rank, (fid, score) in enumerate(zip(top_idx.tolist(), top_vals.tolist()), start=1):\n",
    "        name = repograph[\"function_nodes\"][\"combinedName\"].iloc[fid]\n",
    "        doc = repograph[\"function_nodes\"][\"docstring\"].iloc[fid]\n",
    "        snippet = (doc or \"\").replace(\"\\n\", \" \")[:180]\n",
    "        if len(doc) > 180:\n",
    "            snippet += \"...\"\n",
    "        print(f\"{rank:>2}. {name} (score={score:.4f})\\n   {snippet}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78289c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x64 and 384x11128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow is PCA implemented?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arion\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mask\u001b[39m\u001b[34m(question, k)\u001b[39m\n\u001b[32m     26\u001b[39m q_vec = F.normalize(q_vec, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Cosine similarity\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m sim = (\u001b[43mq_vec\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_emb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m).squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     31\u001b[39m top_vals, top_idx = torch.topk(sim, k)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚ùì Question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1x64 and 384x11128)"
     ]
    }
   ],
   "source": [
    "ask(\"How is PCA implemented?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
