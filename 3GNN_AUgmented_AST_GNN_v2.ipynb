{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35aeb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitek: ['train', 'validation', 'test']\n",
      "Használt split: train\n",
      "Oszlopok: ['functionSource', 'CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'combine']\n",
      "Feltételezett oszlopok → code: functionSource | label: CWE-119\n",
      "CWE-119\n",
      "False    0.981\n",
      "True     0.019\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>CWE-119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear_area(int startx, int starty, int xsize, int ysize)\\n{\\n  int x;\\n\\n  TRACE_LOG(\"Clearing area %d,%d / %d,%d\\n\", startx, starty, xsize, ysize);\\n\\n  wh...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReconstructDuList(Statement* head)\\n{\\n    Statement* spt;\\n\\n    for (spt = head; spt != NULL; spt = spt-&gt;next) {\\n\\tdelete_def_use_list(spt-&gt;use_var_list)...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free_speaker(void)\\n{\\n   if(Lengths)\\n       free(Lengths);\\n\\n   if(!audio2fast &amp;&amp; commento)\\n       fclose(commento);\\n\\n\\n   frase = NON_DECISA;\\n   gam...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlx4_register_device(struct mlx4_dev *dev)\\n{\\n\\tstruct mlx4_priv *priv = mlx4_priv(dev);\\n\\tstruct mlx4_interface *intf;\\n\\n\\tmutex_lock(&amp;intf_mutex);\\n\\n\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parse_Env_Var(void)\\n{\\n  char *p = getenv(\"LINEDIT\");\\n\\n  if (p == NULL)\\n    return;\\n\\n  if (strstr(p, \"gui=no\") != NULL)\\n    use_gui = 0;\\n      \\n  i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    functionSource  \\\n",
       "0  clear_area(int startx, int starty, int xsize, int ysize)\\n{\\n  int x;\\n\\n  TRACE_LOG(\"Clearing area %d,%d / %d,%d\\n\", startx, starty, xsize, ysize);\\n\\n  wh...   \n",
       "1  ReconstructDuList(Statement* head)\\n{\\n    Statement* spt;\\n\\n    for (spt = head; spt != NULL; spt = spt->next) {\\n\\tdelete_def_use_list(spt->use_var_list)...   \n",
       "2  free_speaker(void)\\n{\\n   if(Lengths)\\n       free(Lengths);\\n\\n   if(!audio2fast && commento)\\n       fclose(commento);\\n\\n\\n   frase = NON_DECISA;\\n   gam...   \n",
       "3  mlx4_register_device(struct mlx4_dev *dev)\\n{\\n\\tstruct mlx4_priv *priv = mlx4_priv(dev);\\n\\tstruct mlx4_interface *intf;\\n\\n\\tmutex_lock(&intf_mutex);\\n\\n\\...   \n",
       "4  Parse_Env_Var(void)\\n{\\n  char *p = getenv(\"LINEDIT\");\\n\\n  if (p == NULL)\\n    return;\\n\\n  if (strstr(p, \"gui=no\") != NULL)\\n    use_gui = 0;\\n      \\n  i...   \n",
       "\n",
       "   CWE-119  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4     True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Betöltés\n",
    "ds = load_dataset(\"claudios/Draper\")   # ha van 'train' split, azt fogod látni\n",
    "split = \"train\" if \"train\" in ds else list(ds.keys())[0]\n",
    "print(\"Splitek:\", list(ds.keys()))\n",
    "print(\"Használt split:\", split)\n",
    "\n",
    "# Pandas DataFrame-re alakítás\n",
    "df = pd.DataFrame({c: ds[split][c] for c in ds[split].column_names})\n",
    "print(\"Oszlopok:\", df.columns.tolist())\n",
    "\n",
    "# Céloszlop és kódoszlop gyors azonosítása (ha nem egyértelmű a név)\n",
    "def _auto_pick_columns(df):\n",
    "    code_col = None; label_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() in {\"code\",\"func\",\"function\",\"source\",\"source_code\",\"program\"}:\n",
    "            code_col = c; break\n",
    "    for c in df.columns:\n",
    "        if c.lower() in {\"label\",\"target\",\"y\",\"vul\",\"vulnerable\",\"bug\"}:\n",
    "            label_col = c; break\n",
    "    if code_col is None:\n",
    "        for c in df.columns:\n",
    "            if df[c].dtype == object:\n",
    "                code_col = c; break\n",
    "    if label_col is None:\n",
    "        for c in df.columns:\n",
    "            if pd.api.types.is_integer_dtype(df[c]) or pd.api.types.is_bool_dtype(df[c]):\n",
    "                label_col = c; break\n",
    "    return code_col, label_col\n",
    "\n",
    "code_col, label_col = _auto_pick_columns(df)\n",
    "print(\"Feltételezett oszlopok → code:\", code_col, \"| label:\", label_col)\n",
    "\n",
    "# Eloszlás\n",
    "if label_col:\n",
    "    print(df[label_col].value_counts(normalize=True).rename(\"proportion\").round(3))\n",
    "\n",
    "# Pár minta\n",
    "with pd.option_context(\"display.max_colwidth\", 160):\n",
    "    display(df[[code_col, label_col]].head(5) if label_col else df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Tree-Sitter OK, LANG = cpp\n",
      "Minták száma: 20000\n",
      "Oszlopok: ['code', 'label']\n",
      "Train: 16000 | arány:\n",
      " label\n",
      "0    0.981\n",
      "1    0.019\n",
      "Name: proportion, dtype: float64\n",
      "Val: 2000 | arány:\n",
      " label\n",
      "0    0.981\n",
      "1    0.019\n",
      "Name: proportion, dtype: float64\n",
      "Test: 2000 | arány:\n",
      " label\n",
      "0    0.982\n",
      "1    0.018\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16000/16000 [00:30<00:00, 528.09it/s]\n",
      "100%|██████████| 2000/2000 [00:04<00:00, 427.92it/s]\n",
      "100%|██████████| 2000/2000 [00:04<00:00, 479.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfok: 16000 2000 2000\n",
      "PyG gráfok: 16000 2000 2000 | vocab_size = 226\n",
      "pos_weight (BCE): 52.5117073059082\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) IMPORTOK + ALAP BEÁLLÍTÁS\n",
    "# =========================\n",
    "import os, json, random, hashlib\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")      # NVIDIA, vagy PyTorch-ROCm build AMD-re (Linux)\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")       # Apple Silicon\n",
    "    if hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "        return torch.device(\"xpu\")       # Intel GPU (IPEX)\n",
    "    try:\n",
    "        import torch_directml            # Windows DirectML\n",
    "        return torch_directml.device()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) PARAMÉTEREK\n",
    "# =========================\n",
    "SELECT_DATASET = 'draper_hf'     # 'code_x_glue' | 'draper_hf'\n",
    "LANG = 'cpp'                     # 'c' | 'cpp'\n",
    "MAX_SAMPLES = 20000              # 0 → mind (óvatosan RAM/VRAM miatt)\n",
    "BATCH_TRAIN, BATCH_EVAL = 64, 128\n",
    "EPOCHS_GGNN, EPOCHS_GINE = 30, 20\n",
    "\n",
    "# one-hot hash bucket a levelek szövegéhez (normalizálás miatt lehet kicsi)\n",
    "TOK_DIM = 128                    # korábban 1024; normalizálással bőven elég 64–256\n",
    "TOK_SENTINEL = TOK_DIM           # üres/nem-levél → sentinel id\n",
    "\n",
    "EDGE_TYPES = {'parent':0, 'next_sibling':1, 'next_token':2}\n",
    "\n",
    "# =========================\n",
    "# 2) TREE-SITTER INIT (C/C++)\n",
    "# =========================\n",
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_c as tsc\n",
    "import tree_sitter_cpp as tscpp\n",
    "\n",
    "TS_LANG = Language(tsc.language()) if LANG.lower()=='c' else Language(tscpp.language())\n",
    "parser = Parser(TS_LANG)\n",
    "print('Tree-Sitter OK, LANG =', LANG)\n",
    "\n",
    "# =========================\n",
    "# 3) ADATBETÖLTÉS + CÉL OSZLOPOK\n",
    "# =========================\n",
    "def _normalize_label(x):\n",
    "    if isinstance(x, str):\n",
    "        xs = x.strip().lower()\n",
    "        if xs in {'1','vul','vulnerable','pos','positive','true','bug'}: return 1\n",
    "        if xs in {'0','non-vul','nonvul','benign','safe','neg','negative','false','clean'}: return 0\n",
    "    try:\n",
    "        return 1 if int(x)==1 else 0\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _auto_pick_columns(df: pd.DataFrame):\n",
    "    code_col = None; label_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() in {'code','func','function','source','source_code','program'}:\n",
    "            code_col = c; break\n",
    "    for c in df.columns:\n",
    "        if c.lower() in {'label','target','y','vul','vulnerable','bug'}:\n",
    "            label_col = c; break\n",
    "    if code_col is None:\n",
    "        for c in df.columns:\n",
    "            if df[c].dtype==object:\n",
    "                code_col = c; break\n",
    "    if label_col is None:\n",
    "        for c in df.columns:\n",
    "            if pd.api.types.is_integer_dtype(df[c]) or pd.api.types.is_bool_dtype(df[c]):\n",
    "                label_col = c; break\n",
    "    return code_col, label_col\n",
    "\n",
    "def load_any_dataset(select: str) -> pd.DataFrame:\n",
    "    s = select.lower()\n",
    "    if s == 'code_x_glue':\n",
    "        ds = load_dataset('google/code_x_glue_cc_defect_detection')\n",
    "        df = pd.DataFrame({'code': ds['train']['func'], 'label': ds['train']['target']})\n",
    "        df['label'] = df['label'].apply(_normalize_label)\n",
    "        return df.dropna(subset=['code','label']).reset_index(drop=True)\n",
    "    elif s == 'draper_hf':\n",
    "        ds = load_dataset('claudios/Draper')\n",
    "        split = 'train' if 'train' in ds else list(ds.keys())[0]\n",
    "        df = pd.DataFrame({c: ds[split][c] for c in ds[split].column_names})\n",
    "        ccol, lcol = _auto_pick_columns(df)\n",
    "        df = df[[ccol, lcol]].rename(columns={ccol:'code', lcol:'label'})\n",
    "        df['label'] = df['label'].apply(_normalize_label)\n",
    "        return df.dropna(subset=['code','label']).reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError(select)\n",
    "\n",
    "raw_df = load_any_dataset(SELECT_DATASET)\n",
    "# --- Kiegyensúlyozás: ~10% pozitív (összes pozitív megtartása, negatívakból mintavétel) ---\n",
    "def make_about_10pct_pos(df: pd.DataFrame, seed: int = SEED, neg_per_pos: int = 9) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    df_pos = df[df['label'] == 1]\n",
    "    df_neg = df[df['label'] == 0]\n",
    "    if len(df_pos) == 0:\n",
    "        raise ValueError(\"Nincs pozitív minta a datasetben, nem lehet kiegyensúlyozni.\")\n",
    "\n",
    "    target_neg = min(len(df_neg), neg_per_pos * len(df_pos))   # ~10% pozitív → 1 : 9 arány\n",
    "    df_neg_sampled = df_neg.sample(target_neg, random_state=seed)\n",
    "\n",
    "    df_bal = pd.concat([df_pos, df_neg_sampled]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    return df_bal\n",
    "\n",
    "raw_df = make_about_10pct_pos(raw_df, seed=SEED, neg_per_pos=9)\n",
    "\n",
    "# MAX_SAMPLES alkalmazása STRATIFIKÁLTAN, hogy az arány megmaradjon\n",
    "from sklearn.model_selection import train_test_split\n",
    "if MAX_SAMPLES and len(raw_df) > MAX_SAMPLES:\n",
    "    raw_df, _ = train_test_split(\n",
    "        raw_df, train_size=MAX_SAMPLES, stratify=raw_df['label'], random_state=SEED\n",
    "    )\n",
    "\n",
    "raw_df['label'] = raw_df['label'].astype(int)\n",
    "print('Kiegyensúlyozott minták száma:', len(raw_df))\n",
    "print('Arányok:\\n', raw_df['label'].value_counts(normalize=True).rename('proportion').round(3))\n",
    "display_cols = raw_df.columns.tolist()\n",
    "print(\"Oszlopok:\", display_cols)\n",
    "\n",
    "# =========================\n",
    "# 4) KÓDNORMALIZÁLÁS (alpha-renaming, literál-helyettesítés)\n",
    "#    - függvénynév: FUNC_i\n",
    "#    - paraméterek: PARAM_1, PARAM_2, ...\n",
    "#    - lokális változók: VAR_1, VAR_2, ...\n",
    "#    - literálok: <NUM>, <STR>, <CHAR>\n",
    "# Megjegyzés: ez egy gyakorlatias, egyszerűsített megoldás, a legtöbb esetet jól fedi.\n",
    "# =========================\n",
    "def normalize_code(code: str) -> str:\n",
    "    text = code.encode(\"utf8\")\n",
    "    try:\n",
    "        tree = parser.parse(text)\n",
    "        root = tree.root_node\n",
    "    except Exception:\n",
    "        # parser hiba esetén fallback: nagyon egyszerű normalizálás\n",
    "        import re\n",
    "        code = re.sub(r'\\\"([^\"\\\\]|\\\\.)*\\\"', '<STR>', code)\n",
    "        code = re.sub(r\"\\'([^'\\\\]|\\\\.)*\\'\", '<CHAR>', code)\n",
    "        code = re.sub(r'\\b\\d+(\\.\\d+)?\\b', '<NUM>', code)\n",
    "        return code\n",
    "\n",
    "    scope_stack = []  # list of dicts: {\"func\":str, \"params\":{}, \"vars\":{}}\n",
    "    counters = {\"func\":0}\n",
    "\n",
    "    def push_scope():\n",
    "        scope_stack.append({\"func\":None, \"params\":{}, \"vars\":{}})\n",
    "    def pop_scope():\n",
    "        scope_stack.pop()\n",
    "    def get_id(node):\n",
    "        return text[node.start_byte:node.end_byte].decode(\"utf8\",\"ignore\")\n",
    "    def assign_param(name, scope):\n",
    "        if name in scope[\"params\"]: return scope[\"params\"][name]\n",
    "        idx = len(scope[\"params\"]) + 1\n",
    "        scope[\"params\"][name] = f\"PARAM_{idx}\"\n",
    "        return scope[\"params\"][name]\n",
    "    def assign_var(name, scope):\n",
    "        if name in scope[\"vars\"]: return scope[\"vars\"][name]\n",
    "        idx = len(scope[\"vars\"]) + 1\n",
    "        scope[\"vars\"][name] = f\"VAR_{idx}\"\n",
    "        return scope[\"vars\"][name]\n",
    "    LITS = {\"number_literal\":\"<NUM>\", \"string_literal\":\"<STR>\", \"char_literal\":\"<CHAR>\"}\n",
    "\n",
    "    # Első passz: scope-ok/deklarációk\n",
    "    def first_pass(node):\n",
    "        t = node.type\n",
    "        if t == \"function_definition\":\n",
    "            push_scope()\n",
    "            # function_declarator: azonosító + param lista\n",
    "            func_decl = None\n",
    "            for ch in node.children:\n",
    "                if ch.type == \"function_declarator\":\n",
    "                    func_decl = ch; break\n",
    "            if func_decl is not None:\n",
    "                # függvénynév FUNC_i\n",
    "                for ch in func_decl.children:\n",
    "                    if ch.type == \"identifier\":\n",
    "                        counters[\"func\"] += 1\n",
    "                        scope_stack[-1][\"func\"] = f\"FUNC_{counters['func']}\"\n",
    "                        break\n",
    "                # paraméter nevek\n",
    "                for ch in func_decl.children:\n",
    "                    if ch.type == \"parameter_list\":\n",
    "                        for p in ch.children:\n",
    "                            if p.type == \"parameter_declaration\":\n",
    "                                for gch in p.children:\n",
    "                                    if gch.type == \"identifier\":\n",
    "                                        assign_param(get_id(gch), scope_stack[-1])\n",
    "            # bejárt gyerekek\n",
    "            for ch in node.children:\n",
    "                first_pass(ch)\n",
    "            pop_scope()\n",
    "            return\n",
    "\n",
    "        # lokális deklarációk (egyszerűsítve)\n",
    "        if scope_stack:\n",
    "            if t in {\"init_declarator\", \"declarator\"}:\n",
    "                for ch in node.children:\n",
    "                    if ch.type == \"identifier\":\n",
    "                        assign_var(get_id(ch), scope_stack[-1])\n",
    "\n",
    "        for ch in node.children:\n",
    "            first_pass(ch)\n",
    "\n",
    "    # Második passz: kibocsátás\n",
    "    def lookup_identifier(name):\n",
    "        for sc in reversed(scope_stack):\n",
    "            if name in sc[\"params\"]: return sc[\"params\"][name]\n",
    "            if name in sc[\"vars\"]: return sc[\"vars\"][name]\n",
    "        return name\n",
    "\n",
    "    def second_pass(node):\n",
    "        t = node.type\n",
    "        if t == \"function_definition\":\n",
    "            push_scope()\n",
    "            out = []\n",
    "            for ch in node.children:\n",
    "                out.append(second_pass(ch))\n",
    "            pop_scope()\n",
    "            return \"\".join(out)\n",
    "\n",
    "        if t in LITS:\n",
    "            return LITS[t]\n",
    "\n",
    "        if t == \"identifier\":\n",
    "            # ha function_declarator gyereke és ez a név: FUNC_i\n",
    "            if scope_stack and scope_stack[-1][\"func\"] is not None:\n",
    "                parent = node.parent\n",
    "                if parent and parent.type == \"function_declarator\":\n",
    "                    return scope_stack[-1][\"func\"]\n",
    "            return lookup_identifier(get_id(node))\n",
    "\n",
    "        # Levél: visszaadjuk az eredeti lexémát\n",
    "        if len(node.children) == 0:\n",
    "            return text[node.start_byte:node.end_byte].decode(\"utf8\",\"ignore\")\n",
    "        # Összefűzzük a gyerekek kibocsátását\n",
    "        parts = []\n",
    "        for ch in node.children:\n",
    "            parts.append(second_pass(ch))\n",
    "        return \"\".join(parts)\n",
    "\n",
    "    # futtatás\n",
    "    try:\n",
    "        first_pass(root)\n",
    "        return second_pass(root)\n",
    "    except Exception:\n",
    "        # Ha bármi gond, biztonságos fallback literálokra\n",
    "        import re\n",
    "        code = text.decode(\"utf8\",\"ignore\")\n",
    "        code = re.sub(r'\\\"([^\"\\\\]|\\\\.)*\\\"', '<STR>', code)\n",
    "        code = re.sub(r\"\\'([^'\\\\]|\\\\.)*\\'\", '<CHAR>', code)\n",
    "        code = re.sub(r'\\b\\d+(\\.\\d+)?\\b', '<NUM>', code)\n",
    "        return code\n",
    "\n",
    "# =========================\n",
    "# 5) STRATIFIKÁLT SPLIT\n",
    "# =========================\n",
    "df_train, df_tmp = train_test_split(raw_df, test_size=0.2, stratify=raw_df['label'], random_state=SEED)\n",
    "df_val, df_test = train_test_split(df_tmp, test_size=0.5, stratify=df_tmp['label'], random_state=SEED)\n",
    "for name, df in [(\"Train\", df_train), (\"Val\", df_val), (\"Test\", df_test)]:\n",
    "    print(f\"{name}: {len(df)} | arány:\\n\", df['label'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# =========================\n",
    "# 6) AUGMENTED AST ÉPÍTÉS (normalizált kódból!)\n",
    "# =========================\n",
    "@dataclass\n",
    "class ASTGraph:\n",
    "    nodes: List[Dict[str, Any]]\n",
    "    edges: List[Tuple[int, int, str]]\n",
    "    label: int\n",
    "    raw: str\n",
    "\n",
    "def build_augmented_ast(code: str):\n",
    "    tree = parser.parse(code.encode('utf8'))\n",
    "    nodes, edges = [], []\n",
    "    nid = 0\n",
    "    def walk(node, parent_id=None, last_sib=None, depth=0):\n",
    "        nonlocal nid\n",
    "        my = nid; nid += 1\n",
    "        snippet = code.encode('utf8')[node.start_byte:node.end_byte]\n",
    "        children = node.children\n",
    "        nodes.append({\n",
    "            'id': my,\n",
    "            'type': node.type,\n",
    "            'is_leaf': int(len(children)==0),\n",
    "            'depth': depth,\n",
    "            'text': snippet.decode('utf8','ignore')\n",
    "        })\n",
    "        if parent_id is not None:\n",
    "            edges.append((parent_id, my, 'parent'))\n",
    "        if last_sib is not None:\n",
    "            edges.append((last_sib, my, 'next_sibling'))\n",
    "        prev = None\n",
    "        for ch in children:\n",
    "            ch_id = walk(ch, my, prev, depth+1)\n",
    "            if prev is not None:\n",
    "                edges.append((prev, ch_id, 'next_token'))\n",
    "            prev = ch_id\n",
    "        return my\n",
    "    walk(tree.root_node)\n",
    "    return nodes, edges\n",
    "\n",
    "def df_to_graphs(df: pd.DataFrame):\n",
    "    out = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        raw_code = str(row['code'])\n",
    "        code = normalize_code(raw_code)           # <<< NORMALIZÁLT!\n",
    "        y = int(row['label'])\n",
    "        n, e = build_augmented_ast(code)\n",
    "        out.append(ASTGraph(n,e,y,code))\n",
    "    return out\n",
    "\n",
    "graphs_train = df_to_graphs(df_train)\n",
    "graphs_val   = df_to_graphs(df_val)\n",
    "graphs_test  = df_to_graphs(df_test)\n",
    "print(\"Gráfok:\", len(graphs_train), len(graphs_val), len(graphs_test))\n",
    "\n",
    "# =========================\n",
    "# 7) PyG KONVERZIÓ + VOCAB\n",
    "# =========================\n",
    "class Vocab:\n",
    "    def __init__(self): self.map = {}\n",
    "    def id(self, k):\n",
    "        if k not in self.map: self.map[k] = len(self.map)\n",
    "        return self.map[k]\n",
    "    def size(self): return len(self.map)\n",
    "\n",
    "type_vocab = Vocab()\n",
    "\n",
    "def _hash_bucket(s: str, D: int = TOK_DIM) -> int:\n",
    "    if not s or not s.strip(): return TOK_SENTINEL\n",
    "    h = hashlib.md5(s.strip().encode('utf8')).hexdigest()\n",
    "    return int(h, 16) % D\n",
    "\n",
    "def to_pyg(gs):\n",
    "    pyg = []\n",
    "    for g in gs:\n",
    "        # type id\n",
    "        type_ids = [[type_vocab.id(n['type'])] for n in g.nodes]\n",
    "        x_type = torch.tensor(np.array(type_ids), dtype=torch.long)\n",
    "\n",
    "        # token bucket csak levelek text-jéből\n",
    "        tok_ids = [[_hash_bucket(n.get('text','') if n.get('is_leaf',0) else '', TOK_DIM)] for n in g.nodes]\n",
    "        x_tok = torch.tensor(np.array(tok_ids), dtype=torch.long)\n",
    "\n",
    "        # small numerikus: [is_leaf, depth_norm]\n",
    "        max_depth = max([n.get('depth',0) for n in g.nodes] + [1])\n",
    "        small = [[float(n.get('is_leaf',0)), float(n.get('depth',0))/float(max_depth)] for n in g.nodes]\n",
    "        x_small = torch.tensor(np.array(small), dtype=torch.float)\n",
    "\n",
    "        # élek\n",
    "        if len(g.edges)==0:\n",
    "            edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "            edge_type = torch.empty((0,), dtype=torch.long)\n",
    "        else:\n",
    "            src = [s for s,_,_ in g.edges]; dst = [d for _,d,_ in g.edges]\n",
    "            et  = [EDGE_TYPES[t] for *_,t in g.edges]\n",
    "            edge_index = torch.tensor([src,dst], dtype=torch.long)\n",
    "            edge_type  = torch.tensor(et, dtype=torch.long)\n",
    "\n",
    "        data = Data(edge_index=edge_index, y=torch.tensor([g.label], dtype=torch.long))\n",
    "        data.edge_type = edge_type\n",
    "        data.x_type = x_type\n",
    "        data.x_tok = x_tok\n",
    "        data.x_small = x_small\n",
    "        data.x = x_type.clone()  # kompatibilitás miatt\n",
    "        pyg.append(data)\n",
    "    return pyg\n",
    "\n",
    "pyg_train = to_pyg(graphs_train)\n",
    "pyg_val   = to_pyg(graphs_val)\n",
    "pyg_test  = to_pyg(graphs_test)\n",
    "\n",
    "vocab_size = type_vocab.size()\n",
    "print('PyG gráfok:', len(pyg_train), len(pyg_val), len(pyg_test), '| vocab_size =', vocab_size)\n",
    "\n",
    "# Loader-ek\n",
    "train_loader = DataLoader(pyg_train, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "val_loader   = DataLoader(pyg_val,   batch_size=BATCH_EVAL)\n",
    "test_loader  = DataLoader(pyg_test,  batch_size=BATCH_EVAL)\n",
    "\n",
    "# Osztálysúly BCE-hez: pos_weight = neg/pos\n",
    "y_train = np.array([int(g.y.item()) for g in pyg_train])\n",
    "pos = (y_train==1).sum(); neg = (y_train==0).sum()\n",
    "pos_weight = torch.tensor([max(1.0, neg/max(1,pos))], dtype=torch.float, device=device)\n",
    "print('pos_weight (BCE):', float(pos_weight.item()))\n",
    "\n",
    "# =========================\n",
    "# 8) GGNN MODELL (változatlan mélység: blocks=5, steps=10)\n",
    "#    - 1 logit kimenet (BCEWithLogitsLoss)\n",
    "# =========================\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GatedGraphConv, global_mean_pool\n",
    "\n",
    "class GGNNBlockFeats(nn.Module):\n",
    "    def __init__(self, channels: int, steps: int, num_edge_types: int = 3):\n",
    "        super().__init__()\n",
    "        self.num_edge_types = max(1, num_edge_types)\n",
    "        self.convs = nn.ModuleList([GatedGraphConv(channels, num_layers=steps) for _ in range(self.num_edge_types)])\n",
    "        self.norm = nn.LayerNorm(channels)\n",
    "    def forward(self, h, edge_index, edge_type=None):\n",
    "        if (edge_type is None) or (self.num_edge_types==1):\n",
    "            h_msg = self.convs[0](h, edge_index)\n",
    "        else:\n",
    "            parts=[]\n",
    "            for t, conv in enumerate(self.convs):\n",
    "                mask = (edge_type==t)\n",
    "                if mask.numel()>0 and int(mask.sum())>0:\n",
    "                    ei = edge_index[:, mask]\n",
    "                    parts.append(conv(h, ei))\n",
    "            h_msg = torch.stack(parts, dim=0).sum(dim=0) if parts else torch.zeros_like(h)\n",
    "        h = self.norm(h + h_msg)\n",
    "        return torch.relu(h)\n",
    "\n",
    "class GGNNClassifierFeatsNoEmb(nn.Module):\n",
    "    def __init__(self, num_types:int, tok_dim:int, small_dim:int=2,\n",
    "                 steps:int=10, blocks:int=5, num_edge_types:int=3, dropout:float=0.3):\n",
    "        super().__init__()\n",
    "        self.dim_type=num_types\n",
    "        self.dim_tok=tok_dim+1\n",
    "        self.dim_small=small_dim\n",
    "        self.channels = self.dim_type + self.dim_tok + self.dim_small\n",
    "        self.blocks = nn.ModuleList([GGNNBlockFeats(self.channels, steps, num_edge_types) for _ in range(blocks)])\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        # 1 logit a BCE-hez\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.channels,self.channels), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(self.channels,1)\n",
    "        )\n",
    "    def build_features(self, data):\n",
    "        xt = getattr(data,'x_type', getattr(data,'x'))\n",
    "        xt = xt.squeeze(-1) if xt.dim()==2 else xt\n",
    "        h_type = F.one_hot(xt.long(), num_classes=self.dim_type).float()\n",
    "\n",
    "        if hasattr(data,'x_tok'):\n",
    "            xk = data.x_tok; xk = xk.squeeze(-1) if xk.dim()==2 else xk\n",
    "            xk = xk.clamp(0, self.dim_tok-1).long()\n",
    "            h_tok = F.one_hot(xk, num_classes=self.dim_tok).float()\n",
    "        else:\n",
    "            N = h_type.size(0)\n",
    "            h_tok = torch.zeros((N,self.dim_tok), dtype=torch.float, device=h_type.device)\n",
    "            h_tok[:, self.dim_tok-1] = 1.0\n",
    "\n",
    "        h_small = getattr(data,'x_small', torch.zeros((h_type.size(0),self.dim_small), dtype=torch.float, device=h_type.device))\n",
    "        return torch.cat([h_type, h_tok, h_small], dim=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.build_features(data)\n",
    "        et = getattr(data,'edge_type', None)\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h, data.edge_index, et)\n",
    "        h = self.drop(h)\n",
    "        hg = global_mean_pool(h, data.batch)\n",
    "        return self.head(hg).view(-1)  # [B]\n",
    "\n",
    "# =========================\n",
    "# 9) TRÉNING LOOP (BCEWithLogitsLoss)\n",
    "# =========================\n",
    "MODEL = 'ggnn'  # 'ggnn' | 'gine' (itt GGNN marad)\n",
    "num_edge_types = len(EDGE_TYPES)\n",
    "\n",
    "model = GGNNClassifierFeatsNoEmb(\n",
    "    num_types=vocab_size, tok_dim=TOK_DIM, small_dim=2,\n",
    "    steps=10, blocks=5, num_edge_types=num_edge_types, dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "lr, epochs = 3e-4, EPOCHS_GGNN\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "# BCEWithLogitsLoss: pos_weight a pozitív osztály súlyozására\n",
    "crit = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "def run(loader, train=False):\n",
    "    model.train() if train else model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "        logits = model(batch)                   # [B]\n",
    "        target = batch.y.float().view(-1)       # [B]\n",
    "        loss = crit(logits, target)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            opt.step()\n",
    "        loss_sum += loss.item() * batch.num_graphs\n",
    "        prob = torch.sigmoid(logits)\n",
    "        pred = (prob >= 0.5).long()\n",
    "        correct += int((pred == batch.y).sum())\n",
    "        total += batch.num_graphs\n",
    "    return (loss_sum/total if total else 0.0), (correct/total if total else 0.0)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval(); y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            logits = model(batch)               # [B]\n",
    "            prob = torch.sigmoid(logits)\n",
    "            pred = (prob >= 0.5).long()\n",
    "            y_true += batch.y.cpu().tolist()\n",
    "            y_pred += pred.cpu().tolist()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, prec, rec, f1, cm\n",
    "\n",
    "# =========================\n",
    "# 10) TANÍTÁS + VALIDÁCIÓ + MENTÉS\n",
    "# =========================\n",
    "best_val, best_state = 0.0, None\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr_loss, tr_acc = run(train_loader, train=True)\n",
    "    va_acc, va_prec, va_rec, va_f1, _ = evaluate(val_loader)\n",
    "    if va_acc > best_val:\n",
    "        best_val, best_state = va_acc, model.state_dict()\n",
    "    print(f\"epoch {epoch:02d} | train acc {tr_acc:.3f} | val acc {va_acc:.3f} | val F1 {va_f1:.3f}\")\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "te_acc, te_prec, te_rec, te_f1, te_cm = evaluate(test_loader)\n",
    "print(\"TEST | acc:\", te_acc, \"| prec:\", te_prec, \"| rec:\", te_rec, \"| f1:\", te_f1)\n",
    "print(\"Confusion matrix:\\n\", te_cm)\n",
    "\n",
    "out_name = f'cpp_augast_GGNN_bce_best.pt'\n",
    "torch.save(model.state_dict(), out_name)\n",
    "print('Mentve:', out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e816c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv - szakdoga)",
   "language": "python",
   "name": "szakdoga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
