{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6011be28",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:2151\u001b[0m\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[0;32m   2137\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \n\u001b[0;32m   2143\u001b[0m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[0;32m   2144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2145\u001b[0m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[0;32m   2146\u001b[0m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[0;32m   2147\u001b[0m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[0;32m   2148\u001b[0m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[0;32m   2149\u001b[0m )\n\u001b[1;32m-> 2151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2152\u001b[0m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[0;32m   2153\u001b[0m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[0;32m   2154\u001b[0m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[0;32m   2155\u001b[0m     accelerator \u001b[38;5;28;01mas\u001b[39;00m accelerator,\n\u001b[0;32m   2156\u001b[0m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[0;32m   2157\u001b[0m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[0;32m   2158\u001b[0m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[0;32m   2159\u001b[0m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[0;32m   2160\u001b[0m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[0;32m   2161\u001b[0m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[0;32m   2162\u001b[0m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[0;32m   2163\u001b[0m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[0;32m   2164\u001b[0m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[0;32m   2165\u001b[0m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[0;32m   2166\u001b[0m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[0;32m   2167\u001b[0m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[0;32m   2168\u001b[0m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[0;32m   2169\u001b[0m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[0;32m   2170\u001b[0m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[0;32m   2171\u001b[0m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[0;32m   2172\u001b[0m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[0;32m   2173\u001b[0m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[0;32m   2174\u001b[0m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[0;32m   2175\u001b[0m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[0;32m   2176\u001b[0m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[0;32m   2177\u001b[0m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[0;32m   2178\u001b[0m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[0;32m   2179\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m   2180\u001b[0m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[0;32m   2181\u001b[0m )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\distributions\\__init__.py:95\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindependent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Independent\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minverse_gamma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InverseGamma\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_kl_info, kl_divergence, register_kl\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkumaraswamy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Kumaraswamy\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlaplace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Laplace\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\distributions\\kl.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mone_hot_categorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotCategorical\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpareto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pareto\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoisson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Poisson\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformed_distribution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformedDistribution\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muniform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Uniform\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) IMPORTOK + ALAP BEÁLLÍTÁS\n",
    "# =========================\n",
    "import os, json, random, hashlib\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# <<< CUDA allocator: ezt a torch import ELŐTT kell beállítani!\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:128\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")      # NVIDIA, vagy PyTorch-ROCm build AMD-re (Linux)\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")       # Apple Silicon\n",
    "    if hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "        return torch.device(\"xpu\")       # Intel GPU (IPEX)\n",
    "    try:\n",
    "        import torch_directml            # Windows DirectML\n",
    "        return torch_directml.device()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) PARAMÉTEREK\n",
    "# =========================\n",
    "SELECT_DATASET = 'draper_hf'     # 'code_x_glue' | 'draper_hf'\n",
    "LANG = 'cpp'                     # 'c' | 'cpp'\n",
    "MAX_SAMPLES = 20000              # 0 → mind (óvatosan RAM/VRAM miatt)\n",
    "BATCH_TRAIN, BATCH_EVAL = 64, 128\n",
    "EPOCHS_GGNN, EPOCHS_GINE = 30, 20\n",
    "\n",
    "# one-hot hash bucket a levelek szövegéhez (normalizálás miatt lehet kicsi)\n",
    "TOK_DIM = 128                    # korábban 1024; normalizálással bőven elég 64–256\n",
    "TOK_SENTINEL = TOK_DIM           # üres/nem-levél → sentinel id\n",
    "\n",
    "EDGE_TYPES = {'parent':0, 'next_sibling':1, 'next_token':2}\n",
    "\n",
    "# =========================\n",
    "# 2) TREE-SITTER INIT (C/C++)\n",
    "# =========================\n",
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_c as tsc\n",
    "import tree_sitter_cpp as tscpp\n",
    "\n",
    "TS_LANG = Language(tsc.language()) if LANG.lower()=='c' else Language(tscpp.language())\n",
    "parser = Parser(TS_LANG)\n",
    "print('Tree-Sitter OK, LANG =', LANG)\n",
    "\n",
    "# =========================\n",
    "# 3) ADATBETÖLTÉS + CÉL OSZLOPOK\n",
    "# =========================\n",
    "def _normalize_label(x):\n",
    "    if isinstance(x, str):\n",
    "        xs = x.strip().lower()\n",
    "        if xs in {'1','vul','vulnerable','pos','positive','true','bug'}: return 1\n",
    "        if xs in {'0','non-vul','nonvul','benign','safe','neg','negative','false','clean'}: return 0\n",
    "    try:\n",
    "        return 1 if int(x)==1 else 0\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _auto_pick_columns(df: pd.DataFrame):\n",
    "    code_col = None; label_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() in {'code','func','function','source','source_code','program'}:\n",
    "            code_col = c; break\n",
    "    for c in df.columns:\n",
    "        if c.lower() in {'label','target','y','vul','vulnerable','bug'}:\n",
    "            label_col = c; break\n",
    "    if code_col is None:\n",
    "        for c in df.columns:\n",
    "            if df[c].dtype==object:\n",
    "                code_col = c; break\n",
    "    if label_col is None:\n",
    "        for c in df.columns:\n",
    "            if pd.api.types.is_integer_dtype(df[c]) or pd.api.types.is_bool_dtype(df[c]):\n",
    "                label_col = c; break\n",
    "    return code_col, label_col\n",
    "\n",
    "def load_any_dataset(select: str) -> pd.DataFrame:\n",
    "    s = select.lower()\n",
    "    if s == 'code_x_glue':\n",
    "        ds = load_dataset('google/code_x_glue_cc_defect_detection')\n",
    "        df = pd.DataFrame({'code': ds['train']['func'], 'label': ds['train']['target']})\n",
    "        df['label'] = df['label'].apply(_normalize_label)\n",
    "        return df.dropna(subset=['code','label']).reset_index(drop=True)\n",
    "    elif s == 'draper_hf':\n",
    "        ds = load_dataset('claudios/Draper')\n",
    "        split = 'train' if 'train' in ds else list(ds.keys())[0]\n",
    "        df = pd.DataFrame({c: ds[split][c] for c in ds[split].column_names})\n",
    "        ccol, lcol = _auto_pick_columns(df)\n",
    "        df = df[[ccol, lcol]].rename(columns={ccol:'code', lcol:'label'})\n",
    "        df['label'] = df['label'].apply(_normalize_label)\n",
    "        return df.dropna(subset=['code','label']).reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError(select)\n",
    "\n",
    "raw_df = load_any_dataset(SELECT_DATASET)\n",
    "# --- Kiegyensúlyozás: ~10% pozitív (összes pozitív megtartása, negatívakból mintavétel) ---\n",
    "def make_about_10pct_pos(df: pd.DataFrame, seed: int = SEED, neg_per_pos: int = 9) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    df_pos = df[df['label'] == 1]\n",
    "    df_neg = df[df['label'] == 0]\n",
    "    if len(df_pos) == 0:\n",
    "        raise ValueError(\"Nincs pozitív minta a datasetben, nem lehet kiegyensúlyozni.\")\n",
    "\n",
    "    target_neg = min(len(df_neg), neg_per_pos * len(df_pos))   # ~10% pozitív → 1 : 9 arány\n",
    "    df_neg_sampled = df_neg.sample(target_neg, random_state=seed)\n",
    "\n",
    "    df_bal = pd.concat([df_pos, df_neg_sampled]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    return df_bal\n",
    "\n",
    "raw_df = make_about_10pct_pos(raw_df, seed=SEED, neg_per_pos=9)\n",
    "\n",
    "# MAX_SAMPLES alkalmazása STRATIFIKÁLTAN, hogy az arány megmaradjon\n",
    "from sklearn.model_selection import train_test_split\n",
    "if MAX_SAMPLES and len(raw_df) > MAX_SAMPLES:\n",
    "    raw_df, _ = train_test_split(\n",
    "        raw_df, train_size=MAX_SAMPLES, stratify=raw_df['label'], random_state=SEED\n",
    "    )\n",
    "\n",
    "raw_df['label'] = raw_df['label'].astype(int)\n",
    "print('Kiegyensúlyozott minták száma:', len(raw_df))\n",
    "print('Arányok:\\n', raw_df['label'].value_counts(normalize=True).rename('proportion').round(3))\n",
    "display_cols = raw_df.columns.tolist()\n",
    "print(\"Oszlopok:\", display_cols)\n",
    "\n",
    "# =========================\n",
    "# 4) KÓDNORMALIZÁLÁS (alpha-renaming, literál-helyettesítés)\n",
    "# =========================\n",
    "def normalize_code(code: str) -> str:\n",
    "    text = code.encode(\"utf8\")\n",
    "    try:\n",
    "        tree = parser.parse(text)\n",
    "        root = tree.root_node\n",
    "    except Exception:\n",
    "        # parser hiba esetén fallback: nagyon egyszerű normalizálás\n",
    "        import re\n",
    "        code = re.sub(r'\\\"([^\"\\\\]|\\\\.)*\\\"', '<STR>', code)\n",
    "        code = re.sub(r\"\\'([^'\\\\]|\\\\.)*\\'\", '<CHAR>', code)\n",
    "        code = re.sub(r'\\b\\d+(\\.\\d+)?\\b', '<NUM>', code)\n",
    "        return code\n",
    "\n",
    "    scope_stack = []  # list of dicts: {\"func\":str, \"params\":{}, \"vars\":{}}\n",
    "    counters = {\"func\":0}\n",
    "\n",
    "    def push_scope():\n",
    "        scope_stack.append({\"func\":None, \"params\":{}, \"vars\":{}})\n",
    "    def pop_scope():\n",
    "        scope_stack.pop()\n",
    "    def get_id(node):\n",
    "        return text[node.start_byte:node.end_byte].decode(\"utf8\",\"ignore\")\n",
    "    def assign_param(name, scope):\n",
    "        if name in scope[\"params\"]: return scope[\"params\"][name]\n",
    "        idx = len(scope[\"params\"]) + 1\n",
    "        scope[\"params\"][name] = f\"PARAM_{idx}\"\n",
    "        return scope[\"params\"][name]\n",
    "    def assign_var(name, scope):\n",
    "        if name in scope[\"vars\"]: return scope[\"vars\"][name]\n",
    "        idx = len(scope[\"vars\"]) + 1\n",
    "        scope[\"vars\"][name] = f\"VAR_{idx}\"\n",
    "        return scope[\"vars\"][name]\n",
    "    LITS = {\"number_literal\":\"<NUM>\", \"string_literal\":\"<STR>\", \"char_literal\":\"<CHAR>\"}\n",
    "\n",
    "    # Első passz: scope-ok/deklarációk\n",
    "    def first_pass(node):\n",
    "        t = node.type\n",
    "        if t == \"function_definition\":\n",
    "            push_scope()\n",
    "            # function_declarator: azonosító + param lista\n",
    "            func_decl = None\n",
    "            for ch in node.children:\n",
    "                if ch.type == \"function_declarator\":\n",
    "                    func_decl = ch; break\n",
    "            if func_decl is not None:\n",
    "                # függvénynév FUNC_i\n",
    "                for ch in func_decl.children:\n",
    "                    if ch.type == \"identifier\":\n",
    "                        counters[\"func\"] += 1\n",
    "                        scope_stack[-1][\"func\"] = f\"FUNC_{counters['func']}\"\n",
    "                        break\n",
    "                # paraméter nevek\n",
    "                for ch in func_decl.children:\n",
    "                    if ch.type == \"parameter_list\":\n",
    "                        for p in ch.children:\n",
    "                            if p.type == \"parameter_declaration\":\n",
    "                                for gch in p.children:\n",
    "                                    if gch.type == \"identifier\":\n",
    "                                        assign_param(get_id(gch), scope_stack[-1])\n",
    "            # bejárt gyerekek\n",
    "            for ch in node.children:\n",
    "                first_pass(ch)\n",
    "            pop_scope()\n",
    "            return\n",
    "\n",
    "        # lokális deklarációk (egyszerűsítve)\n",
    "        if scope_stack:\n",
    "            if t in {\"init_declarator\", \"declarator\"}:\n",
    "                for ch in node.children:\n",
    "                    if ch.type == \"identifier\":\n",
    "                        assign_var(get_id(ch), scope_stack[-1])\n",
    "\n",
    "        for ch in node.children:\n",
    "            first_pass(ch)\n",
    "\n",
    "    # Második passz: kibocsátás\n",
    "    def lookup_identifier(name):\n",
    "        for sc in reversed(scope_stack):\n",
    "            if name in sc[\"params\"]: return sc[\"params\"][name]\n",
    "            if name in sc[\"vars\"]: return sc[\"vars\"][name]\n",
    "        return name\n",
    "\n",
    "    def second_pass(node):\n",
    "        t = node.type\n",
    "        if t == \"function_definition\":\n",
    "            push_scope()\n",
    "            out = []\n",
    "            for ch in node.children:\n",
    "                out.append(second_pass(ch))\n",
    "            pop_scope()\n",
    "            return \"\".join(out)\n",
    "\n",
    "        if t in LITS:\n",
    "            return LITS[t]\n",
    "\n",
    "        if t == \"identifier\":\n",
    "            # ha function_declarator gyereke és ez a név: FUNC_i\n",
    "            if scope_stack and scope_stack[-1][\"func\"] is not None:\n",
    "                parent = node.parent\n",
    "                if parent and parent.type == \"function_declarator\":\n",
    "                    return scope_stack[-1][\"func\"]\n",
    "            return lookup_identifier(get_id(node))\n",
    "\n",
    "        # Levél: visszaadjuk az eredeti lexémát\n",
    "        if len(node.children) == 0:\n",
    "            return text[node.start_byte:node.end_byte].decode(\"utf8\",\"ignore\")\n",
    "        # Összefűzzük a gyerekek kibocsátását\n",
    "        parts = []\n",
    "        for ch in node.children:\n",
    "            parts.append(second_pass(ch))\n",
    "        return \"\".join(parts)\n",
    "\n",
    "    # futtatás\n",
    "    try:\n",
    "        first_pass(root)\n",
    "        return second_pass(root)\n",
    "    except Exception:\n",
    "        # Ha bármi gond, biztonságos fallback literálokra\n",
    "        import re\n",
    "        code = text.decode(\"utf8\",\"ignore\")\n",
    "        code = re.sub(r'\\\"([^\"\\\\]|\\\\.)*\\\"', '<STR>', code)\n",
    "        code = re.sub(r\"\\'([^'\\\\]|\\\\.)*\\'\", '<CHAR>', code)\n",
    "        code = re.sub(r'\\b\\d+(\\.\\d+)?\\b', '<NUM>', code)\n",
    "        return code\n",
    "\n",
    "# =========================\n",
    "# 5) STRATIFIKÁLT SPLIT\n",
    "# =========================\n",
    "df_train, df_tmp = train_test_split(raw_df, test_size=0.2, stratify=raw_df['label'], random_state=SEED)\n",
    "df_val, df_test = train_test_split(df_tmp, test_size=0.5, stratify=df_tmp['label'], random_state=SEED)\n",
    "for name, df in [(\"Train\", df_train), (\"Val\", df_val), (\"Test\", df_test)]:\n",
    "    print(f\"{name}: {len(df)} | arány:\\n\", df['label'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# =========================\n",
    "# 6) AUGMENTED AST ÉPÍTÉS (normalizált kódból!)\n",
    "# =========================\n",
    "@dataclass\n",
    "class ASTGraph:\n",
    "    nodes: List[Dict[str, Any]]\n",
    "    edges: List[Tuple[int, int, str]]\n",
    "    label: int\n",
    "    raw: str\n",
    "\n",
    "def build_augmented_ast(code: str):\n",
    "    tree = parser.parse(code.encode('utf8'))\n",
    "    nodes, edges = [], []\n",
    "    nid = 0\n",
    "    def walk(node, parent_id=None, last_sib=None, depth=0):\n",
    "        nonlocal nid\n",
    "        my = nid; nid += 1\n",
    "        snippet = code.encode('utf8')[node.start_byte:node.end_byte]\n",
    "        children = node.children\n",
    "        nodes.append({\n",
    "            'id': my,\n",
    "            'type': node.type,\n",
    "            'is_leaf': int(len(children)==0),\n",
    "            'depth': depth,\n",
    "            'text': snippet.decode('utf8','ignore')\n",
    "        })\n",
    "        if parent_id is not None:\n",
    "            edges.append((parent_id, my, 'parent'))\n",
    "        if last_sib is not None:\n",
    "            edges.append((last_sib, my, 'next_sibling'))\n",
    "        prev = None\n",
    "        for ch in children:\n",
    "            ch_id = walk(ch, my, prev, depth+1)\n",
    "            if prev is not None:\n",
    "                edges.append((prev, ch_id, 'next_token'))\n",
    "            prev = ch_id\n",
    "        return my\n",
    "    walk(tree.root_node)\n",
    "    return nodes, edges\n",
    "\n",
    "def df_to_graphs(df: pd.DataFrame):\n",
    "    out = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        raw_code = str(row['code'])\n",
    "        code = normalize_code(raw_code)           # <<< NORMALIZÁLT!\n",
    "        y = int(row['label'])\n",
    "        n, e = build_augmented_ast(code)\n",
    "        out.append(ASTGraph(n,e,y,code))\n",
    "    return out\n",
    "\n",
    "graphs_train = df_to_graphs(df_train)\n",
    "graphs_val   = df_to_graphs(df_val)\n",
    "graphs_test  = df_to_graphs(df_test)\n",
    "print(\"Gráfok:\", len(graphs_train), len(graphs_val), len(graphs_test))\n",
    "\n",
    "# =========================\n",
    "# 7) PyG KONVERZIÓ + VOCAB\n",
    "# =========================\n",
    "class Vocab:\n",
    "    def __init__(self): self.map = {}\n",
    "    def id(self, k):\n",
    "        if k not in self.map: self.map[k] = len(self.map)\n",
    "        return self.map[k]\n",
    "    def size(self): return len(self.map)\n",
    "\n",
    "type_vocab = Vocab()\n",
    "\n",
    "def _hash_bucket(s: str, D: int = TOK_DIM) -> int:\n",
    "    if not s or not s.strip(): return TOK_SENTINEL\n",
    "    h = hashlib.md5(s.strip().encode('utf8')).hexdigest()\n",
    "    return int(h, 16) % D\n",
    "\n",
    "def to_pyg(gs):\n",
    "    pyg = []\n",
    "    for g in gs:\n",
    "        # type id\n",
    "        type_ids = [[type_vocab.id(n['type'])] for n in g.nodes]\n",
    "        x_type = torch.tensor(np.array(type_ids), dtype=torch.long)\n",
    "\n",
    "        # token bucket csak levelek text-jéből\n",
    "        tok_ids = [[_hash_bucket(n.get('text','') if n.get('is_leaf',0) else '', TOK_DIM)] for n in g.nodes]\n",
    "        x_tok = torch.tensor(np.array(tok_ids), dtype=torch.long)\n",
    "\n",
    "        # small numerikus: [is_leaf, depth_norm]\n",
    "        max_depth = max([n.get('depth',0) for n in g.nodes] + [1])\n",
    "        small = [[float(n.get('is_leaf',0)), float(n.get('depth',0))/float(max_depth)] for n in g.nodes]\n",
    "        x_small = torch.tensor(np.array(small), dtype=torch.float)\n",
    "\n",
    "        # élek\n",
    "        if len(g.edges)==0:\n",
    "            edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "            edge_type = torch.empty((0,), dtype=torch.long)\n",
    "        else:\n",
    "            src = [s for s,_,_ in g.edges]; dst = [d for _,d,_ in g.edges]\n",
    "            et  = [EDGE_TYPES[t] for *_,t in g.edges]\n",
    "            edge_index = torch.tensor([src,dst], dtype=torch.long)\n",
    "            edge_type  = torch.tensor(et, dtype=torch.long)\n",
    "\n",
    "        data = Data(edge_index=edge_index, y=torch.tensor([g.label], dtype=torch.long))\n",
    "        data.edge_type = edge_type\n",
    "        data.x_type = x_type\n",
    "        data.x_tok = x_tok\n",
    "        data.x_small = x_small\n",
    "        data.x = x_type.clone()  # kompatibilitás miatt\n",
    "        pyg.append(data)\n",
    "    return pyg\n",
    "\n",
    "pyg_train = to_pyg(graphs_train)\n",
    "pyg_val   = to_pyg(graphs_val)\n",
    "pyg_test  = to_pyg(graphs_test)\n",
    "\n",
    "vocab_size = type_vocab.size()\n",
    "print('PyG gráfok:', len(pyg_train), len(pyg_val), len(pyg_test), '| vocab_size =', vocab_size)\n",
    "\n",
    "# Loader-ek\n",
    "train_loader = DataLoader(pyg_train, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "val_loader   = DataLoader(pyg_val,   batch_size=BATCH_EVAL)\n",
    "test_loader  = DataLoader(pyg_test,  batch_size=BATCH_EVAL)\n",
    "\n",
    "# Osztálysúly BCE-hez: pos_weight = neg/pos\n",
    "y_train = np.array([int(g.y.item()) for g in pyg_train])\n",
    "pos = (y_train==1).sum(); neg = (y_train==0).sum()\n",
    "pos_weight = torch.tensor([max(1.0, neg/max(1,pos))], dtype=torch.float, device=device)\n",
    "print('pos_weight (BCE):', float(pos_weight.item()))\n",
    "\n",
    "# =========================\n",
    "# 8) GGNN MODELL (változatlan mélység: blocks=5, steps=10)\n",
    "#    - 1 logit kimenet (BCEWithLogitsLoss)\n",
    "# =========================\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GatedGraphConv, global_mean_pool\n",
    "\n",
    "class GGNNBlockFeats(nn.Module):\n",
    "    def __init__(self, channels: int, steps: int, num_edge_types: int = 3):\n",
    "        super().__init__()\n",
    "        self.num_edge_types = max(1, num_edge_types)\n",
    "        self.convs = nn.ModuleList([GatedGraphConv(channels, num_layers=steps) for _ in range(self.num_edge_types)])\n",
    "        self.norm = nn.LayerNorm(channels)\n",
    "    def forward(self, h, edge_index, edge_type=None):\n",
    "        if (edge_type is None) or (self.num_edge_types==1):\n",
    "            h_msg = self.convs[0](h, edge_index)\n",
    "        else:\n",
    "            parts=[]\n",
    "            for t, conv in enumerate(self.convs):\n",
    "                mask = (edge_type==t)\n",
    "                if mask.numel()>0 and int(mask.sum())>0:\n",
    "                    ei = edge_index[:, mask]\n",
    "                    parts.append(conv(h, ei))\n",
    "            h_msg = torch.stack(parts, dim=0).sum(dim=0) if parts else torch.zeros_like(h)\n",
    "        h = self.norm(h + h_msg)\n",
    "        return torch.relu(h)\n",
    "\n",
    "class GGNNClassifierFeatsNoEmb(nn.Module):\n",
    "    def __init__(self, num_types:int, tok_dim:int, small_dim:int=2,\n",
    "                 steps:int=10, blocks:int=5, num_edge_types:int=3, dropout:float=0.3):\n",
    "        super().__init__()\n",
    "        self.dim_type=num_types\n",
    "        self.dim_tok=tok_dim+1\n",
    "        self.dim_small=small_dim\n",
    "        self.channels = self.dim_type + self.dim_tok + self.dim_small\n",
    "        self.blocks = nn.ModuleList([GGNNBlockFeats(self.channels, steps, num_edge_types) for _ in range(blocks)])\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        # 1 logit a BCE-hez\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.channels,self.channels), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(self.channels,1)\n",
    "        )\n",
    "    def build_features(self, data):\n",
    "        xt = getattr(data,'x_type', getattr(data,'x'))\n",
    "        xt = xt.squeeze(-1) if xt.dim()==2 else xt\n",
    "        h_type = F.one_hot(xt.long(), num_classes=self.dim_type).float()\n",
    "\n",
    "        if hasattr(data,'x_tok'):\n",
    "            xk = data.x_tok; xk = xk.squeeze(-1) if xk.dim()==2 else xk\n",
    "            xk = xk.clamp(0, self.dim_tok-1).long()\n",
    "            h_tok = F.one_hot(xk, num_classes=self.dim_tok).float()\n",
    "        else:\n",
    "            N = h_type.size(0)\n",
    "            h_tok = torch.zeros((N,self.dim_tok), dtype=torch.float, device=h_type.device)\n",
    "            h_tok[:, self.dim_tok-1] = 1.0\n",
    "\n",
    "        h_small = getattr(data,'x_small', torch.zeros((h_type.size(0),self.dim_small), dtype=torch.float, device=h_type.device))\n",
    "        return torch.cat([h_type, h_tok, h_small], dim=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.build_features(data)\n",
    "        et = getattr(data,'edge_type', None)\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h, data.edge_index, et)\n",
    "        h = self.drop(h)\n",
    "        hg = global_mean_pool(h, data.batch)\n",
    "        return self.head(hg).view(-1)  # [B]\n",
    "\n",
    "# =========================\n",
    "# 9) TRÉNING LOOP (BCEWithLogitsLoss) + AMP\n",
    "# =========================\n",
    "MODEL = 'ggnn'  # 'ggnn' | 'gine' (itt GGNN marad)\n",
    "num_edge_types = len(EDGE_TYPES)\n",
    "\n",
    "model = GGNNClassifierFeatsNoEmb(\n",
    "    num_types=vocab_size, tok_dim=TOK_DIM, small_dim=2,\n",
    "    steps=10, blocks=5, num_edge_types=num_edge_types, dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "lr, epochs = 3e-4, EPOCHS_GGNN\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "# BCEWithLogitsLoss: pos_weight a pozitív osztály súlyozására\n",
    "crit = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# <<< AMP bekapcsolása CUDA-n\n",
    "use_amp = (device.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "def run(loader, train=False):\n",
    "    model.train() if train else model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        # <<< autocast az előre- és veszteségszámításhoz\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            logits = model(batch)                   # [B]\n",
    "            target = batch.y.float().view(-1)       # [B]\n",
    "            loss = crit(logits, target)\n",
    "\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "        loss_sum += loss.item() * batch.num_graphs\n",
    "        prob = torch.sigmoid(logits)\n",
    "        pred = (prob >= 0.5).long()\n",
    "        correct += int((pred == batch.y).sum())\n",
    "        total += batch.num_graphs\n",
    "    return (loss_sum/total if total else 0.0), (correct/total if total else 0.0)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval(); y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        # <<< eval alatt is mehet autocast\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                logits = model(batch)               # [B]\n",
    "                prob = torch.sigmoid(logits)\n",
    "                pred = (prob >= 0.5).long()\n",
    "                y_true += batch.y.cpu().tolist()\n",
    "                y_pred += pred.cpu().tolist()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, prec, rec, f1, cm\n",
    "\n",
    "# =========================\n",
    "# 10) TANÍTÁS + VALIDÁCIÓ + MENTÉS\n",
    "# =========================\n",
    "best_val, best_state = 0.0, None\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr_loss, tr_acc = run(train_loader, train=True)\n",
    "    va_acc, va_prec, va_rec, va_f1, _ = evaluate(val_loader)\n",
    "    if va_acc > best_val:\n",
    "        best_val, best_state = va_acc, model.state_dict()\n",
    "    print(f\"epoch {epoch:02d} | train acc {tr_acc:.3f} | val acc {va_acc:.3f} | val F1 {va_f1:.3f}\")\n",
    "\n",
    "    # <<< VRAM tisztítás epoch végén (ha CUDA)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "te_acc, te_prec, te_rec, te_f1, te_cm = evaluate(test_loader)\n",
    "print(\"TEST | acc:\", te_acc, \"| prec:\", te_prec, \"| rec:\", te_rec, \"| f1:\", te_f1)\n",
    "print(\"Confusion matrix:\\n\", te_cm)\n",
    "\n",
    "out_name = f'cpp_augast_GGNN_bce_best.pt'\n",
    "torch.save(model.state_dict(), out_name)\n",
    "print('Mentve:', out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58e9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
