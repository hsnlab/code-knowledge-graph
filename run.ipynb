{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fdcb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szmid\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'graph_tool'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('package'))\n",
    "from package import KnowledgeGraphBuilder\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f296ee",
   "metadata": {},
   "source": [
    "# 1. Build knowledge graph\n",
    "\n",
    "Initialize the `KnowledgeGraphBuilder` object. A github token must be given as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50ba155",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./_/git_token.txt', 'r') as f:\n",
    "    git_token = f.read().strip()\n",
    "\n",
    "with open ('./_/hf_token.txt', 'r') as f:\n",
    "    hf_token = f.read().strip()\n",
    "\n",
    "kgb = KnowledgeGraphBuilder(git_token, hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b014a1f",
   "metadata": {},
   "source": [
    "Build the knowledge graph with the `KnowledgeGraphBuilder.build_knowledge_graph()` method. Parameters:\n",
    "- *repo_name*: Name of the repository. Must match the format \"owner/repo_name\", as it is used for github API calls.\n",
    "- *graph_type* (optional): Type of subgraph to build from the functions. Can be \"CFG\" (Control Flow Graph) or \"AST\" (Abstract Syntax Tree). Default is \"CFG\".\n",
    "- *num_of_PRs* (optional): Number of pull requests to retrieve in detail. Defaults to 0 (all).\n",
    "- *create_embedding* (optional): Whether to create embeddings for the nodes. Defaults to False.\n",
    "- *repo_path_modifier* (optional): Path modifier for the repository for cases when only a subfolder is meant to be parsed.\n",
    "- *URI* (optional): URI for the Neo4J data saving.\n",
    "- *user* (optional): Username for the Neo4J data saving.\n",
    "- *password* (optional): Password for the Neo4J data saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf28143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already exists here: ./repos\\scikit-learn\n",
      "Building CG...\n",
      "Creating subgraphs for each function...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10537it [51:01,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraphs created.\n",
      "Filtering graph nodes...\n",
      "Graph nodes filtered. Creating hierarchical edges...\n",
      "Hierarchical graph building successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 15.15it/s]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 20 with silhouette score: 0.01682088667840439\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nclone; clone parametrized; classifier mixin score; regressor mixin score; bicluster mixin biclusters; bicluster mixin get indices; bicluster mixin get shape; bicluster mixin get submatrix; density mixin score; is classifier; is regressor; is clusterer; is outlier detector; decorator; wrapper; calibrated classifier cv   init; calibrated classifier cv predict proba; calibrated classifier cv predict; calibrated classifier cv get metadata routing; calibrated classifier   init; calibrated classifier predict proba; sigmoid calibration; loss grad; convert to logits; sigmoid calibration predict; temperature scaling log loss; temperature scaling predict; calibration curve; calibration display   init; calibration display plot; calibration display from predictions; raccoon face or skip; global dtype; fetch fixture; wrapped; pytest collection modifyitems; pyplot; pytest generate tests; pytest configure; hide available pandas; mocked import; cov; class means; class cov; discriminant analysis prediction mixin decision function; discriminant analysis prediction mixin predict; discriminant analysis prediction mixin predict proba; discriminant analysis prediction mixin predict log proba; linear discriminant analysis   init; linear discriminant analysis  solve lstsq\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nclone, parametrized clone, classifier mixin score, regressor mixin score, bicluster mixin biclusters, bicluster mixin get indices, bicluster mixin get shape, bicl'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nbase estimator   dir; base estimator  get param names; base estimator get params; base estimator  get params html; base estimator is non default; base estimator set params; base estimator   sklearn clone; base estimator   repr; base estimator   getstate; base estimator   setstate; base estimator  validate params; calibrated classifier cv  get estimator; calibration display from estimator; fit estimator; available if estimator has; multi output estimator   init; multi output estimator fit; multi output estimator predict; multi output estimator get metadata routing; available if base estimator has; base chain  get estimator; final estimator has; test sparse coder estimator; base bagging  get estimator; bagging classifier  get estimator; bagging regressor  get estimator; fit single estimator; base ensemble  validate estimator; isolation forest  get estimator; dummy size estimator fit; dummy size estimator predict; test single estimator; test estimator; estimator accepting sample weight fit; estimator accepting sample weight predict; estimator rejecting sample weight fit; estimator rejecting sample weight predict; my estimator fit; test zero estimator reg; test zero estimator clf; my estimator fit; test voting classifier estimator init; test set estimator drop; test estimator weights format; test none estimator with weights; mock estimator predict proba; test estimator; dummy estimator fit; dummy estimator predict; get equivalent estimator\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nbase, estimator, fit, predict, parameters, calibration, bagging, ensemble, dummy, voting, mock, test, sample weight, sparse coder, isolation forest, chain, metadata routing, repr, get'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nbase estimator   sklearn tags; classifier mixin   sklearn tags; regressor mixin   sklearn tags; cluster mixin   sklearn tags; transformer mixin   sklearn tags; density mixin   sklearn tags; outlier mixin   sklearn tags; multi output mixin   sklearn tags; unstable arch mixin   sklearn tags; calibrated classifier cv   sklearn tags; temperature scaling   sklearn tags; linear discriminant analysis   sklearn tags; dummy classifier   sklearn tags; dummy regressor   sklearn tags; isotonic regression   sklearn tags; polynomial count sketch   sklearn tags; rbf sampler   sklearn tags; skewed chi2sampler   sklearn tags; additive chi2sampler   sklearn tags; nystroem   sklearn tags; kernel ridge   sklearn tags; one vs rest classifier   sklearn tags; one vs one classifier   sklearn tags; output code classifier   sklearn tags; multi output estimator   sklearn tags; multi output classifier   sklearn tags; base chain   sklearn tags; classifier chain   sklearn tags; regressor chain   sklearn tags; base discrete nb   sklearn tags; multinomial nb   sklearn tags; complement nb   sklearn tags; categorical nb   sklearn tags; pipeline   sklearn tags; feature union   sklearn tags; base random projection   sklearn tags; affinity propagation   sklearn tags; base spectral   sklearn tags; birch   sklearn tags; bisecting k means   sklearn tags; dbscan   sklearn tags; base k means   sklearn tags; spectral clustering   sklearn tags; hdbscan   sklearn tags; column transformer   sklearn tags; transformed target regressor   sklearn tags; pls   sklearn tags; sparse coder   sklearn tags; dictionary learning   sklearn tags; fast ica   sklearn tags\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nClassification, Regression, Clustering, Transformation, Density Estimation, Outlier Detection, Multi-output, Unstable Architecture, Calibration, Temperature Scaling, Linear Discriminant'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ncluster mixin fit predict; outlier mixin fit predict; fit context; calibrated classifier cv fit; fit classifier calibrator pair; fit calibrator; sigmoid calibration fit; temperature scaling fit; linear discriminant analysis fit; quadratic discriminant analysis fit; dummy classifier fit; dummy regressor fit; isotonic regression fit; polynomial count sketch fit; rbf sampler fit; skewed chi2sampler fit; additive chi2sampler fit; nystroem fit; kernel ridge fit; fit binary; constant predictor fit; one vs rest classifier fit; fit ovo binary; one vs one classifier fit; output code classifier fit; multi output classifier fit; base chain fit; classifier chain fit; regressor chain fit; gaussian nb fit; base discrete nb fit; categorical nb fit; fit one; affinity propagation fit; affinity propagation fit predict; agglomerative clustering fit; agglomerative clustering  fit; agglomerative clustering fit predict; feature agglomeration fit; feature agglomeration fit predict; base spectral fit; spectral coclustering  fit; spectral biclustering  fit; spectral biclustering  fit best piecewise; birch fit; birch  fit; bisecting k means fit; dbscan fit; dbscan fit predict; base k means fit predict\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nClassification, Regression, Clustering, Model Fitting, Prediction, Outlier Detection, Calibration, Discriminant Analysis, Sampling, Chain Methods, Naive Bayes, Affinity Propagation'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ntransformer mixin fit transform; linear discriminant analysis transform; isotonic regression  transform; isotonic regression transform; polynomial count sketch transform; rbf sampler transform; skewed chi2sampler transform; additive chi2sampler transform; additive chi2sampler  transform dense; additive chi2sampler  transform sparse; nystroem transform; cached transform; pipeline  can inverse transform; pipeline inverse transform; transform one; fit transform one; feature union fit transform; birch transform; agglomeration transform transform; agglomeration transform inverse transform; base k means fit transform; base k means transform; base k means  transform; test transform match across dtypes; test transform; test fit transform; trans transform; double trans transform; sparse matrix trans transform; trans no2d transform; trans raise transform; test column transform set output mixed; test column transform set output after fitting; test transform pd na; test metadata routing no fit transform; no fit transform fit; no fit transform transform; test transform target regressor error; test transform target regressor invertible; test transform target regressor functions; test transform target regressor functions multioutput; test transform target regressor 1d transformer; test transform target regressor 2d transformer; test transform target regressor 2d transformer multioutput; test transform target regressor 3d target; test transform target regressor multi to single; dummy checker array transformer inverse transform; test transform target regressor ensure y array; dummy transformer inverse transform; test transform target regressor count fit\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nTransformations, Machine Learning Models, Data Preprocessing, Dimensionality Reduction, Sampling, Pipeline, K-means, Isotonic Regression, Polynomial Count Sketch, RBF Sampler, S'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\none to one feature mixin get feature names out; class name prefix features out mixin get feature names out; isotonic regression get feature names out; additive chi2sampler get feature names out; pipeline get feature names out; pipeline feature names in; feature union   init; feature union set output; feature union named transformers; feature union get params; feature union set params; feature union  validate transformers; feature union  validate transformer weights; feature union  iter; feature union get feature names out; feature union  add prefix for feature names out; feature union fit; feature union  log message; feature union  parallel func; feature union transform; feature union  hstack; feature union  update transformer list; feature union n features in; feature union feature names in; feature union   sklearn is fitted; feature union  sk visual block; feature union   getitem; feature union get metadata routing; test feature names out; test one feature; test feature agglomeration; test feature agglomeration feature names out; test feature names out; column transformer get feature names out; column transformer  add prefix for feature names out; feature names out with str format; test column transformer get feature names; test feature names empty columns; test feature names out pandas; test feature names out non pandas; test feature names in; trans with names get feature names out; test verbose feature names out true; feature names out callable name clash; feature names out callable upper; test verbose feature names out callable or str; test verbose feature names out false; test verbose feature names out false errors; test transformers with pandas out but not feature names out; test pls feature names out\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nfeature extraction, data preprocessing, pipeline, isotonic regression, additive chi2sampler, column transformer, one to one feature mixin, test feature names, feature union, sklearn integration, verbose output'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nisotonic regression; isotonic regression   getstate; test affinity propagation; test affinity propagation precomputed; test affinity propagation no copy; test affinity propagation affinity shape; test affinity propagation precomputed with sparse input; test affinity propagation predict; test affinity propagation predict error; test affinity propagation equal mutual similarities; test affinity propagation predict non convergence; test affinity propagation non convergence regressiontest; test equal similarities and preferences; test affinity propagation convergence warning dense sparse; test correct clusters; test sparse input for predict; test affinity propagation equal points; test get submatrix; test shape indices; test spectral coclustering; test spectral biclustering; do scale test; do bistochastic test; test scale normalize; test bistochastic normalize; test log normalize; test project and cluster; test perfect checkerboard; test spectralbiclustering parameter validation; test n samples leaves roots; test birch predict; test n clusters; test sparse x; test branching factor; test threshold; test birch n clusters long int; test subcluster dtype; test both subclusters updated; test birch copy deprecated; test three clusters; test sparse; test n clusters; test one cluster; test dtype preserved; test float32 float64 equivalence; test no crash on empty bisections; test dbscan similarity; test dbscan feature; test dbscan sparse; test dbscan sparse precomputed\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nIsotonic regression, Affinity propagation, Clustering, Biclustering, Scale normalization, Bistochastic normalization, Log normalization, Project and cluster, Spectral clustering, Spectral'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\npartial fit binary; one vs rest classifier partial fit; partial fit ovo binary; one vs one classifier partial fit; partial fit estimator; multi output estimator partial fit; multi output regressor partial fit; gaussian nb partial fit; gaussian nb  partial fit; base discrete nb partial fit; categorical nb partial fit; birch partial fit; mini batch k means partial fit; test partial fit; test partial fit second call error checks; test minibatch kmeans partial fit init; incremental pca partial fit; latent dirichlet allocation partial fit; mini batch nmf partial fit; test incremental pca partial fit small batch; test incremental pca partial fit; test incremental pca partial fit float division; test minibatch nmf partial fit; test lda partial fit; test lda partial fit multi jobs; forest regressor  compute partial dependence recursion; base gradient boosting  compute partial dependence recursion; base hist gradient boosting  compute partial dependence recursion; tree predictor compute partial dependence; hashing vectorizer partial fit; select from model partial fit; test partial fit; test partial fit validate max features; test partial fit validate feature names; partial dependence recursion; partial dependence brute; partial dependence; test partial dependence helpers; test partial dependence easy target; test partial dependence error; test partial dependence unknown feature indices; test partial dependence unknown feature string; test partial dependence x list; test partial dependence sample weight of fitted estimator; test partial dependence pipeline; test partial dependence binary model grid resolution; test partial dependence binary model custom values; test partial dependence pipeline custom values; test partial dependence dataframe; test partial dependence feature type\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\npartial fit, binary classification, one vs rest classifier, one vs one classifier, multi output estimator, multi output regressor, gaussian naive bayes, discrete naive bayes, categorical naive bayes'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\npipeline   init; pipeline set output; pipeline get params; pipeline set params; pipeline  validate steps; pipeline  iter; pipeline   len; pipeline   getitem; pipeline  estimator type; pipeline named steps; pipeline  final estimator; pipeline  log message; pipeline  check method params; pipeline  get metadata for step; pipeline  fit; pipeline fit; pipeline  can fit transform; pipeline fit transform; pipeline predict; pipeline fit predict; pipeline predict proba; pipeline decision function; pipeline score samples; pipeline predict log proba; pipeline  can transform; pipeline transform; pipeline score; pipeline classes; pipeline n features in; pipeline   sklearn is fitted; pipeline  sk visual block; pipeline  get name; pipeline get metadata routing; test gridsearch pipeline; test gridsearch pipeline precomputed; test bagging with pipeline; alpha param pipeline get params; rev param pipeline get params; test gradient boosting with init pipeline; test countvectorizer custom vocabulary pipeline; test count vectorizer pipeline grid selection; test vectorizer pipeline grid selection; test vectorizer pipeline cross validation; test w pipeline 2d coef; test pipeline with nans; test pipeline support; test imputation pipeline grid search; test model pipeline same dense and sparse; test pipeline; test pipeline with nearest neighbors transformer\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\npipeline, machine learning, model, data processing, transformation, fitting, prediction, parameters, estimator, validation, grid search, bagging, gradient boosting, count vectorizer, imputation, nearest neighbors, cross validation, sk'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nmake pipeline; make union; spectral biclustering make piecewise; make column selector   init; make column selector   call; test make column transformer; test make column transformer pandas; test make column transformer kwargs; test make column selector with select dtypes; test make column selector error; test make column selector pickle; make classification; make multilabel classification; make hastie 10 2; make regression; make circles; make moons; make blobs; make friedman1; make friedman2; make friedman3; make low rank matrix; make sparse coded signal; make sparse uncorrelated; make spd matrix; make sparse spd matrix; make swiss roll; make s curve; make gaussian quantiles; make biclusters; make checkerboard; test make classification; test make classification informative features; test make classification return x y; test make classification weights type; test make classification weights array or list ok; test make multilabel classification return sequences; test make multilabel classification return indicator; test make multilabel classification return indicator sparse; test make hastie 10 2; test make regression; test make regression multitarget; test make blobs; test make blobs n samples list; test make blobs n samples list with centers; test make blobs n samples centers none; test make blobs return centers; test make blobs error; test make friedman1; test make friedman2\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\npipeline, union, spectral clustering, piecewise, column selection, initialization, testing, column transformation, pandas, data types, errors, pickling, classification, multilabel classification, Hastie 10-2'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ngaussian random matrix; sparse random matrix; base random projection   init; base random projection  make random matrix; base random projection  compute inverse components; base random projection fit; base random projection inverse transform; gaussian random projection   init; gaussian random projection  make random matrix; gaussian random projection transform; sparse random projection   init; sparse random projection  make random matrix; sparse random projection transform; test affinity propagation random state; test sanity check pls canonical random; set random states; random forest classifier   init; random forest regressor   init; random trees embedding   init; random trees embedding  set oob score and attributes; random trees embedding fit; random trees embedding fit transform; random trees embedding get feature names out; random trees embedding transform; test set random states; test balance property random forest; test random trees embedding raise error oob; test random trees dense type; test random trees dense equal; test random hasher; test random hasher sparse data; test random trees embedding feature names out; test find binning thresholds random data; test bin mapper random data; test bin mapper small random data; test random seeds warm start; test random starts; test random starts; test iterative imputer dont set random state; test random descent; random x y coef; test liblinear dual random state; test sgd random state; random ys; random data   init; halving random search cv   init; halving random search cv  generate candidate params; test random search cv results; test random search cv results multimetric; test random search bad cv\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nrandom matrix generation, random projections, Gaussian random projections, sparse random projections, base random projections, random forest, random trees, random states, random hashing, data imputation, optimization, random search, machine'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nmini batch step; mini batch k means   init; mini batch k means  check params vs input; mini batch k means  warn mkl vcomp; mini batch k means  mini batch convergence; mini batch k means  random reassign; mini batch k means fit; dict learning; dict learning online; dict learning; dictionary learning   init; dictionary learning fit; dictionary learning fit transform; dictionary learning  n features out; mini batch dictionary learning   init; mini batch dictionary learning  check params; mini batch dictionary learning  initialize dict; mini batch dictionary learning  update inner stats; mini batch dictionary learning  minibatch step; mini batch dictionary learning  check convergence; mini batch dictionary learning fit; mini batch dictionary learning partial fit; mini batch dictionary learning  n features out; mini batch dictionary learning   sklearn tags; mini batch nmf   init; mini batch nmf  check params; mini batch nmf  solve w; mini batch nmf  minibatch step; mini batch nmf  minibatch convergence; mini batch nmf fit transform; mini batch nmf  fit transform; mini batch nmf transform; test dict learning shapes; test dict learning overcomplete; test dict learning lars positive parameter; test dict learning positivity; test dict learning lars dict positivity; test dict learning lars code positivity; test dict learning reconstruction; test dict learning reconstruction parallel; test dict learning lassocd readonly data; test dict learning nonzero coefs; test dict learning split; test dict learning online shapes; test dict learning online lars positive parameter; test minibatch dictionary learning positivity; test minibatch dictionary learning lars; test dict learning online positivity; test dict learning online verbosity; test dict learning online estimator shapes\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nmini batch, k means, dictionary learning, nmf, fit, convergence, check params, initialize, update inner stats, minibatch step, sklearn, test, shapes, overcomplete, lars, positivity, reconstruction'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ntest n features in; transformed target regressor n features in; test n features in; get data features; mock urlopen data features; test load svmlight file n features; sparse coder n features in; sparse coder  n features out; factor analysis  n features out; fast ica  n features out; latent dirichlet allocation  n features out; base nmf  n features out; truncated svd  n features out; test sparse coder n features in; test n components greater n features; base gradient boosting  set max features; base stacking n features in; base voting n features in; test bootstrap features; test bagging small max features; test max features; test iforest subsampled features; test stacking without n features in; test n features in; test get features names out regressor; test get features names out classifier; test get features names out classifier error; test bin mapper n features transform; test categorical with numerical features; count vectorizer  sort features; count vectorizer  limit features; test unseen or no features; test n features in; test vectorizer max features; test count vectorizer max features; test n features in; select from model  check max features; select from model n features in; test max features error; test inferred max features integer; test inferred max features callable; test max features array like; test max features callable data; test max features; test max features tiebreak; test threshold and max features; test prefit max features; test rfe features importance; test rfe percent n features; test number of subsets of features\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nsparse coding, feature extraction, dimensionality reduction, machine learning, regression, classification, data preprocessing, transformation, factor analysis, independent component analysis, latent dirichlet allocation, non-negative matrix factorization, trunc'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ntest hdbscan feature array; test ledoit wolf empty array; sparse data to array; test fetch openml equivalence array dataframe; test fetch openml equivalence array return x y; build sparse array; check array api get precision; test pca array api compliance; test pca mle array api compliance; test array api error and warnings on unsupported params; is jax zero gradient array; is numpy array; is cupy array; is torch array; is ndonnx array; is dask array; is jax array; is pydata sparse array; is array api obj; is array api cls; is array api strict namespace; array namespace; is writeable array; is lazy array; supports array namespace   array namespace; array namespace info   capabilities; array namespace info   default device; array namespace info   default dtypes; array namespace info   dtypes; array namespace info   devices; array namespace info   capabilities; array namespace info   default device; array namespace info   default dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   dtypes; array namespace info   devices; array namespace info   capabilities; array namespace info   default device; array namespace info   default dtypes; array namespace info   dtypes; array namespace info   devices; array namespace info   capabilities; array namespace info   default device\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\narray, sparse data, API, precision, PCA, fetch, openml, equivalence, dataframe, error, warnings, unsupported params, gradient, numpy, cupy, torch, ndonnx, dask,'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ntest minibatch update consistency; trans assert   init; trans assert fit; trans assert transform; assert graphical lasso cv scores; assert matrix orthogonal; test 20news length consistency; test fetch openml consistency parser; test sparse encode numerical consistency; test non negative factorization consistency; assert nmf no nan; test nmf float32 float64 consistency; test lda numerical consistency; test singular values consistency; test oob score consistency; test max samples consistency; test max samples consistency; check children consistency; assert is stump; assert leaves values monotonic; assert children values monotonic; assert children values bounded; assert categories equals bitset; assert predictor equal; xp assert equal; xp assert less; xp assert close; vectorizer mixin  check stop words consistency; check stop words consistency; assert best scores kept; test gpr consistency std cov non invertible kernel; assert array equal and same dtype; assert allclose and same dtype; test linear regression sample weight consistency; test enet sample weight consistency; test enet cv sample weight consistency; test enet ridge consistency; assert same lars path result; test lars numeric consistency; test consistency path; test omp gram numerical consistency; test solver consistency; test lbfgs solver consistency; test ridge sample weight consistency; test sgd numerical consistency; test glm sample weight consistency; assert equal with sign flipping; assert uniform grid; test returned value consistency; assert raises on only one label\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\ntest, consistency, update, fit, transform, graphical lasso, cv scores, matrix orthogonal, 20news length, fetch openml, sparse encode, non negative factorization, nmf, no nan,'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ncolumn transformer   init; column transformer  transformers; column transformer  transformers; column transformer set output; column transformer get params; column transformer set params; column transformer  iter; column transformer  validate transformers; column transformer  validate column callables; column transformer  validate remainder; column transformer  get remainder cols dtype; column transformer  get remainder cols; column transformer named transformers; column transformer  get feature name out for transformer; column transformer  update fitted transformers; column transformer  validate output; column transformer  record output indices; column transformer  log message; column transformer  call func on transformers; column transformer fit; column transformer fit transform; column transformer transform; column transformer  hstack; column transformer  sk visual block; column transformer   getitem; column transformer  get empty routing; column transformer get metadata routing; get transformer list; make column transformer; test column transformer; test column transformer tuple transformers parameter; test column transformer dataframe; test column transformer empty columns; test column transformer output indices; test column transformer output indices df; test column transformer sparse array; test column transformer list; test column transformer sparse stacking; test column transformer mixed cols sparse; test column transformer sparse threshold; test column transformer error msg 1d; test 2d transformer output; test 2d transformer output pandas; test column transformer invalid columns; test column transformer invalid transformer; test make column transformer remainder transformer; test column transformer get set params; test column transformer named estimators; test column transformer cloning; test column transformer special strings\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nColumn Transformer, Data Transformation, Feature Engineering, Machine Learning Pipeline, Transformer Initialization, Transformer Validation, Transformer Fitting, Transformer Calling, Transformer Testing, Sparse Array Handling, Error'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nbase pca get covariance; base pca get precision; base pca fit; base pca transform; base pca  transform; base pca inverse transform; base pca  n features out; incremental pca   init; incremental pca fit; incremental pca transform; kernel pca   init; kernel pca  get kernel; kernel pca  fit transform in place; kernel pca  fit inverse transform; kernel pca fit; kernel pca fit transform; kernel pca transform; kernel pca inverse transform; kernel pca  n features out; pca   init; pca fit; pca fit transform; pca  fit; pca  fit full; pca  fit truncated; pca score samples; pca score; base sparse pca   init; base sparse pca fit; base sparse pca transform; base sparse pca inverse transform; base sparse pca  n features out; sparse pca   init; sparse pca  fit; mini batch sparse pca   init; mini batch sparse pca  fit; test incremental pca; test incremental pca sparse; test incremental pca check projection; test incremental pca inverse; test incremental pca validation; test incremental pca set params; test incremental pca num features change; test incremental pca batch signs; test incremental pca batch values; test incremental pca batch rank; test incremental pca against pca iris; test incremental pca against pca random data; test incremental pca fit overflow error; test kernel pca\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nPrincipal Component Analysis (PCA), Covariance, Precision, Fit, Transform, Inverse Transform, Kernel Methods, Sparse PCA, Mini Batch Sparse PCA, Incremental P'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\ntest raw predict is called with custom scorer; rfecv  get scorer; test scorer; weights scorer; my scorer; logistic regression cv  get scorer; ridge gcv  score without scorer; base ridge cv  get scorer; test logistic cv mock scorer; mock scorer   init; mock scorer   call; test ridge cv custom multioutput scorer; custom multioutput scorer; multimetric scorer   init; multimetric scorer   call; multimetric scorer   repr; multimetric scorer  accept sample weight; multimetric scorer  use cache; multimetric scorer get metadata routing; base scorer   init; base scorer  get pos label; base scorer  accept sample weight; base scorer   repr; base scorer   call; base scorer  warn overlap; base scorer set score request; scorer  score; get scorer; passthrough scorer   init; passthrough scorer   call; passthrough scorer   repr; passthrough scorer  accept sample weight; passthrough scorer get metadata routing; passthrough scorer set score request; make scorer; get scorer names; curve scorer   init; curve scorer from scorer; curve scorer  score; dummy scorer   call; test custom scorer pickling; test classification scorer sample weight; test regression scorer sample weight; test scorer memmap input; test deprecated scorer; test multimetric scorer calls method once; test multimetric scorer calls method once classifier no decision; test multimetric scorer calls method once regressor threshold; test multimetric scorer sanity check; test multimetric scorer exception handling\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nscoring, classification, regression, custom scorers, logistic regression, ridge regression, multimetric scorers, base scorers, mock scorers, curve scorers, dummy scor'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\narff encoder  encode comment; arff encoder  encode relation; arff encoder  encode attribute; arff encoder encode; arff encoder iter encode; one hot; one hot; base encoder  check x; base encoder  fit; base encoder  transform; base encoder infrequent categories; base encoder  check infrequent enabled; base encoder  identify infrequent; base encoder  fit infrequent category mapping; base encoder  map infrequent categories; one hot encoder   init; one hot encoder  map drop idx to infrequent; one hot encoder  set drop idx; one hot encoder  compute transformed categories; one hot encoder  remove dropped categories; one hot encoder  compute n features outs; one hot encoder fit; one hot encoder transform; one hot encoder inverse transform; one hot encoder get feature names out; one hot encoder  check get feature name combiner; ordinal encoder   init; ordinal encoder fit; ordinal encoder transform; ordinal encoder inverse transform; label encoder fit; label encoder fit transform; label encoder transform; target encoder   init; target encoder fit; target encoder fit transform; target encoder transform; target encoder  fit encodings all; target encoder  fit encoding binary or continuous; target encoder  fit encoding multiclass; target encoder  transform x ordinal; test one hot encoder sparse dense; test one hot encoder handle unknown; test one hot encoder handle unknown strings; test one hot encoder dtype; test one hot encoder dtype pandas; test one hot encoder feature names; test one hot encoder feature names unicode; test one hot encoder custom feature name combiner; test one hot encoder set params\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\narff encoding, one-hot encoding, ordinal encoding, label encoding, target encoding, base encoder, feature extraction, data preprocessing, categorical variables, numerical variables, encoding schemes, encoding transformation, encoding inverse transformation,'}]\n",
      "[{'generated_text': 'These function names belong to one cluster:\\nprecision recall fscore support; precision score; recall score; average precision score; binary uninterpolated average precision; precision recall curve; label ranking average precision score; test precision recall f1 score binary; test precision recall f binary single class; test precision recall f extra labels; test precision recall f ignored labels; test average precision score non binary class; test average precision score duplicate values; test average precision score tied values; test precision recall f unused pos label; test precision recall f1 score multiclass; test precision refcall f1 score multilabel unordered labels; test precision recall f1 score binary averaged; test zero precision recall; test precision recall f1 score multilabel 1; test precision recall f1 score multilabel 2; test precision recall f1 score with an empty prediction; test precision recall f1 no labels; test precision recall f1 no labels check warnings; test precision recall f1 no labels average none; test precision recall f1 no labels average none warn; test precision warnings; precision recall curve padded thresholds; average precision; average precision slow; test precision recall curve; test precision recall curve; test precision recall curve toydata; test precision recall curve drop intermediate; test average precision constant values; test average precision score binary pos label errors; test average precision score multilabel pos label errors; test average precision score multiclass pos label errors; test average precision pos label; precision recall display   init; precision recall display plot; precision recall display from estimator; precision recall display from predictions; test precision recall display plotting; test precision recall chance level line; test precision recall display name; test precision recall display pipeline; test precision recall display string labels; test plot precision recall pos label; test precision recall prevalence pos label reusable\\n\\nWrite some keywords and synonyms that summarize the theme of these function names, separated by commas.\\n\\nprecision, recall, fscore, average precision, binary classification, multiclass classification, multilabel classification, precision recall curve, test performance, evaluation metrics, label ranking, zero precision, warnings, padded thresholds,'}]\n",
      "Function nodes clustered.\n",
      "Issues scraped.\n",
      "Warning: Could not extract changed functions from PR # 32799\n",
      "PRs scraped.\n",
      "Issue to PR edges created.\n",
      "Artifacts scraped.\n",
      "Actions scraped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request GET /users/bellet failed with 403: Forbidden\n",
      "Setting next backoff to 215.597688s\n"
     ]
    }
   ],
   "source": [
    "repograph = kgb.build_knowledge_graph(\n",
    "    repo_name='scikit-learn/scikit-learn',\n",
    "    num_of_PRs=300,\n",
    "    num_of_issues=3000,\n",
    "    scrape_comments=False,\n",
    "    semantic_clustering=True,\n",
    "    create_embedding=False,\n",
    "    repo_functions_only=True,\n",
    "    repo_path_modifier='sklearn/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d218c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['function_nodes', 'function_edges', 'subgraph_nodes', 'subgraph_edges', 'subgraph_function_edges', 'function_subgraph_edges', 'import_nodes', 'class_nodes', 'class_function_edges', 'class_class_edges', 'file_nodes', 'file_edges', 'file_function_edges', 'file_class_edges', 'file_import_edges', 'config_nodes', 'file_config_edges', 'import_function_edges', 'pr_nodes', 'pr_function_edges', 'issue_nodes', 'issue_pr_edges', 'artifacts', 'actions', 'cluster_nodes', 'cluster_function_edges', 'functionversion_nodes', 'functionversion_edges', 'functionversion_function_edges', 'developer_nodes', 'developer_function_edges', 'question_nodes', 'question_cluster_edges'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repograph.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7838b820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dev_name</th>\n",
       "      <th>dev_email</th>\n",
       "      <th>dev_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ogrisel</td>\n",
       "      <td>olivier.grisel@ensta.org</td>\n",
       "      <td>Olivier Grisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>amueller</td>\n",
       "      <td>t3kcit+githubspam@gmail.com</td>\n",
       "      <td>Andreas Mueller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>larsmans</td>\n",
       "      <td></td>\n",
       "      <td>Lars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>agramfort</td>\n",
       "      <td>alexandre.gramfort@m4x.org</td>\n",
       "      <td>Alexandre Gramfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>glouppe</td>\n",
       "      <td>g.louppe@gmail.com</td>\n",
       "      <td>Gilles Louppe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>407</td>\n",
       "      <td>mrbeann</td>\n",
       "      <td>jiachengliu@cuhk.edu.hk</td>\n",
       "      <td>mrbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>408</td>\n",
       "      <td>JPFrancoia</td>\n",
       "      <td>jeanpatrick.francoia@gmail.com</td>\n",
       "      <td>JPFrancoia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>409</td>\n",
       "      <td>jaglima</td>\n",
       "      <td>jesselima@protonmail.com</td>\n",
       "      <td>Jesse Lima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>410</td>\n",
       "      <td>fishcorn</td>\n",
       "      <td></td>\n",
       "      <td>Josephine Moeller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>411</td>\n",
       "      <td>jhlegarreta</td>\n",
       "      <td></td>\n",
       "      <td>Jon Haitz Legarreta Gorroño</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     dev_name                       dev_email  \\\n",
       "0      1      ogrisel        olivier.grisel@ensta.org   \n",
       "1      2     amueller     t3kcit+githubspam@gmail.com   \n",
       "2      3     larsmans                                   \n",
       "3      4    agramfort      alexandre.gramfort@m4x.org   \n",
       "4      5      glouppe              g.louppe@gmail.com   \n",
       "..   ...          ...                             ...   \n",
       "406  407      mrbeann         jiachengliu@cuhk.edu.hk   \n",
       "407  408   JPFrancoia  jeanpatrick.francoia@gmail.com   \n",
       "408  409      jaglima        jesselima@protonmail.com   \n",
       "409  410     fishcorn                                   \n",
       "410  411  jhlegarreta                                   \n",
       "\n",
       "                        dev_full  \n",
       "0                 Olivier Grisel  \n",
       "1                Andreas Mueller  \n",
       "2                           Lars  \n",
       "3             Alexandre Gramfort  \n",
       "4                  Gilles Louppe  \n",
       "..                           ...  \n",
       "406                       mrbean  \n",
       "407                   JPFrancoia  \n",
       "408                   Jesse Lima  \n",
       "409            Josephine Moeller  \n",
       "410  Jon Haitz Legarreta Gorroño  \n",
       "\n",
       "[411 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repograph['developer_nodes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917809a7",
   "metadata": {},
   "source": [
    "Scrape issues and PRs for a repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./_/graph_v4.pkl', 'rb') as f:\n",
    "    repograph = pickle.load(f)\n",
    "\n",
    "issues_prs = kgb.scrape_issue_pr_data(\n",
    "    repo_name='scikit-learn/scikit-learn',\n",
    "    cg_nodes=repograph['function_nodes'],\n",
    "    num_of_issues=100,\n",
    "    num_of_PRs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c33898",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('issues_prs.pkl', 'wb') as f:\n",
    "    pickle.dump(issues_prs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6713aac",
   "metadata": {},
   "source": [
    "# 2. Visualize graph\n",
    "\n",
    "Create a HTML visualizaiton of the graph with the `visualize_graph` function. NOTE: for large graphs, it is advised to only plot a fraction of the nodes, othervise the visualization might not render properly. Parameters:\n",
    "- *repograph*: The dictionary containing the created repository graph.\n",
    "- *show_subgraph_nodes* (optional): Whether to plot the subgraph (CFG or AST) nodes. Defaults to *False*.\n",
    "- *save_path* (optional): The file path to save the visualization. Defaults to \"./graph.html\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgb.visualize_graph(repograph, show_subgraph_nodes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ddca6",
   "metadata": {},
   "source": [
    "# 3. Save the graph\n",
    "\n",
    "Saving the graph in different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf755e2a",
   "metadata": {},
   "source": [
    "### 3.1 Save it as a dictionary\n",
    "\n",
    "Saving and loading the resulting graph dictionary as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90b9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_v10_nosubgraph.pkl', 'wb') as f:\n",
    "    pickle.dump(repograph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_TEST.pkl', 'rb') as f:\n",
    "    repograph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repograph.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db90d16",
   "metadata": {},
   "source": [
    "### 3.2 Saving it to Neo4j database\n",
    "\n",
    "The result can be saved to a Neo4j database by calling the `store_knowledge_graph_in_neo4j` method. Parameters:\n",
    "- *URI*: URI for the Neo4J data saving.\n",
    "- *user*: Username for the Neo4J data saving.\n",
    "- *password*: Password for the Neo4J data saving.\n",
    "- *knowledge_graph*: The knowledge graph to save.\n",
    "\n",
    "If the *URI*, *username* and *password* parameters are provided at the `build_knowledge_graph` method, this function will automatically be called and the graph will be saved to neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc78a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgb.store_knowledge_graph_in_neo4j(\n",
    "    URI=\"neo4j://127.0.0.1:7687\",\n",
    "    user=\"neo4j\",\n",
    "    password=\"password\",\n",
    "    knowledge_graph=repograph\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
